{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7780d108-f341-4a7b-b4cd-94d8ef145dc1",
   "metadata": {},
   "source": [
    "# 1. Setup Transformers Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537c609-79f8-44f5-b753-0ef9b973354e",
   "metadata": {},
   "source": [
    "### Transformers library dependency\n",
    "Transformers library is dependent on ML libraries. In order to use it, you MUST install the ML library itself before installing the Transformers library. You will be installing the **Pytorch** ML framework.\n",
    "\n",
    "#### Pytorch installation\n",
    "* Depends on the machine's architecture.\n",
    "* It has separate libraries for CPU & GPU\n",
    "* Follow instructions at [https://pytorch.org/](https://pytorch.org/) to install on your machine\n",
    "* If an incorrect library version is installed, it would lead to an error at runtime (on import statement). You would see an error similar to one below:\n",
    "\n",
    "> **OSError:** [WinError 126] can't find this module. Error loading \"d:\\anaconda3\\envs\\RN\\lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.\n",
    "\n",
    "#### Transformer library installation\n",
    "Once you have the Pytorch installed, use an appropriate command to install the package.\n",
    "\n",
    "* pip install transformers\n",
    "* conda install transformers\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df382b63-cf33-46db-bf9a-e72f3ae61631",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do not use this - use the command generated on [https://pytorch.org/](https://pytorch.org/)\n",
    "# !pip uninstall transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2418364f-e3b6-4647-bc1a-7f2867972061",
   "metadata": {},
   "source": [
    "# 2. Import *pipeline* from transformers \n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7613e7a-c290-40b0-9b8f-05b9f0c6edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d38dc2-bb05-42da-b7a1-490db0430607",
   "metadata": {},
   "source": [
    "# 3. Create the pipeline\n",
    "\n",
    "Easiest way to use any Hugging Face model for inference. \n",
    "\n",
    "**Note:**\n",
    "\n",
    "* Without model argument, you will get a warning\n",
    "* Never use pipeline without model specified explicitly as default model may change in future !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0cd5ce2-f5b9-4531-b806-8aa3df267523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a410b26fc44043a4b977cdc1540f7875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccff00b779a34466ad270ee394a36984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8494ad9f21449fbb70a17cd5baa414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52375520a92a4408bf0f3c40174c2603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raj\\anaconda3\\envs\\genai-course-test\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "pipe = pipeline(\"sentiment-analysis\", model = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f016e8c-fe5d-4fef-9ed0-dcce4f628f77",
   "metadata": {},
   "source": [
    "# 4. Inferencing\n",
    "\n",
    "The parameters used for the pipeline depends on the task. Check out the parameters for each task based on the pipeline class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff25d73-ea21-4b48-a55d-8d39659a7560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998434782028198}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"restaurant had good food\"\n",
    "\n",
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef671ae4-370a-4269-a8da-67f28ee2b4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9996846914291382}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I hated it\"\n",
    "\n",
    "pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ec2ccf-ca38-4ef2-aa54-d5e3e961a7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6b4be-f505-44b2-a4c5-ef6bd03e23c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
