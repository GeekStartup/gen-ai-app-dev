{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9631f11-1f70-4429-8a7d-17ba2e9dc816",
   "metadata": {},
   "source": [
    "# Single step agent with checkpointing\n",
    "Implementation of a single step agent with Langgraph *StateGraph*\n",
    "\n",
    "**Note**\n",
    "Requires langgraph to be installed.\n",
    "\n",
    "%pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86daad1-8031-4b1c-b980-ec24a4f1e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing import Annotated\n",
    "from typing import TypedDict\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from IPython.display import Image, display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78039611-5246-40ab-9bea-222695fb4576",
   "metadata": {},
   "source": [
    "## Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e71df3a4-c3a6-471b-8d07-936ffa9ea9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raj\\anaconda3\\envs\\genai-course\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 0.3.0. An updated version of the class exists in the langchain-cohere package and should be used instead. To use it run `pip install -U langchain-cohere` and import as `from langchain_cohere import Cohere`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load the file that contains the API keys - OPENAI_API_KEY\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')\n",
    "\n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.create_llm import create_gpt_llm, create_anthropic_llm, create_ai21_llm, create_cohere_llm, create_hugging_face_llm\n",
    "\n",
    "# Use MistralAI\n",
    "# A Gated model on HuggingFace\n",
    "model_id = 'distilbert/distilbert-base-cased-distilled-squad'\n",
    "llm = create_cohere_llm() #create_hugging_face_llm(repo_id=model_id, args={\"max_new_tokens\":1024})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41f6b1-8b29-4371-b8db-a4442f686a9c",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1487aa94-4274-40e3-bd27-89218feb4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_messages(response):\n",
    "    # print(messages)\n",
    "    messages = response[\"messages\"]\n",
    "    # return\n",
    "    for message in messages:\n",
    "        print(message.content)\n",
    "        print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76537d1-8d3f-4454-a9b6-9d4738a5d4b9",
   "metadata": {},
   "source": [
    "## 1. Setup StateGraph without checkpoint\n",
    "\n",
    "**Annotated** in python allows developers to declare the type of a reference and provide additional information related to it. In this code the LangGraph is getting informed that *messages* is a list whose behavior is governed by the function *add_messages*. \n",
    "```\n",
    "messages : Annotated[list, add_messages]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a2a461-9e7c-403d-8ec6-5efe79e5c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The messages key is annotated with the add_messages function, which tells LangGraph to append new messages to the existing list, \n",
    "# rather than overwriting it.\n",
    "class AppState(TypedDict):\n",
    "    messages : Annotated[list, add_messages]\n",
    "\n",
    "def test_llm(state : AppState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02714b31-7d40-4f99-b0a6-8e0bdafe006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add nodes, edges & compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a707852-041c-4c6e-be08-b11ec7741a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.graph import START, END\n",
    "\n",
    "graph_builder = StateGraph(AppState)\n",
    "\n",
    "graph_builder.add_node(\"tester\", test_llm)\n",
    "\n",
    "# graph_builder.add_edge(START, \"tester)\n",
    "\n",
    "# If you don't set this a ValueError is thrown\n",
    "graph_builder.set_entry_point(\"tester\")\n",
    "\n",
    "# graph_builder.add_edge(END, \"tester\")\n",
    "graph_builder.set_finish_point(\"tester\")\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84df0725-005c-4148-b422-6ad53db388fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCADbAGsDASIAAhEBAxEB/8QAHQABAAICAwEBAAAAAAAAAAAAAAYHBQgCAwQJAf/EAFAQAAEDAwEDBAsLCAcJAAAAAAECAwQABREGBxIhCBYxQRMUFSJRVVZhlNHTFyMyN0JxdoGRlbQ0UlNUdZKT0glDYnSxs8QkJTNjgoOEwcP/xAAaAQEBAAMBAQAAAAAAAAAAAAAAAQIDBAUH/8QAMxEAAgECAwMKBgIDAAAAAAAAAAECAxEEITESUaETFCNSYXGBkbHRFSIzQVPBBeEyQvH/2gAMAwEAAhEDEQA/APqnSlYK7XaXJuAtFpCRLCQuTMcG83EQejh8pxXyU9AAKlcN1K84xc3ZF1My/IajNlx5xDSB0qWoJA+s1jzqmyg4N3gA/wB5R668DOz+ylYeuEUXuZjCpV1AfWeOeAI3UfMhKR5q9w0rZQMdx4GP7qj1VttRWrbGR+86rL44geko9dOdVl8cQPSUeunNWy+J4HoyPVTmrZfE8D0ZHqp0PbwLkOdVl8cQPSUeunOqy+OIHpKPXTmrZfE8D0ZHqpzVsvieB6Mj1U6Ht4DIc6rL44geko9dOdVl8cQPSUeunNWy+J4HoyPVTmrZfE8D0ZHqp0PbwGR6Yd2g3AkRZkeSR1MupX/ga9dYKZoTTk8e/WO3qV1OJjIStPnSoAEHzg143UTNFgvpfk3Sxg+/NPq7I/DT+ehXwnEDpKVFSgMkE4CabEJ5Qee5+/8Awlk9CU0ri24h5tLjakrQoBSVJOQQegg1yrnIdch9EZhx5w4Q2krUfAAMmsBs/ZUdMRbg8B25dR3RkKGeK3ACBx/NTuIHmQKzVyidv26VFzjs7S28+DII/wDdYrQUrtvRdlWQUuIiNtOJUMFLiBuLSR5lJI+quhZUXbev2X7GepSlc5CO662g6f2a2MXfUlwFugqeRGbUGluuOurOENtttpUtajg4SkE8D4KrfWXKm0zpids/VGZn3O06qkSmzMj2yYtyOhlt0qIZQwpal9kbCCjAUBvKIwkms3yhbTaLtoiILvatS3AR7kxJiSdJR1PXC3SEBRRKbSnJ73iDhKvh4KSCaqMztoLuntj+t9W6evV4k6e1DPM1qHbP95rgux5MePJdiN5KVkLbK0JGRvZwOIAFz6z5QWgtntzjwNQ3xdskPR25XvkCSptlpZIQt5aWylkEgjLhT0HwV36n256K0fqZGnbld3e7jkRqc3AhwJMt1xhxa0JcSllte8nLaskfBwCrAIJoXbmNV7QLjrW2y7Rr1+1XPTjSNKWuxMvRorrz0dfZu6C0lIStLhSktPqCdwHCVEmphsU0/dE7XYF6m2S4wmPc3s0DtmdCcZ3JCX3y6wSpIw4nvCpHSO9PWKAmGy3lBWraZrbV+mmoM+FMsl0dgsrcgSg0+2200pTinVMpbbVvOKAbKt4hIUMhQNWvVH7J5Fw0Xtf2kaeuenr0lGoNQKvVvvDUFbluWwqEwkhUgDdQsKYUndVgklOM5q8KAUpSgIxobEFq62ROA1aJhjR0pzhLCm0OtJGepKXAgeZFSeozpJPbF61TPTnsT1wDLZIxkNMttqPn78OD6qk1dFf6jfdfvtnxK9RUXeCtG3KVLDal2Ka4XpHY0lSobxxvOED+qVjKiPgKyo5SpSkSila4T2bp5pgiuqNnujNqDECTqDT9m1QywlSojs6K3JShK8bxQVA4Ct1OcdOBWBHJt2UBJT7m+lt0kEjuSxgnq+T5zUlk6Ctbj7j8NUuzvOElarZJWwlRJySWwdwknjkpz08eJrq5kyOrVN+H/eZ9lWzYpPSVu9e1xkcNIbKNF7P5j8vTOlLPYJT7fYnXrbCbYWtGc7pKQMjIBxUrqL8yZHlVfv4zPsqcyZHlVfv4zPsqcnT6/Biy3kopWvu2K9ah0JtE2UWS26nuioep7w7BnF9TSlhtLJWNwhsbpz1kGra5kyPKq/fxmfZU5On1+DFlvMvqDTtr1XZ5NpvVujXW2SQA9DmNJdacAIUApKgQcEA/OBUJRybtlLZJRs40ukkEZFpYHAjBHwfAaz/MmR5VX7+Mz7KnMmR5VX7+Mz7KnJ0+vwYst5ibRsB2aWC6RblbdA6cgXCK4l5iVGtjKHGlg5CkqCcgg9YrPXa/uSZLlpsi25F1zuuu/CagpPSt3+1j4LfSo46E7yk+c6CZkcJt5vU9s8C05OU0lXz9i3MjzdB66z1utkS0RERYUZqJHTkhtlASMnpPDrPWeunRwzT2nwGSOFmtMexWqLb4oUGI6AhJWd5SvCpR61E5JPWSTXtpStDbk7vUgpSlQClKUApSlAa78pb46OT39JZH4Y1sRWu/KW+Ojk9/SWR+GNbEUApSlAKUpQClKUApSlAKUpQClKUBrvylvjo5Pf0lkfhjWxFa78pb46OT39JZH4Y1sRQClKUApSlAKUpQClKUApSoa9q+63Nbjlit8N6ClSkIlzpC2+zEHBKEJQe8zkBRIzjIBSQo7adKVT/Etrkyry3S1xL3bJlunsIlQZjK48hhwZS42tJSpJHgIJH11Eu7usP1Cx+lvezp3d1h+oWP0t72db+az3rzQsfF7lE7HZmwva/qDSUlKzGjvF2A+5/XxF8Wl5xgnd4KxwCkqHVX1a5DuxuRsW5PtogTwtu7XhxV6msLBBZcdQgJbwegpbbbCh+dvVg9s3J5d23a90Tqq9wLMiZpt/fU0h9xSZ7IVvpYdy18ALGfmUsfKyLj7u6w/ULH6W97OnNZ715oWJvSoR3d1h+oWP0t72dckX/VyDvLtlmdSPkImupJ+stH/D105rPevNCxNaVjrFe2L/bxKZStpQWpp1h0YWy4k4UhQHDII6QSCMEEggnI1yyi4txepBSlKxApSlAKrnZsd7Z5phRxlVsjE4GOJaTVjVXGzT4utL/suL/lJr0MP9KfevSRfsSJLiFqWlKkqUg4UAeKTjOD9RFcq1l2YPXTQU/b3q+VqO43S32S9z5TtnVHjJbkqbgR3QsrS0FhQSAgAKCcJBIJyT17Pdc7ab1K0veTbbvdIF4CHZ0a4wbZGtsVl1oqQ5HdZkqkEJUUcHAoqSVHvTgU2iGzxIAJJwB1muKFpcQlaFBaFDIUk5BHhrUwas1VqjYjtTtOrtY3GJraNpiVJnael2aPFXCwhwrMdYQQ/HcCS2FgrIBzvJURjPXTWGrdmOyPZpYrTdbnqO/6pdYjx5naUJUiFHEPsqkMtnsLK1AN4SXSfhKJKsBJbQNl6VqzqHaHth0nsz1bImInW+THnWhqyXq/woCJD3Z5jbMhp5mM440UgKGFAJOHDjBSDWxmkrNdLHa1MXfUEnUktTpc7bkx2WCkEDvEpaQkboIJGcq48VGqncHt2en/AGzVo6hd+A/8WMf8SamFQ7Z7+W6u/bH+kjVMa0Yn6r7l6IrFKUrlIKUpQCq42afF1pf9lxf8pNWPVb25cjRFvYs8y2z32YSAzHlQIa5KHmU4CDhtJKVYwCkjpBwSMGvQw2cJQWt1+/cyWaMKxsYtMTXN51HHuV1ZYvWVXSwh5CrbNcLPYS440pBVvFATndUASkEg14tDbCIOz6THTbNV6rctENtxmFZJVzC4cRCklISgbgWoJB70LWrdwMdFS3nnG8WX77kl+ypzzjeLL99yS/ZVv5CfVY2XuIdpzk+2OzzbrLul4v2rpVwtS7Gt7UE1L6m4KzlbKShCOCjglSt5RwO+rzp5ONkd0NF0xO1BqS5sW+SzKtNwkzUCZanGk7rRjuobTjdTkd8FZBOc1J7ptY0/ZJtuh3E3KBLuTpYhR5NrktuSnAMlDaS2CtQHHAyayXPON4sv33JL9lTkJ9VjZe4i0jYfBueipem7vqbUl9alXCNcXJ1xmNuSAth1p1CU4bCEI3mU5SlAzlR6TmrIrAc843iy/fckv2VckauaeO61ab4451JNokN5/wCpaEpH1kU5Ga/1JZnv2e/lurv2x/pI1TGo/oyzSbVBlvzUpam3CSqW8yghQaJSlCUbw6SEoSCfDnHCpBXBiJKVRtdnBWDFKUrnIKUpQClKUApSlAa78pb46OT39JZH4Y1sRWu/KW+Ojk9/SWR+GNbEUApSlAKUpQClKUApSlAKUpQClKUBrvylvjo5Pf0lkfhjWxFa78pb46OT39JZH4Y1sRQClKUApSlAKUpQClKUApSuC3UN431pTno3jigOdeS7vzItqmvW+KidPbYWuPFce7Cl5wJJSgr3VbgJwN7BxnOD0V3dtM/pm/3hTtpn9M3+8KtmD5a7V/6Qp/Wmv9CXWVs4XZ5Oi7s7Mdgu3grU+ooLZaJMdJbIPXhXgxW+PJe29SeUds2d1c/phelWu33YbEdUztoPoQlBLqV9jb4byloxg8Wzx6hozy5uS1Pf5R1imaTjpXF2gSg33g97jzsgPKWQO9SpJDpJ/wCaehNfRvZtouzbLtB2LSlnU2i32mKiM2cgFZA75xWPlKUVKPnUaWYJTSurtpn9M3+8K/RIaUQA6gk9AChSzB2UpSoBSlKAV5bpdItlt0idOeTHiMIK3HFdAA8w4k+ADiTwFeqqg26Xlbs+zWNCsMFK58hP5xSQloecZK1fOhNdmDw/Oq8aW/XuKiOaq2i3nVj7iWpD9ntWSG4sZfY3XE9SnHE98CfzUkAZwd7GahirDbXFKW5AjurVxUt1oLUr5yeJr30r6PRpQw8dikrIx2mY/m9avFkP0dHqpzetXiyH6Oj1VkKiF52uaS0/eXLXPvCGJTSkoePYXFNMKVjdS66lJQ2TkcFKHSK2SqqCvKVvEXe8z/N61eLIfo6PVTm9avFkP0dHqqO3zbDpHTlznW+4XYsy4CkCWhEV5wRwpCVpU4pKCEoKVp78kJ6RnIIHr1RtM01o5+Gzdboll+WgustMtOPrU2OlzdbSohH9o4HnrHl4K/z6a5i73mX5vWrxZD9HR6qHTtqII7mQ8Hh+To9VYLZPq6XrzZ3ZL/ObYalTmS44iMkpbB3lDvQST0AdJNS2soVNuKknkxd7zvslyuGl3Ers09+3hJHvCVFbCh4C0e9+sAHwEVeWz/XzOs4a23kJi3aMB2xGBykg9DiCelJx84PA9RNDV67FeHNN6ltF1bVuhqQhh7j8JhxSUOA+HGQrHhQK8rH4GGKpuSXzrR/plTvkzZulKV89AqkNt0VUfWtqlK/4cqAtlJx8ptzeIz8zo+w+CrvqM7QdGp1rYTFQtLM5hYfiPLzhDgBGFY+SoEpPmOekCvS/j8RHDYmM56aPxKjX+lfkqM4xIk2+fGVHltZbfivDiP5knqI4EdFQ33F9A+Rlj+72v5a+hNyaThZ+P9MwJnWuUTRbNuumqLDqex6zuXdS7yX2nbPLl9z5caQvILgbcS2ggKIWFgcE9dW17i+gfIyxfd7X8tTJKQhISkBKQMADqFaJ0XWttpK3j6pApt7S81j3a47VtlFiZBZZggsrV2yE21LeGyR74d4bvDPHh014NJquezzVjNzuenbzdI9207bIrL8CEp9yI6whQcYcSOLe8VhWTgZByeHC9KVObK6knZq7823+wQDYJbZlo2QaZhz4j8CY1HUHI0lstuNnsijhSTxB41P6jt+2daW1RO7dvGnbZdJe4G+zy4qHF7o6BkjOOJrHe4toHyMsX3e1/LWyEZ04qEUmllr/AECZ11vRVXF2HBb4uy5TMdAAzxU4kZ+oZPzA1jbFpmyaNhPM2i2wrNEWvsriIrSWUFWAN4gADOABnzVbuyXQj709jUlxZUy00lXaEd1JCyVDdLygejvchI8ClE9IrVicTHC0XUnr9u8sdblv0pSvmhRSlKAwupNGWbVzSEXWCiQtsENvpJQ63np3XEkKT9R41CntgdrUolm+3qOk9CAthYHzFTRP2k1Z9K7KWMxFBbNObS3FuVZ7gMHylvf2RfYU9wGD5S3v7IvsKtOlb/ieL/J6ewuVZ7gMHylvf2RfYU9wGD5S3v7IvsKtOlPieL/J6ewuVZ7gMHylvf2RfYV+jYDAzx1JeyPN2qP/AIVaVKfE8X+T0FyFWDZBpywyG5KmHrpLbIUh+4udl3SOgpRgIB84SD56mtKVxVa1Ss9qpJt9ovcUpStJD//Z",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is to visualize the state machine\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015312d5-ba26-484d-820c-6998840d83d9",
   "metadata": {},
   "source": [
    "## 2. Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8883ab5-8125-451c-aa56-e187e7ef77be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is retrieval augmented generation?\n",
      "--------------------\n",
      " Retrieval-Augmented Generation (RAG) is a process that involves using pre-existing information to create new information. In general, it involves three steps: retrieval, augmentation, and generation. Here's a brief overview:\n",
      "\n",
      "1. Retrieval: This step involves collecting and retrieving relevant data from existing sources to serve as the basis for the generation process.  This could include databases, document corpora, or even web sources. \n",
      "\n",
      "2. Augmentation: In this step, the retrieved data is then manipulated, enhanced, or modified to create a richer set of information. This can involve merging or blending information, adding logical extensions, or creating hybrids of different sources. It aims to refine and expand the retrieved data to provide more diverse sources and ideas for the generation process. \n",
      "\n",
      "3. Generation: Finally, the augmented data is then used as the input for an artificial intelligence (AI) model that produces new content. This could be a language model (like GPT-3) or a more specific model depending on the task. \n",
      "\n",
      "RAG is particularly useful when dealing with data regimes, memory, or fact-based data where algorithms need to generate new content but also remain anchored in reality. \n",
      "\n",
      "Let me know if you'd\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Question: 1\n",
    "response = graph.invoke({\"messages\":[HumanMessage(\"what is retrieval augmented generation?\")]})\n",
    "\n",
    "pretty_print_messages(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f274dd12-c120-45e2-be95-d834e07cf4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how is it different than fine tuning?\n",
      "--------------------\n",
      " They are two different concepts, although they may be related.\n",
      "\n",
      "**Training** in general refers to the process of teaching a model to learn and make predictions based on input data. The process of training comprises multiple steps, which include the following:\n",
      "\n",
      "- Data preparation: Preparing the data to feed it to the model is one of the critical steps of the process. The data may need to be cleaned and preprocessed to remove irrelevant information, noise, or duplicated entries.\n",
      "- Supervised learning: This is the most common type of machine learning algorithm that learns from artificially made examples. It comprises two main steps: assigning labels to the data and using the data to infer the logic of relationships between the labels and features to produce a valid output. This step may need multiple iterations to achieve the desired results and meet the objectives. \n",
      "- Evaluation: During the training process, the work of the model is evaluated against established metrics to measure its performance, understanding problems like bias, variance, or any other that might have an influence on the quality of the results. This step helps to understand if the model is effective in making predictions on a separate dataset from which it was trained.\n",
      "\n",
      "**Fine-tuning**, however, refers to the process of adjusting the weights assigned\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Question: 2\n",
    "response = graph.invoke({\"messages\":[HumanMessage(\"how is it different than fine tuning?\")]})\n",
    "\n",
    "pretty_print_messages(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f4a6f4-f87d-4151-ba9e-b1ebcf5cfe81",
   "metadata": {},
   "source": [
    "## 3. Create StateGraph with MemorySaver checkpointing\n",
    "https://langchain-ai.github.io/langgraph/reference/checkpoints/\n",
    "\n",
    "You can compile any LangGraph workflow with a CheckPointer to give your agent \"memory\" by persisting its state.\n",
    "\n",
    "This permits things like:\n",
    "\n",
    "* \r\n",
    "Remembering things across multiple interaction* s\r\n",
    "Interrupting to wait for user inp* ut\r\n",
    "Resilience for long-running, error-prone age* nts\r\n",
    "Time travel retry and branch from a previous checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e7da32-ebea-4519-91d7-5dfb89627817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint import MemorySaver\n",
    "\n",
    "# Initialize memory to persist state between graph runs\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1e10f-acef-465c-b675-cbd41a8e8efb",
   "metadata": {},
   "source": [
    "## 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0614c73-118d-4f65-9159-17d4e548804e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is retrieval augmented generation?\n",
      "--------------------\n",
      " Retrieval-Augmented Generation (RAG) is a methodology that combines the benefits of both generative and retrieval-based models to create more realistic and accurate synthetic media. \n",
      "\n",
      "Here's a high-level overview of how RAG works:\n",
      "\n",
      "1. Retrieval Phase: \n",
      "    - Given a description or prompt, a retrieval model is used to search and retrieve relevant examples from a dataset. \n",
      "    - The retrieval model sorts through thousands of images or videos to find the most similar and pertinent examples that match the description. \n",
      "2. Generation Phase: \n",
      "    - Once the retrieval model identifies the most appropriate media examples, a generative model takes those examples and modifies or synthesizes new content. \n",
      "    - The generative model uses the retrieved examples as a guide to maintain the relevant stylistic constraints and content constraints while modifying the aspects of the retrieved media to match the prompt. \n",
      "\n",
      "This process allows the generator to produce content that is more realistic, accurate, and varied than traditional generative models while also avoiding some of the shortcomings associated with pure retrieval-based methods. \n",
      "\n",
      "RAG has applications in many areas, including image and video synthesis, text-to-image synthesis, and even text-to-video synthesis. \n",
      "\n",
      "RAG is an active\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "response = graph.invoke(\n",
    "    {\"messages\":[HumanMessage(\"what is retrieval augmented generation?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "\n",
    "pretty_print_messages(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b26b587a-7162-4fda-90ac-38160907fa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is retrieval augmented generation?\n",
      "--------------------\n",
      " Retrieval-Augmented Generation (RAG) is a methodology that combines the benefits of both generative and retrieval-based models to create more realistic and accurate synthetic media. \n",
      "\n",
      "Here's a high-level overview of how RAG works:\n",
      "\n",
      "1. Retrieval Phase: \n",
      "    - Given a description or prompt, a retrieval model is used to search and retrieve relevant examples from a dataset. \n",
      "    - The retrieval model sorts through thousands of images or videos to find the most similar and pertinent examples that match the description. \n",
      "2. Generation Phase: \n",
      "    - Once the retrieval model identifies the most appropriate media examples, a generative model takes those examples and modifies or synthesizes new content. \n",
      "    - The generative model uses the retrieved examples as a guide to maintain the relevant stylistic constraints and content constraints while modifying the aspects of the retrieved media to match the prompt. \n",
      "\n",
      "This process allows the generator to produce content that is more realistic, accurate, and varied than traditional generative models while also avoiding some of the shortcomings associated with pure retrieval-based methods. \n",
      "\n",
      "RAG has applications in many areas, including image and video synthesis, text-to-image synthesis, and even text-to-video synthesis. \n",
      "\n",
      "RAG is an active\n",
      "--------------------\n",
      "how is it different than fine tuning?\n",
      "--------------------\n",
      " Fine-tuning and Retrieval-Augmented Generation (RAG) are both methodologies used in the field of synthetic media, but they differ in their approach and overall strategy. Here are the differences in the two approaches: \n",
      "\n",
      "1. Goal: \n",
      "- Fine-tuning: Fine-tuning is primarily focused on using a large amount of prompt data to improve the performance of a pre-trained generative model, usually through increasing the dataset's diversity or making the generator more generic.  \n",
      "- Retrieval-Augmented Generation (RAG): The goal of RAG is to combine the strengths of generative models and retrieval-based methods to enhance the quality, realism, and accuracy of synthetic content. It aims to improve the model's ability to generate novel, never-before-seen samples that are guided by retrieved relevant examples. \n",
      "\n",
      "2. Process: \n",
      "- Fine-tuning: In fine-tuning, the process involves training the entire generative model with a new dataset while keeping the model structure unchanged. \n",
      "- Retrieval-Augmented Generation (RAG): RAG involves two distinct models or phases: retrieval and generation. The retrieval phase uses a retrieval model to collect relevant examples from a dataset based on the prompt. The\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "response = graph.invoke(\n",
    "    {\"messages\":[HumanMessage(\"how is it different than fine tuning?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "\n",
    "pretty_print_messages(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324177e-dc94-4465-8df4-d38579b4dd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
