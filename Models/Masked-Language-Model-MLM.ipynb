{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3737ee48",
   "metadata": {},
   "source": [
    "# Masked Language Modeling (MLM)\n",
    "\n",
    "https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1c5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8931f6d1",
   "metadata": {},
   "source": [
    "## 1. Load Tokenizer, Model classes\n",
    "\n",
    "PS: Ignore warning for the time being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29e9fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# change this to try out other models\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "# create an instanmce of tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# create the model class\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ecfd67",
   "metadata": {},
   "source": [
    "## 2. Prepare the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31eb4e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text :  The cat sat on the [MASK] and watched the birds outside\n",
      "input_ids :  tensor([[ 101, 1996, 4937, 2938, 2006, 1996,  103, 1998, 3427, 1996, 5055, 2648,\n",
      "          102]])\n",
      "Mask token index :  6\n"
     ]
    }
   ],
   "source": [
    "mask_token = tokenizer.mask_token\n",
    "\n",
    "# example text\n",
    "# notice the use of model specific special mask.\n",
    "input_text = \"The cat sat on the \" + mask_token + \" and watched the birds outside\"\n",
    "\n",
    "\n",
    "\n",
    "# prepare the input\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# find the index of mask_token in the tensor \n",
    "# we need it as it will be predicted in the out put\n",
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "print(\"Input text : \", input_text)\n",
    "print(\"input_ids : \", inputs['input_ids'])\n",
    "print(\"Mask token index : \", mask_token_index.tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70c47e",
   "metadata": {},
   "source": [
    "## 3. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d924c1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 30522])    Vocab Size =  30522\n"
     ]
    }
   ],
   "source": [
    "# Call the model \n",
    "logits =  model(**inputs).logits\n",
    "\n",
    "print(logits.size(), \"   Vocab Size = \", tokenizer.vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9399eb",
   "metadata": {},
   "source": [
    "## 4. Interpret logits to generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7274ffc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens : [2598, 2723, 5568, 6411, 7424]\n",
      "Full sentences : \n",
      "The cat sat on the ground and watched the birds outside\n",
      "The cat sat on the floor and watched the birds outside\n",
      "The cat sat on the grass and watched the birds outside\n",
      "The cat sat on the couch and watched the birds outside\n",
      "The cat sat on the porch and watched the birds outside\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract logits\n",
    "mask_token_logits = logits[0, mask_token_index, :]\n",
    "\n",
    "# Use argmax to get the token with max likelihood\n",
    "# https://pytorch.org/docs/stable/generated/torch.argmax.html\n",
    "# top_tokens = torch.argmax(..)\n",
    "\n",
    "# get the top - k tokens with highest probability\n",
    "# https://pytorch.org/docs/stable/generated/torch.topk.html\n",
    "k = 5\n",
    "top_tokens = torch.topk(mask_token_logits, k, dim=1).indices[0].tolist()\n",
    "\n",
    "print(\"Tokens :\",top_tokens)\n",
    "\n",
    "# Reploace mask in the string\n",
    "print(\"Full sentences : \")\n",
    "for token in top_tokens:\n",
    "    print(input_text.replace(tokenizer.mask_token, tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b07a4",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Use the BertNextSentencePrediction to predict the next sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f39733",
   "metadata": {},
   "source": [
    "## 1. Import the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0642c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForNextSentencePrediction, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ffc9e9",
   "metadata": {},
   "source": [
    "## 2. Create the model for NSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bd23d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to try out other models\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "# create an instanmce of tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# create the model class\n",
    "model = AutoModelForNextSentencePrediction.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf791d9",
   "metadata": {},
   "source": [
    "## 3. Carry out next sentence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5336a8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd sentence is NOT a continuation of the 1st sentence.\n"
     ]
    }
   ],
   "source": [
    "# example text\n",
    "# notice the use of model specific special mask.\n",
    "input_text_1 = \"The cat sat on the rug.\" \n",
    "input_text_2 = \"Clouds are white\" \n",
    "\n",
    "\n",
    "# prepare the input\n",
    "inputs = tokenizer(input_text_1, input_text_2, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs, labels=torch.LongTensor([1]))\n",
    "\n",
    "prediction = outputs.logits.argmax(dim=1)\n",
    "\n",
    "if prediction == 0:\n",
    "    print(\"2nd sentence is a continuation of the 1st sentence.\")\n",
    "else:\n",
    "    print(\"2nd sentence is NOT a continuation of the 1st sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d77de5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd sentence is a continuation of the 1st sentence.\n"
     ]
    }
   ],
   "source": [
    "# example text\n",
    "# notice the use of model specific special mask.\n",
    "input_text_1 = \"The cat sat on the rug.\" \n",
    "input_text_2 = \"It watched the birds outside.\" \n",
    "\n",
    "# prepare the input\n",
    "inputs = tokenizer(input_text_1, input_text_2, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs, labels=torch.LongTensor([1]))\n",
    "\n",
    "prediction = outputs.logits.argmax(dim=1)\n",
    "\n",
    "if prediction == 0:\n",
    "    print(\"2nd sentence is a continuation of the 1st sentence.\")\n",
    "else:\n",
    "    print(\"2nd sentence is NOT a continuation of the 1st sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84b6a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
