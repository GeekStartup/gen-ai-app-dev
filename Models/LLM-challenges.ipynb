{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bff477c",
   "metadata": {},
   "source": [
    "# LLM Challenges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3463acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Collab\n",
    "# !pip install load_dotenv transformers huggingface-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a5e71",
   "metadata": {},
   "source": [
    "## Setup the enviornment varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4b45c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the file that contains the API keys\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')\n",
    "\n",
    "# Sets up keys : HUGGINGFACEHUB_API_TOKEN, OPENAI_API_KEY, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694e045",
   "metadata": {},
   "source": [
    "## Create LLM for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abfdb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "hugging_face_model_ids = [\n",
    "    'tiiuae/falcon-7b-instruct',\n",
    "    'mistralai/Mistral-7B-Instruct-v0.2',\n",
    "    'openlm-research/open_llama_3b_v2'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f3e7f2",
   "metadata": {},
   "source": [
    "## 1. Hallucination\n",
    "\n",
    "Some models are better than others. Try out a couple of models to figure out the ones that hallucinate more than other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5a6b51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' as a Master of Laws degree with a specialization in the field of biology. This degree is designed for individuals who have a background in biology and an interest in the legal aspects of the field. The LLM in Biology and Law may be pursued by students who wish to work as legal advisors or consultants in biotechnology companies, research institutions, or government agencies. It may also be of interest to students who wish to pursue a career in academia, focusing on the ethical, legal, and social implications of biological research and applications.\\n\\nThe curriculum for'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"define LLM in the context of biology\"\n",
    "\n",
    "# Change the index to try out different models\n",
    "llm = InferenceClient(model=hugging_face_model_ids[1])\n",
    "\n",
    "llm.text_generation(text, max_new_tokens=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04015520",
   "metadata": {},
   "source": [
    "## 2. Dated knowledge\n",
    "\n",
    "**Note:**\n",
    "You will also observe hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the models & your own prompts\n",
    "# text = \"who won the 2022 super bowl?\"  # LA Rams vs Cincinnati Bengals  https://en.wikipedia.org/wiki/Super_Bowl_LVI\n",
    "text = \"as of today, who is the prime minister of UK\"\n",
    "\n",
    "# Change the index to try out different models\n",
    "llm = InferenceClient(model=hugging_face_model_ids[0])\n",
    "\n",
    "llm.text_generation(text, max_new_tokens=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080bf8b",
   "metadata": {},
   "source": [
    "## 3. Missing context\n",
    "\n",
    "Model is not aware of your enterprise's business domain or model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the models and your own prompts\n",
    "text = \"do you carry the acme brand robo cleaner?\"\n",
    "# text = \"what is your return policy?\"\n",
    "\n",
    "# Change the index to try out different models\n",
    "llm = InferenceClient(model=hugging_face_model_ids[1])  # 1 = mistralai/Mistral-7B-Instruct-v0.2\n",
    "\n",
    "llm.text_generation(text, max_new_tokens=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d7fdd",
   "metadata": {},
   "source": [
    "## 4. Bias\n",
    "\n",
    "Some models are trained to prevent biases. Try out the model **index= 1 'tiiuae/falcon-7b-instruct'** to see its behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07d95e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1) they are more likely to be able to do the job and 2) they are more likely to be able to do the job.\\nI think that is a very good point.\\nI think that is a very good point.\\nI think that is a very good point.\\nI think that is a very good point.\\nI think that is a'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"for the engineering jobs we should only hire men because \"\n",
    "\n",
    "# Change the index to try out different models\n",
    "llm = InferenceClient(model=hugging_face_model_ids[2])  # 2 = openlm-research/open_llama_3b_v2\n",
    "\n",
    "llm.text_generation(text, max_new_tokens=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915dd03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
