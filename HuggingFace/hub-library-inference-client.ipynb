{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77e97a9-c69f-48c1-935a-a1ec042e0710",
   "metadata": {},
   "source": [
    "# 1. Install the Hugging Face hub library\n",
    "\n",
    "This will use the model hosting on the Hugging Face portal\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf5030-3905-4c7d-96ea-5e5075ba1174",
   "metadata": {},
   "source": [
    "### If using local machine - run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721c591-03ab-4f9b-81ca-888dd5842871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4112101-cd0b-429a-811c-781fdb125f68",
   "metadata": {},
   "source": [
    "### On Google Collab - run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c20fa5-e38f-4186-92fc-1ed44a3669ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch huggingface_hub -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0646c5-c3d8-480f-94a4-4813698c0cd0",
   "metadata": {},
   "source": [
    "# 2. Create the Inference Client\n",
    "\n",
    "Client will use the model hosted on the Hugging Face portal\n",
    "\n",
    "**Class**\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/v0.20.2/en/package_reference/inference_client#huggingface_hub.InferenceClient\n",
    "\n",
    "**Supported tasks**\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/guides/inference#supported-tasks\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "Sometimes API calls fail due to heavy usage of the model on HF. If you get a invocation error, try a again!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e13cd822-17d7-479e-94f2-069b930ff31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy/paste HuggingFace token and hit <enter>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import getpass\n",
    "\n",
    "# You will prompted for the HuggingFace token\n",
    "print(\"Copy/paste HuggingFace token and hit <enter>\")\n",
    "HUGGINGFACEHUB_API_TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1b77e9d-a55e-48a7-9954-eccb6e621050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the model name if you would like to try out a different model\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Create the client\n",
    "client = InferenceClient(model=model_name, token=HUGGINGFACEHUB_API_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46463e2f-e8cb-4350-bd05-c1c69947700b",
   "metadata": {},
   "source": [
    "# 3. List deployed models\n",
    "\n",
    "Returns a subset of models for the specified framework\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/package_reference/inference_client#huggingface_hub.InferenceClient.list_deployed_models\n",
    "\n",
    "**Note:**\n",
    "\n",
    "An invalid framework throws an HTTP error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07679d24-0152-444f-a50a-530eed6b016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image-text-to-text': ['HuggingFaceM4/idefics2-8b', 'HuggingFaceM4/idefics2-8b-chatty'], 'text-generation': ['01-ai/Yi-1.5-34B-Chat', 'bigcode/octocoder', 'bigcode/santacoder', 'bigcode/starcoder', 'bigcode/starcoder2-15b', 'bigcode/starcoder2-3b', 'bigcode/starcoderplus', 'bigscience/bloom', 'codellama/CodeLlama-13b-hf', 'codellama/CodeLlama-34b-Instruct-hf', 'codellama/CodeLlama-7b-hf', 'CohereForAI/aya-23-35B', 'CohereForAI/c4ai-command-r-plus', 'deepseek-ai/DeepSeek-Coder-V2-Instruct', 'EleutherAI/gpt-neox-20b', 'google/gemma-1.1-2b-it', 'google/gemma-1.1-7b-it', 'google/gemma-2b', 'google/gemma-7b', 'HuggingFaceH4/starchat-beta', 'HuggingFaceH4/starchat2-15b-v0.1', 'HuggingFaceH4/zephyr-7b-alpha', 'HuggingFaceH4/zephyr-7b-beta', 'HuggingFaceM4/idefics-9b-instruct', 'kashif/stack-llama-2', 'llhf/Meta-Llama-3.1-70B-Instruct', 'llhf/Meta-Llama-3.1-8B-Instruct', 'meta-llama/Llama-2-13b-chat-hf', 'meta-llama/Llama-2-13b-hf', 'meta-llama/Llama-2-70b-chat-hf', 'meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Llama-2-7b-hf', 'meta-llama/Meta-Llama-3-70B-Instruct', 'meta-llama/Meta-Llama-3-8B-Instruct', 'meta-llama/Meta-Llama-3.1-405B-Instruct', 'meta-llama/Meta-Llama-3.1-405B-Instruct-FP8', 'meta-llama/Meta-Llama-3.1-70B-Instruct', 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'microsoft/Phi-3-mini-4k-instruct', 'mistralai/Mistral-7B-Instruct-v0.1', 'mistralai/Mistral-7B-Instruct-v0.2', 'mistralai/Mistral-7B-Instruct-v0.3', 'mistralai/Mistral-7B-v0.1', 'mistralai/Mistral-Nemo-Instruct-2407', 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO', 'OpenAssistant/oasst-sft-1-pythia-12b', 'OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5', 'sllhf/Meta-Llama-3.1-405B-Instruct-FP8', 'tiiuae/falcon-7b', 'tiiuae/falcon-7b-instruct']}\n"
     ]
    }
   ],
   "source": [
    "# For a specific framework\n",
    "framework = \"text-generation-inference\"  # \"text-to-speech\", \n",
    "deployed_models = client.list_deployed_models([framework])\n",
    "print(deployed_models)\n",
    "\n",
    "## Get all the deploymed models\n",
    "# deployed_models = client.list_deployed_models(\"all\")\n",
    "# print(deployed_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf44f9b7-65d6-48d4-a5e1-c8c70f687043",
   "metadata": {},
   "source": [
    "# 4. Check if a specific model is available as endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a478624-1a3a-4ff2-a1e4-5e74baa07dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelStatus(loaded=False, state='Loadable', compute_type='cpu', framework='transformers')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "client.get_model_status(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c6875-8c8f-495a-9a58-18b56654507a",
   "metadata": {},
   "source": [
    "# 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1194eea8-5bec-41f6-b762-cb6da0eb429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 101 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TextClassificationOutputElement(label='POSITIVE', score=0.9998492002487183),\n",
       " TextClassificationOutputElement(label='NEGATIVE', score=0.0001507535926066339)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = \"I loved the restaurant\"\n",
    "\n",
    "client.text_classification(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c73ce-9c6f-4808-9e00-7cd0ab6e3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "text = \"i hated it\"\n",
    "\n",
    "client.text_classification(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638673a-14a1-4ea9-bdea-910addf0dfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
