{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8fe8dbb",
   "metadata": {},
   "source": [
    "# Hugging Face environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52615d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub[cli] -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f383ac5",
   "metadata": {},
   "source": [
    "## Hugging Face CLI\n",
    "A tool for interacting with Hugging Face Hub.\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/guides/cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3052353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: huggingface-cli <command> [<args>]\n",
      "\n",
      "positional arguments:\n",
      "  {env,login,whoami,logout,repo,upload,download,lfs-enable-largefiles,lfs-multipart-upload,scan-cache,delete-cache,tag}\n",
      "                        huggingface-cli command helpers\n",
      "    env                 Print information about the environment.\n",
      "    login               Log in using a token from\n",
      "                        huggingface.co/settings/tokens\n",
      "    whoami              Find out which huggingface.co account you are logged\n",
      "                        in as.\n",
      "    logout              Log out\n",
      "    repo                {create} Commands to interact with your huggingface.co\n",
      "                        repos.\n",
      "    upload              Upload a file or a folder to a repo on the Hub\n",
      "    download            Download files from the Hub\n",
      "    lfs-enable-largefiles\n",
      "                        Configure your repository to enable upload of files >\n",
      "                        5GB.\n",
      "    scan-cache          Scan cache directory.\n",
      "    delete-cache        Delete revisions from the cache directory.\n",
      "    tag                 (create, list, delete) tags for a repo in the hub\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a7f564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copy-and-paste the text below in your GitHub issue.\n",
      "\n",
      "- huggingface_hub version: 0.23.1\n",
      "- Platform: Windows-10-10.0.22631-SP0\n",
      "- Python version: 3.11.9\n",
      "- Running in iPython ?: No\n",
      "- Running in notebook ?: No\n",
      "- Running in Google Colab ?: No\n",
      "- Token path ?: C:\\Users\\raj\\.cache\\huggingface\\token\n",
      "- Has saved token ?: True\n",
      "- Configured git credential helpers: manager\n",
      "- FastAI: N/A\n",
      "- Tensorflow: N/A\n",
      "- Torch: 2.4.0\n",
      "- Jinja2: 3.1.4\n",
      "- Graphviz: N/A\n",
      "- keras: N/A\n",
      "- Pydot: N/A\n",
      "- Pillow: 10.4.0\n",
      "- hf_transfer: N/A\n",
      "- gradio: N/A\n",
      "- tensorboard: N/A\n",
      "- numpy: 1.26.4\n",
      "- pydantic: 2.8.2\n",
      "- aiohttp: 3.10.1\n",
      "- ENDPOINT: https://huggingface.co\n",
      "- HF_HUB_CACHE: C:\\Users\\raj\\.cache\\huggingface\\hub\n",
      "- HF_ASSETS_CACHE: C:\\Users\\raj\\.cache\\huggingface\\assets\n",
      "- HF_TOKEN_PATH: C:\\Users\\raj\\.cache\\huggingface\\token\n",
      "- HF_HUB_OFFLINE: False\n",
      "- HF_HUB_DISABLE_TELEMETRY: False\n",
      "- HF_HUB_DISABLE_PROGRESS_BARS: None\n",
      "- HF_HUB_DISABLE_SYMLINKS_WARNING: False\n",
      "- HF_HUB_DISABLE_EXPERIMENTAL_WARNING: False\n",
      "- HF_HUB_DISABLE_IMPLICIT_TOKEN: False\n",
      "- HF_HUB_ENABLE_HF_TRANSFER: False\n",
      "- HF_HUB_ETAG_TIMEOUT: 10\n",
      "- HF_HUB_DOWNLOAD_TIMEOUT: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9dadc0",
   "metadata": {},
   "source": [
    "## Caching\n",
    "Hugging Face APIs caches the assets downloaded from the hub. This provides better performance.\n",
    "\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/guides/manage-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f344936b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO ID                                         REPO TYPE SIZE ON DISK NB FILES LAST_ACCESSED  LAST_MODIFIED  REFS LOCAL PATH                                                                                  \n",
      "----------------------------------------------- --------- ------------ -------- -------------- -------------- ---- ------------------------------------------------------------------------------------------- \n",
      "distilbert-base-uncased-finetuned-sst-2-english model           268.1M        4 9 hours ago    19 hours ago   main C:\\Users\\raj\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english \n",
      "Falconsai/text_summarization                    model           245.3M        7 19 minutes ago 19 minutes ago main C:\\Users\\raj\\.cache\\huggingface\\hub\\models--Falconsai--text_summarization                   \n",
      "HuggingFaceH4/zephyr-7b-beta                    model             2.3M        5 3 weeks ago    3 weeks ago    main C:\\Users\\raj\\.cache\\huggingface\\hub\\models--HuggingFaceH4--zephyr-7b-beta                   \n",
      "meta-llama/Meta-Llama-3-70B-Instruct            model           141.1G       32 3 weeks ago    3 weeks ago    main C:\\Users\\raj\\.cache\\huggingface\\hub\\models--meta-llama--Meta-Llama-3-70B-Instruct           \n",
      "meta-llama/Meta-Llama-3-8B                      model            654.0        1 4 months ago   4 months ago   main C:\\Users\\raj\\.cache\\huggingface\\hub\\models--meta-llama--Meta-Llama-3-8B                     \n",
      "meta-llama/Meta-Llama-3-8B-Instruct             model            16.1G        9 3 weeks ago    3 weeks ago    main C:\\Users\\raj\\.cache\\huggingface\\hub\\models--meta-llama--Meta-Llama-3-8B-Instruct            \n",
      "sentence-transformers/all-MiniLM-L6-v2          model           182.5M       12 6 weeks ago    5 months ago   main C:\\Users\\raj\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2         \n",
      "teknium/OpenHermes-2.5-Mistral-7B               model           495.2K        4 3 weeks ago    3 weeks ago    main C:\\Users\\raj\\.cache\\huggingface\\hub\\models--teknium--OpenHermes-2.5-Mistral-7B              \n",
      "\n",
      "Done in 0.1s. Scanned 8 repo(s) for a total of \u001b[1m\u001b[31m157.9G\u001b[0m.\n",
      "\u001b[90mGot 1 warning(s) while scanning. Use -vvv to print details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Checkout the downloaded assets\n",
    "!huggingface-cli scan-cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee48e6a",
   "metadata": {},
   "source": [
    "### Change the caching folder\n",
    "\n",
    "You may change the caching folder by setting the environment variable HF_HUB_CACHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a24cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HF_HUB_CACHE=C:\\Users\\raj\\OneDrive\\Documents\\temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff4a87",
   "metadata": {},
   "source": [
    "### Cleaning the cache\n",
    "You may delete the model folder directly or use the CLI\n",
    "\n",
    "You need to run the command in a terminal and select the revisions that you would like to delete\n",
    "\n",
    "*huggingface-cli  delete-cache*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd12db",
   "metadata": {},
   "source": [
    "### Degraded cache performance warning\n",
    "\n",
    "**Windows**\n",
    "\n",
    "HF caching system uses Sym Links that are not available on Windows. So on Windows you will see a warning indicating that caching is degraded; you may ignore it or you may suppress the warning by using the following environment variable.\n",
    "\n",
    "%env HF_HUB_DISABLE_SYMLINKS_WARNING=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d019fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
