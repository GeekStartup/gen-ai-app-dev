{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3DgDaui2oQo"
   },
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAUndWWV3XbP"
   },
   "outputs": [],
   "source": [
    "# Import PyTorch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# This to plot the predictions and data points for visuals\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFdNiedZ3l7I"
   },
   "source": [
    "## Step 1: Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oe9lp-v3tOa"
   },
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Constants for the linear function y = ax + b\n",
    "a = 3.0\n",
    "b = 2.0\n",
    "\n",
    "# Generate random inputs [100 points for training data (x between 0 & 10)]\n",
    "x_train = torch.rand(100, 1) * 10\n",
    "\n",
    "# y = ax + b with some noise\n",
    "# Noise is adjusted by multiplying with 0.5\n",
    "y_train = a * x_train + b + torch.randn(100, 1) * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dx8d_ykL4DN7"
   },
   "source": [
    "## Step 2: Define the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXOsR---5GJz"
   },
   "outputs": [],
   "source": [
    "# A class representing a model. This is a standard way of defining a neural\n",
    "# network when using PyTorch\n",
    "class NeuralNetworkModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetworkModel, self).__init__()\n",
    "\n",
    "        # In neural networks, the input layer is typically not explicitly defined as a separate layer in the code.\n",
    "\n",
    "        # First Hidden Layer: The first hidden layer self.hidden1 is defined as nn.Linear(1, 10),\n",
    "        # meaning it takes an input of size 1 (which corresponds to the single feature in x_train) and produces an output of size 10.\n",
    "        self.hidden1 = nn.Linear(1, 10)\n",
    "\n",
    "        # Defined as nn.Linear(10, 10), meaning it takes the 10 outputs from the first hidden layer and maps them to another set of 10 neurons.\n",
    "        self.hidden2 = nn.Linear(10, 10)\n",
    "\n",
    "        # Defined as nn.Linear(10, 1), meaning it takes the 10 outputs from the second hidden layer and maps them to a single output.\n",
    "        self.output = nn.Linear(10, 1)\n",
    "\n",
    "    # Define the forward flow of data\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = torch.relu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the class that represents the model\n",
    "model = NeuralNetworkModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMMaa_rp5Iot"
   },
   "source": [
    "## Step 3: Define the loss function and optimizer\n",
    "We define a neural network model with two hidden layers, each having 10 neurons. ReLU activation is used for the hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yP-qQTHg5S7v"
   },
   "outputs": [],
   "source": [
    "# Mean Square Error\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugM0Gjz85V5B"
   },
   "source": [
    "## Step 4: Train the model\n",
    "The model is trained for 1000 epochs. The loss is printed every 100 epochs to monitor the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rskMWbMS5bkg",
    "outputId": "fe05db84-8c12-48c4-8b46-3e554163d481"
   },
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(x_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzMRjNnV5cSf"
   },
   "source": [
    "## Step 5: Evaluate the model\n",
    "After training, we evaluate the model and plot the original data along with the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAxX_JEjGOLq"
   },
   "source": [
    "### Predict with x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28Q2-UUsGNH0",
    "outputId": "9bdefd6e-c111-4422-a203-a7d554d8605b"
   },
   "outputs": [],
   "source": [
    "# Change this to test predictions\n",
    "# NOTICE that prediction performance is good with smaller numbers\n",
    "# compared to larger numbers. It is bcaz model was trained with smaller numbers\n",
    "\n",
    "x = 10.0\n",
    "print(\"Actual value: \", (a*x+b))\n",
    "\n",
    "# Convert x to a Pytorch tensor\n",
    "tensor = torch.tensor([x])\n",
    "\n",
    "# Run the prediction\n",
    "with torch.no_grad():\n",
    "    predicted = model(tensor).detach().numpy()\n",
    "\n",
    "# Keep in mind we added some noise deliberately\n",
    "print(\"Predicted   : \", predicted[0:][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-use the training data for evaluation of the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "lUvI5IA42gYg",
    "outputId": "9f20c478-e5b0-4252-f355-dc21e9a6630b"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted = model(x_train).detach().numpy()\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(x_train.numpy(), y_train.numpy(), color='blue', label='Original data')\n",
    "plt.plot(x_train.numpy(), predicted, color='red', label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
