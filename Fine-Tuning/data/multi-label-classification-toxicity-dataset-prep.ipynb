{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a2f573-58fc-495a-8779-0c13b2276b2a",
   "metadata": {},
   "source": [
    "# Converts Parquet data to JSONL format\n",
    "\n",
    "### HuggingFace dataset\n",
    "Data prepared from the following dataset:\n",
    "\n",
    "https://huggingface.co/datasets/Arsive/toxicity_classification_jigsawD output IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8109c656-f5d0-4002-a32b-829b0fda65b8",
   "metadata": {},
   "source": [
    "### Cohere console for Fine Tuning\n",
    "https://dashboard.cohere.com/fine-tuning/create?endpoint=classify\n",
    "\n",
    "### Cohere fine-tuning data requirements\n",
    "https://docs.cohere.com/docs/classify-preparing-the-data\n",
    "\n",
    "\n",
    "### HuggingFace SQL console\n",
    "https://huggingface.co/blog/sql-console\n",
    "\n",
    "\n",
    "### SQL used for downloading the data\n",
    "PS: Deliberately removed the rows that have *obscene*=1\n",
    "\n",
    "### Code\n",
    "PS: This can also be done with a DuckDB struct pack feature\n",
    "\n",
    "* Used SQL console to download 100 rows from the dataset\n",
    "* Used the code below to convert the dataset from Parquet to JSONL format\n",
    "* Renamed the attributes, as per Cohere's multi-label dataset requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cbbb11b-1337-4b7f-96ee-4e0c7d27eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the parquet file into a pandas DataFrame\n",
    "parquet_file_train = \"c:\\\\Users\\\\raj\\\\Downloads\\\\multi_label_comment_classification_train.parquet\"\n",
    "parquet_file_test = \"c:\\\\Users\\\\raj\\\\Downloads\\\\multi_label_comment_classification_test.parquet\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a36640-0711-45ea-bdf7-60ac2f6fc4d3",
   "metadata": {},
   "source": [
    "## Cohere dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96fedb7e-461c-4c88-bf25-31bcfe2c6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of labels to check\n",
    "label_columns = [\"toxic\", \"severe_toxic\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# Function to process each row\n",
    "def generate_output_cohere(row):\n",
    "       \n",
    "    # Extract the comment text\n",
    "    text = row['comment_text']\n",
    "    \n",
    "    # Create a list of labels where the value is 1\n",
    "    labels = [label for label in label_columns if row[label] == 1]\n",
    "    \n",
    "    # Format as desired output\n",
    "    return {\"text\": text, \"label\": labels}\n",
    "\n",
    "def read_parquet_generate_jsonl_cohere(parquet_file, output_file):\n",
    "    # Generate the training set\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    output_df = df.apply(generate_output_cohere, axis=1)\n",
    "    # output = output_df.to_list()\n",
    "\n",
    "    # Convert the DataFrame to a JSONL file (one JSON object per line)\n",
    "    \n",
    "    output_df.to_json(output_file, orient='records', lines=True)\n",
    "\n",
    "    print(f\"Successfully converted {parquet_file_train} to {output_file}\")\n",
    "\n",
    "# Print the output in the desired format\n",
    "# for entry in output:\n",
    "#     print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8334b2f-7047-4ae7-b3c8-2ac1a8eca3bb",
   "metadata": {},
   "source": [
    "#### Training set\n",
    "\n",
    "* Run the following against the **train** set\n",
    "* Download the parquet file\n",
    "* Rename file to : multi_label_comment_classification_train.parquet\n",
    " \n",
    "SELECT comment_text, toxic, severe_toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM train  where obscene=0 and toxic=1 LIMIT 10\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, severe_toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM train  where obscene=0 and severe_toxic=1 LIMIT 10\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, severe_toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM train  where obscene=0 and threat=1 LIMIT 10\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, severe_toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM train  where obscene=0 and identity_hate=1 LIMIT 10\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, severe_toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM train  where obscene=0 and insult=1 LIMIT 10\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac315845-dfc5-454f-b30d-2fd2610457a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted c:\\Users\\raj\\Downloads\\multi_label_comment_classification_train.parquet to c:\\Users\\raj\\Downloads\\multi_label_comment_classification_train_cohere.jsonl\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_train = \"c:\\\\Users\\\\raj\\\\Downloads\\\\multi_label_comment_classification_train_cohere.jsonl\"\n",
    "read_parquet_generate_jsonl_cohere(parquet_file_train, jsonl_file_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f602fe6-870e-4335-9400-a47cf7e2ddc1",
   "metadata": {},
   "source": [
    "#### Validation\n",
    "\n",
    "* Run the following against the **test** set\n",
    "* Download the parquet file\n",
    "* Rename file to : multi_label_comment_classification_test.parquet\n",
    "\n",
    "SELECT comment_text, toxic, severe_toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM test  where obscene=0 and toxic=1 LIMIT 5\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, severe_toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM test  where obscene=0 and severe_toxic=1 LIMIT 5\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, severe_toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM test  where obscene=0 and threat=1 LIMIT 5\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, severe_toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM test  where obscene=0 and identity_hate=1 LIMIT 5\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, severe_toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM test  where obscene=0 and insult=1 LIMIT 5\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a7f735-c9c6-4c6e-b78b-b99e19e091ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted c:\\Users\\raj\\Downloads\\multi_label_comment_classification_train.parquet to c:\\Users\\raj\\Downloads\\multi_label_comment_classification_test_cohere.jsonl\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_test = \"c:\\\\Users\\\\raj\\\\Downloads\\\\multi_label_comment_classification_test_cohere.jsonl\"\n",
    "read_parquet_generate_jsonl_cohere(parquet_file_test, jsonl_file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe2941-7837-4c25-b441-00894220d248",
   "metadata": {},
   "source": [
    "## OpenAI GPT \n",
    "\n",
    "https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset\n",
    "\n",
    "* Requires the dataset to be in chat message format\n",
    "* For non-chat use cases such as classification, use single-turn format with 3 messages [\"system\", \"user\", \"assistant\"]\n",
    "  e.g., ```{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}]}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30116b69-e790-4401-85f0-eed1d619dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each row\n",
    "def generate_output_openai(row):\n",
    "       \n",
    "    # Extract the comment text\n",
    "    text = row['comment_text']\n",
    "    \n",
    "    # Create a list of labels where the value is 1\n",
    "    labels = [label for label in label_columns if row[label] == 1]\n",
    "\n",
    "    system_message = \"you will categorize the user's input into one or more categories: \"+str([\"toxic\", \"severe_toxic\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "\n",
    "    # The output must be in string format i.e., can't be array so use json.dumps to convert to \n",
    "    json_l = {\n",
    "        \"messages\":[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message\n",
    "            },{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            },{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": json.dumps(labels)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Format as desired output\n",
    "    # return json.dumps(json_l)\n",
    "    return json_l\n",
    "\n",
    "\n",
    "def read_parquet_generate_jsonl_openai(parquet_file, output_file):\n",
    "    # Generate the training set\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    output_df = df.apply(generate_output_openai, axis=1)\n",
    "    # output = output_df.to_list()\n",
    "\n",
    "    # Convert the DataFrame to a JSONL file (one JSON object per line)\n",
    "    \n",
    "    output_df.to_json(output_file, orient='records', lines=True)\n",
    "\n",
    "    print(f\"Successfully converted {parquet_file_train} to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e40d3-3ab5-40a0-9317-0553632d85a9",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68665ebd-911b-4762-a615-bb9e08d3133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted c:\\Users\\raj\\Downloads\\multi_label_comment_classification_train.parquet to c:\\Users\\raj\\Downloads\\multi_label_comment_classification_train_openai.jsonl\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_train = \"c:\\\\Users\\\\raj\\\\Downloads\\\\multi_label_comment_classification_train_openai.jsonl\"\n",
    "read_parquet_generate_jsonl_openai(parquet_file_train, jsonl_file_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6448e70-bffe-430b-9e2f-3231934aedb8",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "176af69f-0f6b-4c79-b2ea-4a48197024a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted c:\\Users\\raj\\Downloads\\multi_label_comment_classification_train.parquet to c:\\Users\\raj\\Downloads\\multi_label_comment_classification_test_openai.jsonl\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_test = \"c:\\\\Users\\\\raj\\\\Downloads\\\\multi_label_comment_classification_test_openai.jsonl\"\n",
    "read_parquet_generate_jsonl_openai(parquet_file_test, jsonl_file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c89b5-f446-4e90-8c93-0938c84a48fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
