{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a03252-dbaf-4028-beb4-50f58e655ca4",
   "metadata": {},
   "source": [
    "# LangChain Output Parser\n",
    "\n",
    "* Feel free to adjust the prompts to get the desired results\n",
    "* The prompts may NOT work for certain models\n",
    "* Although code was tested succesfully with OpenAI GPT3.5, it may break with future releases\n",
    "* In case of failure please fix the prompt and share with others on Q&A forum\n",
    "\n",
    "https://python.langchain.com/docs/modules/model_io/output_parsers/\n",
    "\n",
    "https://python.langchain.com/docs/modules/model_io/output_parsers/quick_start\n",
    "\n",
    "https://python.langchain.com/docs/modules/model_io/output_parsers/types/json\n",
    "\n",
    "https://api.python.langchain.com/en/stable/langchain_api_reference.html#module-langchain.output_parsers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c8e16-a778-4ef9-93b5-7eb92557ac77",
   "metadata": {},
   "source": [
    "#### Google Colab\n",
    "If you are running the code in Google colab, install the packages by uncommenting/running the cell below\n",
    "\n",
    "* The API key file file will not be available\n",
    "* You will be prompted to provide the API Token\n",
    "\n",
    "Uncomment & run the code in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff9918-e16d-40f4-9c47-065dc8064c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The script is downloaded and run to setup the utils folder\n",
    "\n",
    "# !curl -H \"Accept: application/vnd.github.VERSION.raw\" https://raw.githubusercontent.com/acloudfan/gen-ai-app-dev/main/Setup/gcsetup.sh  > gcsetup.sh\n",
    "# !chmod u+x gcsetup.sh\n",
    "# !./gcsetup.sh -l\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d0fa9",
   "metadata": {},
   "source": [
    "## Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed7b5b7-bbfa-4311-96f4-33d684558b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import JSON\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the file that contains the API keys\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6503c",
   "metadata": {},
   "source": [
    "## Create the LLM\n",
    "\n",
    "In this setup we are using the GPT3.5\n",
    "\n",
    "**Note**\n",
    "\n",
    "The utility code provides methods for creating different LLMs. Checkout the code available under **utils/create_llm.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f0d8a8-3d2c-4540-afa6-52ad314e82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    " \n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.create_llm import create_gpt_llm, create_cohere_llm, create_ollama_llm\n",
    "\n",
    "# OpenAI GPT args\n",
    "# openai_args = {\"max_tokens\": -1, \"temperature\": 0.5}\n",
    "# llm = create_gpt_llm(openai_args)\n",
    "\n",
    "llm = create_cohere_llm()\n",
    "\n",
    "# Ensure Ollama is running on your machine \n",
    "# On Collab you need to install it - it will take time to download the model\n",
    "# llm = create_ollama_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd8ee9-68d1-4617-a0fc-c4078e22c181",
   "metadata": {},
   "source": [
    "## 1. Default output parser \n",
    "\n",
    "Result is a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecdd32a1-24cb-4e76-af64-0464f49b384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains  import LLMChain\n",
    "from IPython.display   import JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef09574-c941-4397-98b2-7340702c8dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generate 5 random valid word and number pairs. \n",
      "The odd number should be an odd number between between 5 & 50 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "template_1 = \"\"\"\n",
    "generate {number} random valid word and number pairs. \n",
    "The odd number should be an odd number between between 5 & 50 \n",
    "\"\"\" \n",
    "\n",
    "# Create the prompt template\n",
    "prompt_template_1 = PromptTemplate(\n",
    "    template = template_1,\n",
    "    input_variables = [\"number\",]\n",
    ")\n",
    "\n",
    "print(prompt_template_1.format(number=5))\n",
    "\n",
    "# Create the LLM Chain\n",
    "llm_chain_word_number_pair = LLMChain(\n",
    "    prompt = prompt_template_1,\n",
    "    llm = llm\n",
    ")\n",
    "\n",
    "response = llm_chain_word_number_pair.invoke(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2b69ac4-e511-46e5-9d78-714d7d02d0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response : {'number': 5, 'text': ' Sure, here are 5 random valid word and odd number pairs:\\n\\n1. \"vizir\" (11)\\n2. \"zodiac\" (41)\\n3. \"tachy\" (29)\\n4. \"kwela\" (17)\\n5. \"mesa\" (41) \\n\\nAll of these words are valid English words, and the numbers are odd and between 5 and 50. '}\n",
      "response type : <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"response :\", response)\n",
    "print(\"response type :\", type(response['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6fd49e-d720-4a9e-b2f7-1cdf88919abb",
   "metadata": {},
   "source": [
    "## 2. Use CSV Output Parser\n",
    "https://python.langchain.com/docs/modules/model_io/output_parsers/types/csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d86492b-82dd-49b6-8461-d54ba7917c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "format_instructions = CommaSeparatedListOutputParser().get_format_instructions()\n",
    "\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82781db1-4ffe-4bcd-bbe6-ad2dc32ac749",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_1 = \"\"\"\n",
    "Generate 3 random odd number.\n",
    "The numbers should be between 5 & 50.\n",
    "\n",
    "Format instructions:{format_instructions}\n",
    "\"\"\" \n",
    "\n",
    "prompt_template_1 = PromptTemplate(\n",
    "    template = template_1,\n",
    "    input_variables = [],\n",
    "    partial_variables = {\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9bef2ef-a39d-4922-9742-7353888fad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLM Chain\n",
    "# Output Parser specified = Result is parsed and ready to be consumed\n",
    "# Output Parser not specified = Result is string type\n",
    "llm_chain_three_odd_numbers = LLMChain(\n",
    "    prompt = prompt_template_1,\n",
    "    llm = llm,\n",
    "    output_key = \"result\",\n",
    "    output_parser = CommaSeparatedListOutputParser(),\n",
    ")\n",
    "\n",
    "response = llm_chain_three_odd_numbers.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccba0709-90dd-48b1-ae92-12e4b86753be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result : ['35', '27', '21']\n",
      "result type: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print('result :', response['result'])\n",
    "print('result type:', type(response['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26c706-3c19-4e91-84f8-01ed76f30ddc",
   "metadata": {},
   "source": [
    "## 3. EnumOutputParser\n",
    "\n",
    "* Return type is < enum >\n",
    "\n",
    "https://python.langchain.com/docs/modules/model_io/output_parsers/types/enum\n",
    "\n",
    "Python enum package\n",
    "\n",
    "https://docs.python.org/3/library/enum.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01f27d75-d999-4516-8e79-915fa3d9c4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Select one of the following options: red, green, blue, white, others'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import EnumOutputParser\n",
    "from enum import Enum\n",
    "\n",
    "# Create a class with a set of options\n",
    "class Colors(Enum):\n",
    "    RED = \"red\"\n",
    "    GREEN = \"green\"\n",
    "    BLUE = \"blue\"\n",
    "    WHITE = \"white\"\n",
    "    UNKNOWN = \"others\"\n",
    "\n",
    "# Create the output parser\n",
    "output_parser_enum = EnumOutputParser(enum=Colors)\n",
    "\n",
    "format_instructions = output_parser_enum.get_format_instructions()\n",
    "\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e663e87d-76e0-4da8-8e0b-26c5a14cba56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question using the following format instructions.\n",
      "\n",
      "Format instructions:\n",
      "Select one of the following options: red, green, blue, white, others\n",
      "\n",
      "If the color is not there in the options just say \"others\"\n",
      "\n",
      "Question:blood\n",
      "Answer: red\n",
      "\n",
      "Question:Cucumbers\n",
      "Answer:green\n",
      "\n",
      "Question:lavender\n",
      "Answer:others\n",
      "\n",
      "Question:orange\n",
      "Answer:others\n",
      "\n",
      "Question:car\n",
      "Answer:others\n",
      "\n",
      "Question:shoes\n",
      "Answer:others\n",
      "\n",
      "\n",
      "Question:onion\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Works for Open AI GPT but not for Cohere\n",
    "template_1 = template_1 = \"\"\"\n",
    "Answer the question using the following format instructions.\n",
    "\n",
    "Format instructions:\n",
    "Select one of the following options: red, green, blue, white, others\n",
    "\n",
    "If the color is not there in the options just say \"others\"\n",
    "\n",
    "Question:blood\n",
    "Answer: red\n",
    "\n",
    "Question:Cucumbers\n",
    "Answer:green\n",
    "\n",
    "Question:lavender\n",
    "Answer:others\n",
    "\n",
    "Question:orange\n",
    "Answer:others\n",
    "\n",
    "Question:car\n",
    "Answer:others\n",
    "\n",
    "Question:shoes\n",
    "Answer:others\n",
    "\n",
    "\n",
    "Question:{object}\n",
    "Answer:\n",
    "\"\"\"  \n",
    "\n",
    "prompt_template_1 = PromptTemplate(\n",
    "    template = template_1,\n",
    "    input_variables = [\"object\",],\n",
    "    partial_variables = {\"format_instructions\": output_parser_enum.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Legacy : Create the LLM Chain\n",
    "# llm_chain_get_color = LLMChain(\n",
    "#     prompt = prompt_template_1,\n",
    "#     llm = llm,\n",
    "#     output_key = \"result\",\n",
    "#     output_parser = output_parser_enum,\n",
    "# )\n",
    "\n",
    "# Use LCEL to setup the chain\n",
    "llm_chain_get_color = prompt_template_1 | llm | output_parser_enum\n",
    "\n",
    "print(prompt_template_1.format(object=\"onion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38a679d4-cdd2-452b-ba15-1333cf2210b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_chain_get_color.invoke(input={\"object\": \"blueberries\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "829fb4cf-292f-4066-9768-1e42b334baac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response : Colors.BLUE\n",
      "response type : <enum 'Colors'>\n"
     ]
    }
   ],
   "source": [
    "print('response :', response)\n",
    "print('response type :', type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a9610-4cbc-4db4-9bc3-a018380d816d",
   "metadata": {},
   "source": [
    "## 4. JSON Output Parser\n",
    "\n",
    "* Return type is < dict >\n",
    "\n",
    "https://python.langchain.com/docs/modules/model_io/output_parsers/types/json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c17ad6d-fb60-4968-bafc-d79ba15eb720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from IPython.display import Markdown, JSON\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "template_2 = \"\"\"\n",
    "generate {number} random valid word and odd numbers.\n",
    "The numbers should be between 5 & 50 pairs\n",
    "\n",
    "Format instructions:\n",
    "{format_instructions}\n",
    "\"\"\" \n",
    "\n",
    "class WordNumberCombo(BaseModel):\n",
    "    word: str = Field(description=\"this is a random word\")\n",
    "    odd_number: int = Field(description=\"this is an odd number between 5 and 50\")\n",
    "\n",
    "class ArrayWordNumberCombo(BaseModel):\n",
    "    result: list[WordNumberCombo]\n",
    "\n",
    "# Setup the parser\n",
    "output_parser_json = JsonOutputParser(pydantic_object=ArrayWordNumberCombo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "167a2691-9f18-47a9-8182-9cb070946971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generate 5 random valid word and odd numbers.\n",
      "The numbers should be between 5 & 50 pairs\n",
      "\n",
      "Format instructions:\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"result\": {\"title\": \"Result\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/WordNumberCombo\"}}}, \"required\": [\"result\"], \"definitions\": {\"WordNumberCombo\": {\"title\": \"WordNumberCombo\", \"type\": \"object\", \"properties\": {\"word\": {\"title\": \"Word\", \"description\": \"this is a random word\", \"type\": \"string\"}, \"odd_number\": {\"title\": \"Odd Number\", \"description\": \"this is an odd number between 5 and 50\", \"type\": \"integer\"}}, \"required\": [\"word\", \"odd_number\"]}}}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_template_2 = PromptTemplate(\n",
    "    template = template_2,\n",
    "    input_variables = [\"number\",],\n",
    "    partial_variables = {\"format_instructions\": output_parser_json.get_format_instructions()}\n",
    ")\n",
    "\n",
    "print(prompt_template_2.format(number=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "249ae9b2-7160-4cf3-a772-0f1f6d5df22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLM Chain\n",
    "# With 'output_parser', set the type of result = <class 'dict'>\n",
    "llm_chain_json_five_numbers = LLMChain(\n",
    "    prompt = prompt_template_2,\n",
    "    llm = llm,\n",
    "    output_key = \"result\",\n",
    "    output_parser = output_parser_json,\n",
    ")\n",
    "\n",
    "response = llm_chain_json_five_numbers.invoke(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2682eebf-2a1f-44b4-be4b-64713ad5809a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  {'number': 5, 'result': {'result': [{'word': 'Ephemeral', 'odd_number': 31}, {'word': 'Luncheon', 'odd_number': 39}, {'word': 'Treacle', 'odd_number': 17}, {'word': ' Whirlpool', 'odd_number': 41}, {'word': 'Lumberjack', 'odd_number': 29}]}}\n",
      "type:  <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print('result: ',response)\n",
    "print('type: ',type(response['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da0e32f-74a8-4c9f-9b93-91ee8eb9d6b6",
   "metadata": {},
   "source": [
    "## 5. Using PydanticOutputParser\n",
    "\n",
    "* Return type is object of specified class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1201b5b-6995-4a42-9e05-31a20ac12f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generate 5 pairs of random word and an odd numbers.\n",
      "the numbers should be between 5 and 50.\n",
      "\n",
      "Format instructions:\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"WordNumberCombo\": {\"properties\": {\"word\": {\"description\": \"this is a random word\", \"title\": \"Word\", \"type\": \"string\"}, \"odd_number\": {\"description\": \"this is an odd number between 5 and 50\", \"title\": \"Odd Number\", \"type\": \"integer\"}}, \"required\": [\"word\", \"odd_number\"], \"title\": \"WordNumberCombo\", \"type\": \"object\"}}, \"properties\": {\"result\": {\"items\": {\"$ref\": \"#/$defs/WordNumberCombo\"}, \"title\": \"Result\", \"type\": \"array\"}}, \"required\": [\"result\"]}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "template_3 = \"\"\"\n",
    "generate {number} pairs of random word and an odd numbers.\n",
    "the numbers should be between 5 and 50.\n",
    "\n",
    "Format instructions:\n",
    "{format_instructions}\n",
    "\"\"\" \n",
    "\n",
    "# Create the class to represent the word-number pair\n",
    "class WordNumberCombo(BaseModel):\n",
    "    word: str = Field(description=\"this is a random word\")\n",
    "    odd_number: int = Field(description=\"this is an odd number between 5 and 50\")\n",
    "\n",
    "# Create the actual class for output. Its a list of word-number pairs\n",
    "class ArrayWordNumberCombo(BaseModel):\n",
    "    result: list[WordNumberCombo]\n",
    "    \n",
    "output_parser_pydantic = PydanticOutputParser(pydantic_object=ArrayWordNumberCombo)\n",
    "\n",
    "# Create the prompt template\n",
    "# Partial variables can be passed at the time of template creation\n",
    "prompt_template_pydantic = PromptTemplate(\n",
    "    template = template_3,\n",
    "    input_variables = [\"number\",],\n",
    "    partial_variables = {\"format_instructions\": output_parser_pydantic.get_format_instructions()}\n",
    ")\n",
    "\n",
    "print(prompt_template_pydantic.format(number=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "835cea02-2407-4cee-b53c-5d0d427e6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLM Chain\n",
    "llm_chain_pydantic_five_numbers = LLMChain(\n",
    "    prompt = prompt_template_pydantic,\n",
    "    llm = llm,\n",
    "    output_key = 'result',\n",
    "    output_parser = output_parser_pydantic\n",
    ")\n",
    "\n",
    "response = llm_chain_pydantic_five_numbers.invoke(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f7dd4da-2904-46c6-853a-95c02aeea3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result=[WordNumberCombo(word='intent', odd_number=47), WordNumberCombo(word='velocity', odd_number=39), WordNumberCombo(word='articulate', odd_number=17), WordNumberCombo(word='fetish', odd_number=41), WordNumberCombo(word='ecliptic', odd_number=29)]\n",
      "type:  <class '__main__.ArrayWordNumberCombo'>\n"
     ]
    }
   ],
   "source": [
    "print(response['result'])\n",
    "print('type: ',type(response['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150bbb39-3f1d-4c18-9963-2038c37e7a47",
   "metadata": {},
   "source": [
    "## 6. StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d285914a-141f-48a9-aeb4-490ac5807e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "906decbe-d189-4b1b-b157-c76a10418d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"answer to the user's question\"),\n",
    "    ResponseSchema(\n",
    "        name=\"source\",\n",
    "        description=\"source used to answer the user's question, should be a website.\",\n",
    "    ),\n",
    "]\n",
    "output_parser_structured = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04ed0dd3-21a3-488f-84f0-4ae9d1a651ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser_structured.get_format_instructions()\n",
    "prompt_template_structured = PromptTemplate(\n",
    "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c181afe1-d352-4d04-9948-2d54f1166ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer the users question as best as possible.\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"answer\": string  // answer to the user's question\n",
      "\t\"source\": string  // source used to answer the user's question, should be a website.\n",
      "}\n",
      "```\n",
      "where is paris?\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template_structured.format(question=\"where is paris?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2b8a0fb-d445-4934-b944-d8e9aa3becb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLM Chain\n",
    "# llm_chain_structured = LLMChain(\n",
    "#     prompt = prompt_template_4,\n",
    "#     llm = llm,\n",
    "#     output_key = 'result',\n",
    "#     output_parser = output_parser_structured\n",
    "# )\n",
    "\n",
    "# Use LCEL notation to create the chain\n",
    "chain = prompt_template_structured | llm | output_parser_structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa24bd3b-f78f-4f3c-a20f-708408c270bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"question\":\"where is paris?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecc29ecf-b41c-4807-ba60-55aef56ba82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '48.85341', 'source': 'https://www.openstreetmap.org/place/Paris'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e8e58c4-e12d-4f64-93cf-a71a242df7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  {'answer': '48.85341', 'source': 'https://www.openstreetmap.org/place/Paris'}\n",
      "type:  <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print('result: ',response)\n",
    "print('type: ',type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37826fad-e7af-4bdc-a2c8-1ea75f066418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
