{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a2f573-58fc-495a-8779-0c13b2276b2a",
   "metadata": {},
   "source": [
    "# Create multi-label toxicity dataset\n",
    "\n",
    "\n",
    "\n",
    "### Source of Parquet file?\n",
    "SQL used for downloading the data from:\n",
    "\n",
    "https://huggingface.co/datasets/acloudfan/toxicity-multi-label-classifier\n",
    "\n",
    "The SQL statements are shown in cells below.\n",
    "\n",
    "PS: Deliberately removed the rows that have *obscene*=1\n",
    "\n",
    "**Original dataset:** from which this dataset was created\n",
    "https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cbbb11b-1337-4b7f-96ee-4e0c7d27eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the parquet file into a pandas DataFrame\n",
    "parquet_file_train = \"./toxicity-classifier/multi_label_comment_classification_train.parquet\"\n",
    "parquet_file_validation = \"./toxicity-classifier/multi_label_comment_classification_validation.parquet\"\n",
    "parquet_file_test = \"./toxicity-classifier/multi_label_comment_classification_test.parquet\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a36640-0711-45ea-bdf7-60ac2f6fc4d3",
   "metadata": {},
   "source": [
    "## Cohere dataset\n",
    "\n",
    "**Requirements :** https://docs.cohere.com/docs/classify-preparing-the-data\n",
    "\n",
    "* Used the code below to convert the dataset from Parquet to JSONL format\n",
    "* Renamed the attributes, as per Cohere's multi-label dataset requirement\n",
    "* Converts Parquet to JSONL\n",
    "* Split the dataset into (Training, Validation & Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96fedb7e-461c-4c88-bf25-31bcfe2c6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of labels to check\n",
    "label_columns = [\"toxic\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# Function to process each row\n",
    "def generate_output_cohere(row):\n",
    "       \n",
    "    # Extract the comment text\n",
    "    text = row['comment_text']\n",
    "    \n",
    "    # Create a list of labels where the value is 1\n",
    "    labels = [label for label in label_columns if row[label] == 1]\n",
    "    \n",
    "    # Format as desired output\n",
    "    return {\"text\": text, \"label\": labels}\n",
    "\n",
    "def read_parquet_generate_jsonl_cohere(parquet_file, output_file):\n",
    "    # Generate the training set\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    output_df = df.apply(generate_output_cohere, axis=1)\n",
    "    # output = output_df.to_list()\n",
    "\n",
    "    # Convert the DataFrame to a JSONL file (one JSON object per line)\n",
    "    \n",
    "    output_df.to_json(output_file, orient='records', lines=True)\n",
    "\n",
    "    print(f\"Successfully converted {parquet_file_train} to {output_file}\")\n",
    "\n",
    "# Print the output in the desired format\n",
    "# for entry in output:\n",
    "#     print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8334b2f-7047-4ae7-b3c8-2ac1a8eca3bb",
   "metadata": {},
   "source": [
    "#### Training set\n",
    "\n",
    "* Run the following against the **train** set\n",
    "* Download the parquet file\n",
    "* Rename file to : multi_label_comment_classification_train.parquet\n",
    "\n",
    "**HuggingFace SQL console :**\n",
    "https://huggingface.co/blog/sql-console\n",
    "\n",
    "```\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate FROM (\n",
    " SELECT * FROM train  \n",
    " where obscene=0 AND toxic=0 AND severe_toxic=0 AND threat=0 AND insult=0 AND identity_hate=0   LIMIT 20\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM train  where obscene=0 and toxic=1 LIMIT 20\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic,  threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM train  where obscene=0 and threat=1 LIMIT 20\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM train  where obscene=0 and identity_hate=1 LIMIT 20\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM train  where obscene=0 and insult=1 LIMIT 20\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac315845-dfc5-454f-b30d-2fd2610457a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted ./toxicity-classifier/multi_label_comment_classification_train.parquet to ./toxicity-classifier/multi_label_comment_classification_train_cohere.jsonl\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_train = \"./toxicity-classifier/multi_label_comment_classification_train_cohere.jsonl\"\n",
    "read_parquet_generate_jsonl_cohere(parquet_file_train, jsonl_file_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f602fe6-870e-4335-9400-a47cf7e2ddc1",
   "metadata": {},
   "source": [
    "#### Validation\n",
    "\n",
    "* Run the following against the **test** set\n",
    "* Download the parquet file\n",
    "* Rename file to : multi_label_comment_classification_test.parquet\n",
    "\n",
    "```\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate FROM (\n",
    " SELECT * FROM validation  \n",
    " where obscene=0 AND toxic=0 AND severe_toxic=0 AND threat=0 AND insult=0 AND identity_hate=0   LIMIT 8\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM validation  where obscene=0 and toxic=1 LIMIT 8\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic,  threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM validation  where obscene=0 and threat=1 LIMIT 8\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM validation  where obscene=0 and identity_hate=1 LIMIT 8\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM validation  where obscene=0 and insult=1 LIMIT 8\n",
    ");\n",
    "```5\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "133ff967-cf81-4b97-acce-45dff00c196e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted ./toxicity-classifier/multi_label_comment_classification_train.parquet to ./toxicity-classifier/multi_label_comment_classification_validation_cohere.jsonl\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_validation = \"./toxicity-classifier/multi_label_comment_classification_validation_cohere.jsonl\"\n",
    "read_parquet_generate_jsonl_cohere(parquet_file_validation, jsonl_file_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed89ea-36e4-4ef6-9ac4-f43c13dd1e1d",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n",
    "* Run the following against the **test** set\n",
    "* Download the parquet file\n",
    "* Rename file to : multi_label_comment_classification_test.parquet\n",
    "  \n",
    "```\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate FROM (\n",
    " SELECT * FROM test  \n",
    " where obscene=0 AND toxic=0 AND severe_toxic=0 AND threat=0 AND insult=0 AND identity_hate=0   LIMIT 8\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM test  where obscene=0 and toxic=1 LIMIT 8\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic,  threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM test  where obscene=0 and threat=1 LIMIT 8\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM test  where obscene=0 and identity_hate=1 LIMIT 8\n",
    ")\n",
    "UNION\n",
    "SELECT comment_text, toxic, threat, insult, identity_hate  FROM (\n",
    "   SELECT * FROM test  where obscene=0 and insult=1 LIMIT 8\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6a7f735-c9c6-4c6e-b78b-b99e19e091ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted ./toxicity-classifier/multi_label_comment_classification_train.parquet to ./toxicity-classifier/multi_label_comment_classification_test_cohere.jsonl\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_test = \"./toxicity-classifier/multi_label_comment_classification_test_cohere.jsonl\"\n",
    "read_parquet_generate_jsonl_cohere(parquet_file_test, jsonl_file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe2941-7837-4c25-b441-00894220d248",
   "metadata": {},
   "source": [
    "## OpenAI GPT \n",
    "\n",
    "**Requirements :** https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset\n",
    "\n",
    "* Requires the dataset to be in chat message format\n",
    "* For non-chat use cases such as classification, use single-turn format with 3 messages [\"system\", \"user\", \"assistant\"]\n",
    "  e.g.,\n",
    "\n",
    "```\n",
    "{\n",
    "  \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, \n",
    "                {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, \n",
    "                {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\"}\n",
    "              ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30116b69-e790-4401-85f0-eed1d619dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of labels to check\n",
    "label_columns = [\"toxic\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# Function to process each row\n",
    "def generate_output_openai(row):\n",
    "       \n",
    "    # Extract the comment text\n",
    "    text = row['comment_text']\n",
    "    \n",
    "    # Create a list of labels where the value is 1\n",
    "    labels = [label for label in label_columns if row[label] == 1]\n",
    "\n",
    "    system_message = \"you will categorize the user's input into one or more categories: \"+str([\"toxic\", \"severe_toxic\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "\n",
    "    # The output must be in string format i.e., can't be array so use json.dumps to convert to \n",
    "    json_l = {\n",
    "        \"messages\":[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_message\n",
    "            },{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            },{\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": json.dumps(labels)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Format as desired output\n",
    "    # return json.dumps(json_l)\n",
    "    return json_l\n",
    "\n",
    "\n",
    "def read_parquet_generate_jsonl_openai(parquet_file, output_file):\n",
    "    # Generate the training set\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    output_df = df.apply(generate_output_openai, axis=1)\n",
    "    # output = output_df.to_list()\n",
    "\n",
    "    # Convert the DataFrame to a JSONL file (one JSON object per line)\n",
    "    \n",
    "    output_df.to_json(output_file, orient='records', lines=True)\n",
    "\n",
    "    print(f\"Successfully converted {parquet_file_train} to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e40d3-3ab5-40a0-9317-0553632d85a9",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68665ebd-911b-4762-a615-bb9e08d3133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted ./toxicity-classifier/multi_label_comment_classification_train.parquet to ./toxicity-classifier/multi_label_comment_classification_train_openai.jsonl\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_train = \"./toxicity-classifier/multi_label_comment_classification_train_openai.jsonl\"\n",
    "read_parquet_generate_jsonl_openai(parquet_file_train, jsonl_file_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6448e70-bffe-430b-9e2f-3231934aedb8",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "176af69f-0f6b-4c79-b2ea-4a48197024a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted ./toxicity-classifier/multi_label_comment_classification_train.parquet to ./toxicity-classifier/multi_label_comment_classification_validation_openai.jsonl\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_validation = \"./toxicity-classifier/multi_label_comment_classification_validation_openai.jsonl\"\n",
    "read_parquet_generate_jsonl_openai(parquet_file_validation, jsonl_file_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d804797-2f1f-42b9-b861-841fc8207532",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "716b384d-8060-496a-a554-580a16bcfa53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted ./toxicity-classifier/multi_label_comment_classification_train.parquet to ./toxicity-classifier/multi_label_comment_classification_test_openai.jsonl\n"
     ]
    }
   ],
   "source": [
    "jsonl_file_test = \"./toxicity-classifier/multi_label_comment_classification_test_openai.jsonl\"\n",
    "read_parquet_generate_jsonl_openai(parquet_file_test, jsonl_file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e33573-8023-4eff-b0af-b6d30c77c7e4",
   "metadata": {},
   "source": [
    "# HF Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd0a27c-aa0c-4aa9-afb2-a9d2cbe36907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bfa0b38-90d0-4e52-9b6a-ca194c91690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd98cbd50984864854391f447a9f69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e1fcce31f7402697e41b453c494dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3679a31ca3c544e7a0591071d5dd2025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951c60e02dc44ef8a4cce05b2ccb3116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19577fbbe1e4ed599eb1b0095a97d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"parquet\", data_files={'train': parquet_file_train, 'validation': parquet_file_validation, 'test': parquet_file_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d9cb7b1-78a6-4d0c-8ef8-80d4395ef9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0118310a25c44ce9d657b8ca339a917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d47201e659412db50da74c2cbf2744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db34fca7ef44d65906c914a88db8fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9dc4bfd4f94bbd97316954db35fb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07733e7d2c034f2f97919e9f2d1159ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c51691861a4568aec01fb29cfe9c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'HfApi' object has no attribute 'list_files_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Load the file that contains the API keys\u001b[39;00m\n\u001b[0;32m     15\u001b[0m load_dotenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mraj\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m.jupyter\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m.env\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m dataset\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macloudfan/toxicity-multi-label-classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen-ai-app-dev-course\\Lib\\site-packages\\datasets\\dataset_dict.py:1710\u001b[0m, in \u001b[0;36mDatasetDict.push_to_hub\u001b[1;34m(self, repo_id, config_name, commit_message, private, token, revision, branch, create_pr, max_shard_size, num_shards, embed_external_files)\u001b[0m\n\u001b[0;32m   1708\u001b[0m deletions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1709\u001b[0m repo_files_to_add \u001b[38;5;241m=\u001b[39m [addition\u001b[38;5;241m.\u001b[39mpath_in_repo \u001b[38;5;28;01mfor\u001b[39;00m addition \u001b[38;5;129;01min\u001b[39;00m additions]\n\u001b[1;32m-> 1710\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m repo_file \u001b[38;5;129;01min\u001b[39;00m api\u001b[38;5;241m.\u001b[39mlist_files_info(repo_id, revision\u001b[38;5;241m=\u001b[39mrevision, repo_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, token\u001b[38;5;241m=\u001b[39mtoken):\n\u001b[0;32m   1711\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m repo_file\u001b[38;5;241m.\u001b[39mrfilename \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1712\u001b[0m         repo_with_dataset_card \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HfApi' object has no attribute 'list_files_info'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Setting path so we can access the utils folder\n",
    "sys.path.append('../')\n",
    "sys.path.append('./')\n",
    "\n",
    "from IPython.display import Markdown, JSON\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the file that contains the API keys\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')\n",
    "\n",
    "\n",
    "dataset.push_to_hub(\"acloudfan/toxicity-multi-label-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b3a56-cbf0-4b2f-9b70-180794227c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
