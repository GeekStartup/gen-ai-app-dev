{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29ce844",
   "metadata": {},
   "source": [
    "# PyTorch fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5acee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa157c4",
   "metadata": {},
   "source": [
    "## Create Tensor\n",
    "https://pytorch.org/docs/stable/torch.html#creation-ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8402ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50519c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3, 2],\n",
      "        [6, 4, 5],\n",
      "        [5, 8, 7]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Empty tensor\n",
    "t_empty = torch.empty(2,2)\n",
    "t_rand = torch.rand(2,2)\n",
    "t_zeros = torch.zeros(2,2)\n",
    "t_ones = torch.ones(2,2)\n",
    "\n",
    "# Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.\n",
    "t_eyes = torch.eye(3,3)\n",
    "\n",
    "# Specify the data type for the tensor elements\n",
    "t_full = torch.full((2,2), 34, dtype=torch.float)\n",
    "\n",
    "t_multi_dim = torch.tensor([[1,3,2], [6,4,5], [5,8,7]])\n",
    "\n",
    "# Print the tensors of your interest\n",
    "print(t_multi_dim)\n",
    "print(t_multi_dim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18a8e8f",
   "metadata": {},
   "source": [
    "# Common Tensor Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252db5b6",
   "metadata": {},
   "source": [
    "## torch.argmax() function\n",
    "\n",
    "Index of maximum value\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.argmax.html#torch.argmax\n",
    "\n",
    "**torch.argmin()** does the opposite\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.argmin.html#torch.argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e137e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of maximum value: tensor(2)\n",
      "Value:  tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.tensor([4, 1, 5, 3, 2])\n",
    "\n",
    "# Find the index of the maximum value\n",
    "max_index = torch.argmax(tensor)\n",
    "\n",
    "print(\"Index of maximum value:\", max_index)  # Output: tensor(2)\n",
    "print(\"Value: \", tensor[max_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcec58b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_index = torch.argmax(t_multi_dim, dim=-1)\n",
    "max_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6a121",
   "metadata": {},
   "source": [
    "## torch.topk() function\n",
    "\n",
    "Returns the k largest elements of the given input tensor along a given dimension\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.topk.html#torch.topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8918f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 values: tensor([5, 4, 3])\n",
      "Top 3 indices: tensor([0, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.tensor([5, 1, 4, 2, 3])\n",
    "\n",
    "# Get the 3 largest elements and their indices\n",
    "top_k_values, top_k_indices = torch.topk(tensor, k=3)\n",
    "\n",
    "print(\"Top 3 values:\", top_k_values)   # Output: tensor([5, 4, 3])\n",
    "print(\"Top 3 indices:\", top_k_indices)  # Output: tensor([0, 2, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f81bd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 values in each row: tensor([[6, 4],\n",
      "        [5, 3],\n",
      "        [9, 8]])\n",
      "Top 2 indices in each row: tensor([[2, 0],\n",
      "        [2, 1],\n",
      "        [2, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D tensor\n",
    "tensor = torch.tensor([[4, 2, 6], [1, 3, 5], [7, 8, 9]])\n",
    "\n",
    "# Get the top 2 values and indices along each row (dim=1)\n",
    "top_k_values, top_k_indices = torch.topk(tensor, k=2, dim=1)\n",
    "\n",
    "print(\"Top 2 values in each row:\", top_k_values)   # Output: tensor([[6, 4], [5, 3], [9, 8]])\n",
    "print(\"Top 2 indices in each row:\", top_k_indices)  # Output: tensor([[2, 0], [2, 1], [0, 1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013a9d7e",
   "metadata": {},
   "source": [
    "# Common NN Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b8c7d",
   "metadata": {},
   "source": [
    "## nn.softmax()\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax\n",
    "\n",
    "It is a mathematical function that transforms a tensor of real numbers into a probability distribution. It is often used to normalize the neural networkâ€™s output so that the sum of all outputs is equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ba8995b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: tensor([0.0900, 0.2447, 0.6652])\n",
      "Sum of all probabilities: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of model output\n",
    "logits = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# Apply softmax function\n",
    "probabilities = nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "print(\"Probabilities:\", probabilities)  # Output: tensor([0.1192, 0.2712, 0.6096])\n",
    "print(\"Sum of all probabilities:\", torch.sum(probabilities)) # Output : 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec2f9b",
   "metadata": {},
   "source": [
    "# Gradients\n",
    "\n",
    "By default gradients are not calculated. In order to automatically calculate the gradients, set the requires_grad=True\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c057034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([32.2])\n",
    "\n",
    "print(tensor.requires_grad)\n",
    "\n",
    "tensor = torch.tensor([32.2], requires_grad=True)\n",
    "\n",
    "print(tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4efc210",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21my_func\u001b[39m(x):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m*\u001b[39m(x\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m*\u001b[39m(x\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m7.0\u001b[39m,\u001b[38;5;241m300.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m), requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(x))\n\u001b[0;32m     10\u001b[0m y \u001b[38;5;241m=\u001b[39m y_func(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def y_func(x):\n",
    "    return x*(x-3)*(x-7)\n",
    "\n",
    "x = torch.tensor(np.arange(7.0,300.0, 2.0), requires_grad=True)\n",
    "\n",
    "print(type(x))\n",
    "\n",
    "y = y_func(x)\n",
    "\n",
    "print(type(y))\n",
    "\n",
    "gradient= torch.empty(x.shape[0]).fill_(1.0)\n",
    "\n",
    "dy = torch.tensor(y,requires_grad=True).backward(gradient=gradient)\n",
    "\n",
    "print(dy)\n",
    "# plt.plot(x,y)\n",
    "# plt.plot(x,dy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff9c095",
   "metadata": {},
   "source": [
    "# Tensor maths\n",
    "\n",
    "https://pytorch.org/docs/stable/torch.html#math-operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f80425e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtract 1 :  tensor([[0, 1, 2],\n",
      "        [2, 3, 4],\n",
      "        [4, 5, 6]])\n",
      "multiple by 2 :  tensor([[ 2,  4,  6],\n",
      "        [ 6,  8, 10],\n",
      "        [10, 12, 14]])\n"
     ]
    }
   ],
   "source": [
    "t_test = torch.tensor([[1,2,3], [3,4,5], [5,6,7]])\n",
    "\n",
    "# Crteate a new tensor by subtracting 1 from each element\n",
    "print('subtract 1 : ', t_test - 1)\n",
    "\n",
    "print('multiple by 2 : ', t_test * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d02e9dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 10],\n",
       "        [15, 22],\n",
       "        [23, 34]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product operator\n",
    "# i.e., matrix multiplacation\n",
    "\n",
    "t_1 = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "t_2 = torch.tensor([[1,2],[3,4]])\n",
    "\n",
    "print(t_1)\n",
    "print(t_2)\n",
    "\n",
    "t_1 @ t_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b041daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index of the element for which val = max value in tensor\n",
    "torch.tensor([1,2,9,4,5,6,7]).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dfbd4c",
   "metadata": {},
   "source": [
    "# Create NN\n",
    "\n",
    "- forward method does the computation\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4af3938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7f08fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "# Input feature tensor size = 2, Output feature tensor size = 3\n",
    "layer_1 = nn.Linear(2,3)\n",
    "activation_1 = nn.ReLU()\n",
    "\n",
    "layer_2 = nn.Linear(3,2)\n",
    "activation_2 = nn.ReLU()\n",
    "\n",
    "model = nn.Sequential(\n",
    "    layer_1,\n",
    "    activation_1,\n",
    "    layer_2,\n",
    "    activation_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3925d141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: Sequential(\n",
      "  (0): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (3): ReLU()\n",
      ")\n",
      "\n",
      "\n",
      "Layer: 0.weight | Size: torch.Size([3, 2]) | Values : tensor([[ 0.3293,  0.6854],\n",
      "        [-0.3402, -0.3223]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 0.bias | Size: torch.Size([3]) | Values : tensor([-0.5806, -0.6471], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.weight | Size: torch.Size([2, 3]) | Values : tensor([[-0.2085,  0.5761,  0.4243],\n",
      "        [-0.1109, -0.3793,  0.3125]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.bias | Size: torch.Size([2]) | Values : tensor([-0.4078, -0.3010], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e36287b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1.0,2.0], [1.0,2.0], [1.0,2.0]])\n",
    "\n",
    "x = torch.rand(3,2)\n",
    "\n",
    "output = model(x)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6866317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
