{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77e97a9-c69f-48c1-935a-a1ec042e0710",
   "metadata": {},
   "source": [
    "# 1. Install the Hugging Face hub library\n",
    "\n",
    "This will use the model hosting on the Hugging Face portal\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c20fa5-e38f-4186-92fc-1ed44a3669ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch huggingface_hub -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0646c5-c3d8-480f-94a4-4813698c0cd0",
   "metadata": {},
   "source": [
    "# 2. Create the Inference Client\n",
    "\n",
    "Client will use the model hosted on the Hugging Face portal\n",
    "\n",
    "**Class**\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/v0.20.2/en/package_reference/inference_client#huggingface_hub.InferenceClient\n",
    "\n",
    "**Supported tasks**\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/guides/inference#supported-tasks\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "Sometimes API calls fail due to heavy usage of the model on HF. If you get a invocation error, try a again!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e13cd822-17d7-479e-94f2-069b930ff31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1b77e9d-a55e-48a7-9954-eccb6e621050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# REPLACE THE KEY with your own key\n",
    "HUGGINGFACEHUB_API_TOKEN = \"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\"\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "client = InferenceClient(model=model_name, token=HUGGINGFACEHUB_API_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46463e2f-e8cb-4350-bd05-c1c69947700b",
   "metadata": {},
   "source": [
    "# 3. List deployed models\n",
    "\n",
    "Returns a subset of models for the specified framework\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/package_reference/inference_client#huggingface_hub.InferenceClient.list_deployed_models\n",
    "\n",
    "**Note:**\n",
    "\n",
    "An invalid framework throws an HTTP error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07679d24-0152-444f-a50a-530eed6b016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text2text-generation': ['google/flan-t5-xxl', 'google/flan-ul2'], 'text-generation': ['bigcode/starcoder', 'bigscience/bloom', 'codellama/CodeLlama-13b-hf', 'codellama/CodeLlama-34b-Instruct-hf', 'HuggingFaceH4/starchat-beta', 'HuggingFaceH4/zephyr-7b-alpha', 'HuggingFaceH4/zephyr-7b-beta', 'HuggingFaceM4/idefics-80b-instruct', 'mistralai/Mistral-7B-Instruct-v0.1', 'mistralai/Mistral-7B-Instruct-v0.2', 'mistralai/Mistral-7B-v0.1', 'openchat/openchat-3.5-0106', 'TheBloke/vicuna-7B-v1.5-GPTQ', 'tiiuae/falcon-7b-instruct']}\n"
     ]
    }
   ],
   "source": [
    "# For a specific framework\n",
    "framework = \"text-generation-inference\"  # \"text-to-speech\", \n",
    "deployed_models = client.list_deployed_models([framework])\n",
    "print(deployed_models)\n",
    "\n",
    "## Get all the deploymed models\n",
    "# deployed_models = client.list_deployed_models(\"all\")\n",
    "# print(deployed_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf44f9b7-65d6-48d4-a5e1-c8c70f687043",
   "metadata": {},
   "source": [
    "# 4. Check if a specific model is available as endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a478624-1a3a-4ff2-a1e4-5e74baa07dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelStatus(loaded=False, state='Loadable', compute_type='cpu', framework='transformers')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "client.get_model_status(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c6875-8c8f-495a-9a58-18b56654507a",
   "metadata": {},
   "source": [
    "# 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1194eea8-5bec-41f6-b762-cb6da0eb429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 74.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998492002487183},\n",
       " {'label': 'NEGATIVE', 'score': 0.00015075372357387096}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = \"I loved the restaurant\"\n",
    "\n",
    "client.text_classification(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "716c73ce-9c6f-4808-9e00-7cd0ab6e3683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 61.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9996846914291382},\n",
       " {'label': 'POSITIVE', 'score': 0.00031535723246634007}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = \"i hated it\"\n",
    "\n",
    "client.text_classification(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638673a-14a1-4ea9-bdea-910addf0dfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
