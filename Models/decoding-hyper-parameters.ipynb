{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fb38ab-b2ff-4b34-a1ee-4a551c3fae87",
   "metadata": {},
   "source": [
    "# Decoding hyperparameters\n",
    "\n",
    "Mistral\n",
    "\n",
    "https://docs.mistral.ai/deployment/self-deployment/cerebrium/#setup-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510db8b-cf98-4e29-b55f-b048bed5c29c",
   "metadata": {},
   "source": [
    "## Google Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd07c5-d61e-4204-82d6-5569251f0daa",
   "metadata": {},
   "source": [
    "#### 1. Set Google API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbfef115-db96-4c0f-9d39-0524e44a82f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import GenerationConfig, GenerativeModel\n",
    "\n",
    "google_api_key = getpass.getpass()\n",
    "\n",
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c537e-47a9-42c6-a068-ccf6ddcc28ef",
   "metadata": {},
   "source": [
    "#### 2. Create LLM client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de88f4bf-ad5c-4d0b-988b-ab6662617bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/gemini-1.5-flash',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n"
     ]
    }
   ],
   "source": [
    "model = \"gemini-1.5-flash\"\n",
    "\n",
    "# Defaults\n",
    "print(genai.get_model(name=\"models/\"+model))\n",
    "\n",
    "# Create the model with default parameter set values\n",
    "llm = GenerativeModel(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97c33d7-4874-4c44-af30-1ff09ef0ea57",
   "metadata": {},
   "source": [
    "#### 3. Run a query with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12e9c6ee-e20d-4951-9730-6c9fff922c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## LLM in a Nutshell: \n",
      "\n",
      "LLM stands for **Large Language Model**. Think of it as a super-powered computer program that can understand and generate human-like text. \n",
      "\n",
      "**Here's the breakdown:**\n",
      "\n",
      "* **Large:** LLMs are trained on massive amounts of text data, like books, articles, and websites. This lets them learn complex patterns and relationships in language.\n",
      "* **Language:** They specialize in understanding and manipulating language, including grammar, vocabulary, and meaning. \n",
      "* **Model:** It's like a mathematical formula that can predict the next word in a sentence or generate completely new text.\n",
      "\n",
      "**What can LLMs do?**\n",
      "\n",
      "* **Summarize text:** Extract key information from long documents.\n",
      "* **Translate languages:** Convert text from one language to another.\n",
      "* **Write different types of text:** Compose stories, poems, emails, code, and even musical pieces.\n",
      "* **Answer questions:** Provide informative answers based on the information they've learned.\n",
      "* **Have conversations:** Engage in natural-sounding dialogues with humans.\n",
      "\n",
      "**Examples of LLMs:**\n",
      "\n",
      "* **GPT-3 (Generative Pre-trained Transformer 3)** by OpenAI\n",
      "* **LaMDA (Language Model for Dialogue Applications)** by Google\n",
      "* **BERT (Bidirectional Encoder Representations from Transformers)** by Google\n",
      "\n",
      "**Think of LLMs as the next step in AI evolution.** They are revolutionizing how we interact with computers and are opening up new possibilities for creativity and productivity. \n",
      "\n",
      "1445\n"
     ]
    }
   ],
   "source": [
    "query = \"Explain LLM briefly\"\n",
    "\n",
    "response = llm.generate_content([query]) #, generation_config=generation_config)\n",
    "\n",
    "# Extract the content from the response\n",
    "response_text = response.candidates[0].content.parts[0].text\n",
    "\n",
    "print(response_text)\n",
    "print(len(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95275df4-67c9-48c6-9471-5e12e35807ea",
   "metadata": {},
   "source": [
    "#### 4. Try query with differnt decoding parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec21911-bd9a-4137-a559-4948a3e26799",
   "metadata": {},
   "source": [
    "#### Test 1 :  **max_output_tokens**,  **stop_sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97cd161f-d649-4a21-96df-ef2fe742d062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## LLM in a Nutshell:\n",
      "\n",
      "\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "# Set the parameters and \n",
    "generation_config = GenerationConfig( \n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    "    top_k=None,\n",
    "    max_output_tokens=20,\n",
    "    stop_sequences=None   #[\"**\", \"/n/n\"]\n",
    ")\n",
    "\n",
    "# Generate a response\n",
    "response = llm.generate_content([query], generation_config=generation_config)\n",
    "\n",
    "# Extract the content from the response\n",
    "response_text = response.candidates[0].content.parts[0].text\n",
    "\n",
    "# Print the results\n",
    "print(response_text)\n",
    "print(len(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62acb8-47e7-4eef-aa2c-b448eb204723",
   "metadata": {},
   "source": [
    "#### Test 2 :  **temperature**,  **top_p**, **top_k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07807f87-5d78-40fd-9697-2424adea0d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LLM) is a type of artificial intelligence that excels at understanding and generating human-like text. These models are trained on vast amounts of data, allowing them to learn patterns and relationships within language. LLMs can perform various tasks, including writing different creative text formats, translating languages, and answering your questions in an informative way. They are still under development, but have shown great potential in numerous applications. While impressive, LLMs are not sentient and should not be mistaken for human intelligence. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"describe an LLM with 5 sentences\"\n",
    "\n",
    "# Switch to defaults\n",
    "generation_config = GenerationConfig( \n",
    "    temperature=None,\n",
    "    top_p=None,\n",
    "    top_k=None,\n",
    "    max_output_tokens=None,\n",
    "    stop_sequences=None\n",
    ")\n",
    "\n",
    "llm = GenerativeModel(model,generation_config=generation_config)\n",
    "\n",
    "# print response with defaults\n",
    "response = llm.generate_content([query])\n",
    "response_text = response.candidates[0].content.parts[0].text\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54a9a815-f4d5-44f4-8afc-f24e67132507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A large language model (LLM) is a type of artificial intelligence trained on massive datasets of text and code. LLMs can generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way. They use deep learning techniques to understand the relationships between words and phrases, allowing them to communicate and generate human-like text. While impressive, LLMs are still under development and can sometimes produce inaccurate or biased information. However, their potential applications in various fields, such as education, healthcare, and customer service, are vast. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_config = GenerationConfig( \n",
    "    temperature=2.0,\n",
    "    top_p=0.9,\n",
    "    top_k=100\n",
    ")\n",
    "\n",
    "# print response with defaults\n",
    "response = llm.generate_content([query],generation_config=generation_config)\n",
    "response_text = response.candidates[0].content.parts[0].text\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5862a58c-87b6-4504-a744-fe0114d5ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
