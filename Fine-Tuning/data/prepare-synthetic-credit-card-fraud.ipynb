{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbb92547-96f2-4509-9c1d-f904e030639b",
   "metadata": {},
   "source": [
    "# Synthetic data generation\n",
    "\n",
    "In this exercise you would generate synthetic data for \"credit card fraud detection\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a26c2-f4c4-4d55-9171-6a3a3ab01ea7",
   "metadata": {},
   "source": [
    "### Part-1 Use an LLM to generate the synthetic data\n",
    "\n",
    "Use the instructions available in the section **Fine-Tuning/Project..** in the course guide. Refer to Part-1 for the prompt. At the end of part-1, you should have the following file under the folder for this notebook.\n",
    "\n",
    "**./synthetic-credit-card-fraud/credit-card-fraud-chatgpt.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362f1511-00bf-4c84-8ab9-3e173f224987",
   "metadata": {},
   "source": [
    "### Part-2 Pre-process data to JSON line format & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44847d2-bf33-44d0-b7a9-9fb1ec90c347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./synthetic-credit-card-fraud/credit-card-fraud-chatgpt-train.jsonl # of lines :  56\n",
      "./synthetic-credit-card-fraud/credit-card-fraud-chatgpt-validate.jsonl # of lines :  14\n",
      "./synthetic-credit-card-fraud/credit-card-fraud-chatgpt-test.jsonl # of lines :  14\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# This file has the synthetic data in JSON [ ] format\n",
    "j_file = \"./synthetic-credit-card-fraud/credit-card-fraud-chatgpt.json\"\n",
    "\n",
    "with open(j_file) as f:\n",
    "    dat = json.load(f)\n",
    "\n",
    "# JSON array is converted to json line format\n",
    "def  write_jsonl_file(dat_subset, file_name):\n",
    "    jsonl = \"\"\n",
    "    for rec in dat_subset:\n",
    "        jsonl = jsonl + json.dumps(rec) + \"\\n\"\n",
    "\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(jsonl)\n",
    "\n",
    "    print(file_name, \"# of lines : \", len(dat_subset))\n",
    "\n",
    "# Train - split\n",
    "output_file_prefix = \"./synthetic-credit-card-fraud/credit-card-fraud-chatgpt-\"\n",
    "file_name = output_file_prefix+\"train.jsonl\"\n",
    "write_jsonl_file(dat[0:56], file_name)\n",
    "\n",
    "# Validation - split\n",
    "file_name = output_file_prefix+\"validate.jsonl\"\n",
    "write_jsonl_file(dat[56:70], file_name)\n",
    "\n",
    "# Test - split\n",
    "file_name = output_file_prefix+\"test.jsonl\"\n",
    "write_jsonl_file(dat[70:], file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f6783-f19c-48d7-a2cb-ebd749f63e18",
   "metadata": {},
   "source": [
    "### Part-3 Check data distribution of training set\n",
    "\n",
    "#### Step-1 Check if dataset is balanced\n",
    "* Get the count of fraud & not_fraud records\n",
    "* Check if they are near about same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ae1315-ac4b-481b-b256-d1b604f2289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud labels :  35 %  \n",
      "Not_Fraud labels :  65 %  \n"
     ]
    }
   ],
   "source": [
    "# Get the counts for fraud & not_fraud examples\n",
    "training_file_name = \"./synthetic-credit-card-fraud/credit-card-fraud-chatgpt-train.jsonl\"\n",
    "\n",
    "# Count fraud vs not fraud examples in the training file\n",
    "def get_training_dataset_distribution(data_file_name):\n",
    "    fraud_count = 0\n",
    "    not_fraud_count = 0\n",
    "    with open(data_file_name) as f:\n",
    "        for line in f:\n",
    "            if json.loads(line)[\"transaction_label\"] == \"fraud\":\n",
    "                fraud_count = fraud_count + 1\n",
    "            else:\n",
    "                not_fraud_count = not_fraud_count + 1\n",
    "    \n",
    "    # Calculate % of examples labeled as Fraud\n",
    "    fraud_pct = int(fraud_count*100/(fraud_count + not_fraud_count))\n",
    "    \n",
    "    print(\"Fraud labels : \", fraud_pct, \"%  \")\n",
    "    print(\"Not_Fraud labels : \", (100-fraud_pct), \"%  \")\n",
    "\n",
    "    return fraud_count, not_fraud_count\n",
    "\n",
    "# Check the balance\n",
    "fraud_count, not_fraud_count = get_training_dataset_distribution(training_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945e5d16-8255-4ac5-9f49-aa6d4ea10f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation suggested. add examples for 'Fraud': 16\n"
     ]
    }
   ],
   "source": [
    "# Check number of additional examples to be generated\n",
    "if (fraud_count - not_fraud_count) > 0:\n",
    "    print(\"Augmentation suggested. add examples for 'Not Fraud':\", (fraud_count - not_fraud_count))\n",
    "elif (fraud_count - not_fraud_count) < 0:\n",
    "    print(\"Augmentation suggested. add examples for 'Fraud':\", (not_fraud_count - fraud_count))\n",
    "else:\n",
    "    print(\"Dataset is balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebd0a46-c4e6-4b78-a166-d6e54d6fee8b",
   "metadata": {},
   "source": [
    "#### Step-2 Generate suggested number of examples\n",
    "\n",
    "* Use earlier prompt to generate suggested number of records using ChatGPT (or other LLM)\n",
    "* Save the examples to a file : **credit-card-fraud-chatgpt-train-additional.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91775cb-f542-45e1-8830-61d6cefa5490",
   "metadata": {},
   "source": [
    "#### Step-3 Balance the training dataset\n",
    "\n",
    "* Convert the additional examples to JSON line format\n",
    "* Open the training dataset for 'append'\n",
    "* Append the additional examples to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b7db4e-8b51-4d50-a09a-b8a4c959fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of additional examples :  16\n"
     ]
    }
   ],
   "source": [
    "# JSON file with additional examples\n",
    "j_file_additional = './synthetic-credit-card-fraud/credit-card-fraud-chatgpt-train-additional.json'\n",
    "\n",
    "# Open the file and read the JSON array data\n",
    "with open(j_file_additional) as f:\n",
    "    additional_dat = json.load(f)\n",
    "\n",
    "# Print count of additional examples for validation\n",
    "print( \"# of additional examples : \", len(additional_dat))\n",
    "\n",
    "# Convert JSON array to JSON Line\n",
    "jsonl = \"\"\n",
    "for rec in additional_dat:\n",
    "    jsonl = jsonl + json.dumps(rec) + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ef077d-ea70-4a09-866a-912a7bf0bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the credit-card-fraud-chatgpt-train.json and append the augmentation examples to it\n",
    "training_file_name = \"./synthetic-credit-card-fraud/credit-card-fraud-chatgpt-train.jsonl\"\n",
    "\n",
    "with open(training_file_name) as training_file:\n",
    "    original_training_dat = training_file.read()\n",
    "\n",
    "output_train_file = './synthetic-credit-card-fraud/credit-card-fraud-chatgpt-train-augmented.jsonl'\n",
    "with open(output_train_file, \"w\") as f:\n",
    "    f.write(original_training_dat)\n",
    "    f.write(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60346d82-7997-41dc-b88c-09596b4ef7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud labels :  50 %  \n",
      "Not_Fraud labels :  50 %  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_training_dataset_distribution(output_train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e64e5-b45f-436f-8629-a5b55fc6ef52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
