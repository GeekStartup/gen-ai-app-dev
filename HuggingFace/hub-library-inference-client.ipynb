{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77e97a9-c69f-48c1-935a-a1ec042e0710",
   "metadata": {},
   "source": [
    "# 1. Install the Hugging Face hub library\n",
    "\n",
    "This will use the model hosting on the Hugging Face portal\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf5030-3905-4c7d-96ea-5e5075ba1174",
   "metadata": {},
   "source": [
    "### If using local machine - run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f721c591-03ab-4f9b-81ca-888dd5842871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4112101-cd0b-429a-811c-781fdb125f68",
   "metadata": {},
   "source": [
    "### On Google Collab - run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c20fa5-e38f-4186-92fc-1ed44a3669ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch huggingface_hub -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0646c5-c3d8-480f-94a4-4813698c0cd0",
   "metadata": {},
   "source": [
    "# 2. Create the Inference Client\n",
    "\n",
    "Client will use the model hosted on the Hugging Face portal\n",
    "\n",
    "**Class**\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/v0.20.2/en/package_reference/inference_client#huggingface_hub.InferenceClient\n",
    "\n",
    "**Supported tasks**\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/guides/inference#supported-tasks\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "Sometimes API calls fail due to heavy usage of the model on HF. If you get a invocation error, try a again!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e13cd822-17d7-479e-94f2-069b930ff31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy/paste HuggingFace token and hit <enter>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import getpass\n",
    "\n",
    "# You will prompted for the HuggingFace token\n",
    "print(\"Copy/paste HuggingFace token and hit <enter>\")\n",
    "HUGGINGFACEHUB_API_TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1b77e9d-a55e-48a7-9954-eccb6e621050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the model name if you would like to try out a different model\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Create the client\n",
    "client = InferenceClient(model=model_name, token=HUGGINGFACEHUB_API_TOKEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46463e2f-e8cb-4350-bd05-c1c69947700b",
   "metadata": {},
   "source": [
    "# 3. List deployed models\n",
    "\n",
    "Returns a subset of models for the specified framework\n",
    "\n",
    "https://huggingface.co/docs/huggingface_hub/package_reference/inference_client#huggingface_hub.InferenceClient.list_deployed_models\n",
    "\n",
    "### Note : Error \"Bad Request\"\n",
    "The HF backend is throwing an error on the list_deployed_models call as of 03/01/2025. Pease check the status at the following thread. \n",
    "Please continue with the course as this API is not critical but good to know.\n",
    "\n",
    "https://discuss.huggingface.co/t/huggingface-hub-client-giving-error-on-list-deployed-models/143678\n",
    "\n",
    "**Note:**\n",
    "\n",
    "An invalid framework throws an HTTP error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07679d24-0152-444f-a50a-530eed6b016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a specific framework\n",
    "framework = \"text-generation-inference\"  # \"text-to-speech\", \n",
    "deployed_models = client.list_deployed_models([framework])\n",
    "print(deployed_models)\n",
    "\n",
    "## Get all the deploymed models\n",
    "# client = InferenceClient(token=HUGGINGFACEHUB_API_TOKEN)\n",
    "# deployed_models = client.list_deployed_models(frameworks=\"all\")\n",
    "# print(deployed_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf44f9b7-65d6-48d4-a5e1-c8c70f687043",
   "metadata": {},
   "source": [
    "# 4. Check if a specific model is available as endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a478624-1a3a-4ff2-a1e4-5e74baa07dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "client.get_model_status(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c6875-8c8f-495a-9a58-18b56654507a",
   "metadata": {},
   "source": [
    "# 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1194eea8-5bec-41f6-b762-cb6da0eb429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 218 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TextClassificationOutputElement(label='POSITIVE', score=0.9998492002487183),\n",
       " TextClassificationOutputElement(label='NEGATIVE', score=0.00015075344708748162)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = \"I loved the restaurant\"\n",
    "\n",
    "client.text_classification(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "716c73ce-9c6f-4808-9e00-7cd0ab6e3683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 107 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TextClassificationOutputElement(label='NEGATIVE', score=0.9996846914291382),\n",
       " TextClassificationOutputElement(label='POSITIVE', score=0.00031535723246634007)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text = \"i hated it\"\n",
    "\n",
    "client.text_classification(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638673a-14a1-4ea9-bdea-910addf0dfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
