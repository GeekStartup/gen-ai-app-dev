{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ed7585-a502-4bbf-8483-0df5e6dfbed7",
   "metadata": {},
   "source": [
    "# Single step agent\n",
    "\n",
    "1. Setup prompt that asks an LLM to use provided tools or use tool responses to generate answers\n",
    "2. Setup the tools, descriptions\n",
    "3. **Single Step Agent**:\n",
    "   - Asks LLM to pick the tools to run\n",
    "   - Runs the tools\n",
    "   - Sends the tools responses to LLM to generate final answer\n",
    "4. Test setup\n",
    "\n",
    "Note:\n",
    "* Code uses the OpenAI GPT 3.5 turbo model\n",
    "* Code does not use Langchain Agent & Tool classes (covered later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2b1d8-251a-4b0a-b113-1d9bfca8b72b",
   "metadata": {},
   "source": [
    "## Setup LLM\n",
    "Same LLM will be used for planning & answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dcee5a3-230e-4d0f-a61b-bb7c3944acc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load the file that contains the API keys - OPENAI_API_KEY\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')\n",
    "\n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.create_chat_llm import create_gpt_chat_llm, create_cohere_chat_llm, create_anthropic_chat_llm, create_hugging_face_chat_llm\n",
    "\n",
    "# Try with GPT\n",
    "llm = create_gpt_chat_llm({\"temperature\":0.1})\n",
    "\n",
    "# model_name = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "# llm = create_hugging_face_chat_llm(repo_id=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f932d9-f0a0-4776-b96a-c52188884994",
   "metadata": {},
   "source": [
    "## 1. Setup the prompt\n",
    "\n",
    "* Review the code to understand how an LLM learns about th eavailable tool(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f862de3b-b134-4a0e-a4f9-8a41897fdc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tempplate\n",
    "template = \"\"\"\n",
    "You are a helpful assistant capable of answering questions on various topics. \n",
    "You must not use your internal knowledge or information to answer questions.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Think step-by-step to create a plan.\n",
    "Use only the following available tools to find information.\n",
    "Tools Available:\n",
    "\n",
    "{tools}\n",
    "Guidelines for Responses:\n",
    "\n",
    "Format 1: If the question cannot be answered with the available tools, use this format:\n",
    "{{\"answer\": \"No appropriate tool available\"}}\n",
    "\n",
    "Format 2: If you need to run tools to obtain the information, use this format:\n",
    "{{\"actions\": [{{ \"action\" : tool name, \"arguments\" : dictionary of argument values}}}}]\n",
    "\n",
    "Format 3: If you can answer the question using the responses from the tools, use this format:\n",
    "{{\"answer\": \"your response to the question\", \"explanation\": \"provide your explanation here\"}}\n",
    "\n",
    "\n",
    "Avoid any preamble; respond directly using one of the specified JSON formats.\n",
    "Question:\n",
    "\n",
    "{question}\n",
    "Tool Responses:\n",
    "\n",
    "{tool_responses}\n",
    "Your Response:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = template,\n",
    "    input_variables = ['tools', 'question', 'tool_responses']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f44c12-4358-405a-8099-a1f305a25da9",
   "metadata": {},
   "source": [
    "## 2. Setup tools\n",
    "* Dummy tool functions for stock price & city weather\n",
    "* Functions are hardcoded to respond for fixed set of cities/stocks\n",
    "* Tool map = dictionary of functions with function name as the key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4af73d-9733-48c4-8084-2512b9b8c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tool 1 for stocks\n",
    "def  company_stock_price(stock_symbol: str) -> float:\n",
    "    if stock_symbol.upper()=='AAPL':\n",
    "        return  {\"price\": 192.32}\n",
    "    elif stock_symbol.upper()=='MSFT':\n",
    "        return  {\"price\": 415.60}\n",
    "    elif stock_symbol.upper()=='AMZN':\n",
    "        return  {\"price\": 183.60}\n",
    "    else:\n",
    "        return {\"price\": \"unknown\"}\n",
    "\n",
    "\n",
    "stock_tool_description = {\n",
    "    \"name\" : \"company_stock_price\",\n",
    "    \"description\": \"This tool returns the last known stock price for a company based on its ticker symbol. For example company_stock_price('ABCD') returns the stock price for a company with ticker symbol 'ABCD'\",\n",
    "    \"arguments\": [\n",
    "        {\"stock_symbol\" : \"stock ticker symbol for the company\"}\n",
    "    ],\n",
    "    \"response\": \"last known stock price\"\n",
    "}\n",
    "\n",
    "## Tool 2 for city weather\n",
    "def city_weather(city: str) -> int:\n",
    "    if city.lower() == \"new york\":\n",
    "        return {\"temperature\": 68, \"forecast\": \"rain\"}\n",
    "    elif city.lower() == \"paris\":\n",
    "        return {\"temperature\": 73, \"forecast\": \"sunny\"}\n",
    "    elif city.lower() == \"london\":\n",
    "        return {\"temperature\": 82, \"forecast\": \"cloudy\"}\n",
    "    else:\n",
    "        return {\"temperature\": \"unknown\"}\n",
    "        \n",
    "city_weather_tool_description = {\n",
    "    \"name\" : \"city_weather\",\n",
    "    \"description\": \"This tool returns the current temperature and forecast for the given city\",\n",
    "    \"arguments\": [\n",
    "        {\"city\" : \"name of the city\"}\n",
    "    ],\n",
    "    \"response\": \"current temperature & forecast\"\n",
    "}\n",
    "\n",
    "# Maintain the tools in a map for invocation by th eagent\n",
    "tools = [stock_tool_description, city_weather_tool_description]\n",
    "tools_map = {\n",
    "    'company_stock_price': company_stock_price,\n",
    "    'city_weather' : city_weather\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b2d07-7fae-4a69-ae69-f0bc8c8a1460",
   "metadata": {},
   "source": [
    "## 3. Agent code\n",
    "\n",
    "* Create a function for invoking the agent\n",
    "* Create a utility function for invoking the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d9f564-92b5-4729-a58d-5d06b14d6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for answering the question\n",
    "def  invoke_agent(question):\n",
    "    \n",
    "    # Setup the prompt. Since no tool has been invoked set action_response as blank\n",
    "    query = prompt.format(tools=tools, question=question, tool_responses=\"\")\n",
    "\n",
    "    # STEP-1 Invoke LLM for a plan i.e., tools to execute\n",
    "    # ===================================================\n",
    "    # Invoke LLM to get the tools to be run\n",
    "    # The response consist of tools that LLM requires to be executed\n",
    "    response = llm.invoke(query)\n",
    "\n",
    "    # Convert response to JSON object. The response is of type AIMessage\n",
    "    response_json = json.loads(response.content)\n",
    "\n",
    "    # print the response\n",
    "    print(\"STEP-1:\", response_json, \"\\n\")\n",
    "\n",
    "    # STEP-2  Invoke the tool(s) suggested by LLM\n",
    "    # ===========================================\n",
    "    # LLM may respond with an answer \n",
    "    # It may happen if LLM determines that no tool is available for responding to the question\n",
    "    action_responses=[]\n",
    "    if \"answer\" in response_json:\n",
    "        # If the answer is already there\n",
    "        return {\"answer\" : response_json[\"answer\"]}\n",
    "    elif \"actions\" in response_json:\n",
    "        # If the LLM has suggested tools to be executed, execute the tools\n",
    "        action_responses = invoke_tools(response_json)\n",
    "\n",
    "    # Print the tool responses\n",
    "    print(\"STEP-2\", \"   Agent tool invocation responses :\", action_responses, \"\\n\")\n",
    "\n",
    "    # STEP-3  Invoke LLM to generate final response\n",
    "    # =============================================\n",
    "    # Now send the action responses to LLM for generating the answer\n",
    "    query = prompt.format(tools=tools, question=question,tool_responses=action_responses)\n",
    "    response = llm.invoke(query)\n",
    "\n",
    "    # print the response\n",
    "    print(\"STEP-3:\", response_json, \"\\n\")\n",
    "\n",
    "    # Convert response to JSON object\n",
    "    response_json = json.loads(response.content)\n",
    "\n",
    "    # Extract the answer from the response    \n",
    "    if \"answer\" in response_json:\n",
    "        return response_json[\"answer\"]\n",
    "    else:\n",
    "        return (\"Can't generate as there is no response from the tool!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dfc5ccf-3755-48e7-bbeb-0eeeb1adaa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to process the actions receieved from the LLM\n",
    "# Responses from the tools are expected to be in JSON format \n",
    "def   invoke_tools(response):\n",
    "    action_responses = []\n",
    "    if len(response[\"actions\"]) == 0:\n",
    "        print('question cannot be answered as there is no tool to use !!!')\n",
    "        exit\n",
    "    else:\n",
    "        for action in response[\"actions\"]:\n",
    "\n",
    "            # Get the function pointer from the map\n",
    "            action_function = tools_map[action[\"action\"]]\n",
    "            \n",
    "            # Invoke the tool/function with the arguments as suggested by the LLM\n",
    "            action_invoke_result = action_function(**action[\"arguments\"])\n",
    "            action[\"response\"] = action_invoke_result\n",
    "\n",
    "            # Add the response to the action attribute\n",
    "            action_responses.append(action)\n",
    "\n",
    "    # Return the response      \n",
    "    return action_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff2bfe-bf71-459a-a509-29c2236f4346",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb069cbc-093e-4218-abc4-6f9d470455ad",
   "metadata": {},
   "source": [
    "### 1. Simple test that uses 1 tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ce2fda5-d301-4dca-b597-bc87ff74c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP-1: {'actions': [{'action': 'city_weather', 'arguments': {'city': 'Paris'}}, {'action': 'city_weather', 'arguments': {'city': 'London'}}]} \n",
      "\n",
      "STEP-2    Agent tool invocation responses : [{'action': 'city_weather', 'arguments': {'city': 'Paris'}, 'response': {'temperature': 73, 'forecast': 'sunny'}}, {'action': 'city_weather', 'arguments': {'city': 'London'}, 'response': {'temperature': 82, 'forecast': 'cloudy'}}] \n",
      "\n",
      "STEP-3: {'actions': [{'action': 'city_weather', 'arguments': {'city': 'Paris'}, 'response': {'temperature': 73, 'forecast': 'sunny'}}, {'action': 'city_weather', 'arguments': {'city': 'London'}, 'response': {'temperature': 82, 'forecast': 'cloudy'}}]} \n",
      "\n",
      "Final response:: London is hotter than Paris\n"
     ]
    }
   ],
   "source": [
    "question = \"Which of these cities is hotter, Paris or London\"\n",
    "# question = \"I am visting paris, should i carry an umbrella?\"\n",
    "\n",
    "response = invoke_agent(question)\n",
    "\n",
    "print(\"Final response::\",response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918ea267-850e-4e21-a350-ebddc865a44a",
   "metadata": {},
   "source": [
    "### 2. Simple test when no appropriate tool is available for processing the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "295ef3e0-ba4b-4861-9390-d992f552a147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP-1: {'answer': 'No appropriate tool available'} \n",
      "\n",
      "Final response:: {'answer': 'No appropriate tool available'}\n"
     ]
    }
   ],
   "source": [
    "question = \"search the web for articles on 'large language models'\"\n",
    "\n",
    "response = invoke_agent(question)\n",
    "\n",
    "print(\"Final response::\",response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac578414-77f7-4b9e-8556-23b3776deb20",
   "metadata": {},
   "source": [
    "### 3. A complex scenario requiring use of more than one tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db8c90b-76b2-421c-83a4-fc2fcce651b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP-1: {'actions': [{'action': 'city_weather', 'arguments': {'city': 'New York'}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'AAPL'}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'MSFT'}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'AMZN'}}]} \n",
      "\n",
      "STEP-2    Agent tool invocation responses : [{'action': 'city_weather', 'arguments': {'city': 'New York'}, 'response': {'temperature': 68, 'forecast': 'rain'}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'AAPL'}, 'response': {'price': 192.32}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'MSFT'}, 'response': {'price': 415.6}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'AMZN'}, 'response': {'price': 183.6}}] \n",
      "\n",
      "STEP-3: {'actions': [{'action': 'city_weather', 'arguments': {'city': 'New York'}, 'response': {'temperature': 68, 'forecast': 'rain'}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'AAPL'}, 'response': {'price': 192.32}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'MSFT'}, 'response': {'price': 415.6}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'AMZN'}, 'response': {'price': 183.6}}]} \n",
      "\n",
      "Final response: AAPL\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "I am interested in investing in one of these stocks: AAPL, MSFT, or AMZN.\n",
    "\n",
    "Decision Criteria:\n",
    "\n",
    "Sunny Weather: Choose the stock with the lowest price.\n",
    "Raining Weather: Choose the stock with the highest price.\n",
    "Cloudy Weather: Do not buy any stock.\n",
    "Location:\n",
    "\n",
    "I am currently in New York.\n",
    "Question:\n",
    "\n",
    "Based on the current weather in New York and the stock prices, which stock should I invest in?\n",
    "\"\"\"\n",
    "\n",
    "response = invoke_agent(question)\n",
    "\n",
    "print(\"Final response:\",response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e859be7-f0a9-44f7-acdd-158bcb73c46c",
   "metadata": {},
   "source": [
    "### 4. Test for a scenario when the response from tool is insufficient to generate an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c315ae8-22f1-4272-a28c-b48a3e510aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP-1: {'actions': [{'action': 'company_stock_price', 'arguments': {'stock_symbol': 'GOOG'}}]} \n",
      "\n",
      "STEP-2    Agent tool invocation responses : [{'action': 'company_stock_price', 'arguments': {'stock_symbol': 'GOOG'}, 'response': {'price': 'unknown'}}] \n",
      "\n",
      "STEP-3: {'actions': [{'action': 'company_stock_price', 'arguments': {'stock_symbol': 'GOOG'}, 'response': {'price': 'unknown'}}]} \n",
      "\n",
      "Final response: Can't generate as there is no response from the tool!!!\n"
     ]
    }
   ],
   "source": [
    "question = \"I have only $200, can i buy GOOG stock?\"\n",
    "\n",
    "response = invoke_agent(question)\n",
    "\n",
    "print(\"Final response:\",response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12607e-d664-4f0e-b071-d04cf79e3b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
