{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299a57bd-23fa-4d9b-8369-312293bb2669",
   "metadata": {},
   "source": [
    "# Sentence BERT Models\n",
    "https://sbert.net/\n",
    "\n",
    "This notebook shows how to use SBERT to:\n",
    "* Encode i.e., generate embeddings\n",
    "* Calculate similarity score using cosine metric\n",
    "* Do classification task using embeddings and cosine metric\n",
    "* Semantic search using SBERT utility & PyTorch\n",
    "\n",
    "**Note:**\n",
    "* The code in this notebook will download the model to local cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a58d009-29ae-4bc7-af31-c8c4670f6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd7c31-96af-4fcb-a230-42fc3d2d4a8e",
   "metadata": {},
   "source": [
    "## Create Model instance\n",
    "\n",
    "Create a pre-trained SBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5be0b25-d032-4ff3-b7c8-f7a4881a35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Model name \n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Model creation\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ecb33-1078-4874-aa60-69e4164adbf0",
   "metadata": {},
   "source": [
    "## 1. Generate embeddings and cosine scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c63d363-1d11-4b30-9beb-92dc17f5bd69",
   "metadata": {},
   "source": [
    "### Generate embeddings\n",
    "\n",
    "Embeddings are generated using the **model.encode** function.\n",
    "\n",
    "https://www.sbert.net/docs/package_reference/SentenceTransformer.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4913a40-2365-428c-956e-f74b52d35939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# Single list of sentences\n",
    "words = [\n",
    "    \"cat\",\n",
    "    \"dog\",\n",
    "    \"pasta\",\n",
    "    \"puppy\",\n",
    "    \"kitten\",\n",
    "    \"car\",\n",
    "    \"motorbike\",\n",
    "    \"pizza\",\n",
    "]\n",
    "\n",
    "# Compute embeddings for the entire list of words\n",
    "embeddings = model.encode(words)\n",
    "\n",
    "# Length\n",
    "print(len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a623e6-c19e-465f-898a-f03e4302a40f",
   "metadata": {},
   "source": [
    "### Calculate the score between test word and the list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d3155b-cc82-4e45-9ab1-0260ab97632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test word =  truck\n",
      "(0.69, 'car')\n",
      "(0.51, 'motorbike')\n",
      "(0.45, 'dog')\n",
      "(0.45, 'cat')\n",
      "(0.39, 'kitten')\n",
      "(0.38, 'puppy')\n",
      "(0.32, 'pasta')\n",
      "(0.31, 'pizza')\n"
     ]
    }
   ],
   "source": [
    "# Change the word to test\n",
    "test_word = \"truck\"\n",
    "\n",
    "test_word_embedding = model.encode(test_word)\n",
    "\n",
    "results = []\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    \n",
    "    # calculate the score\n",
    "    score = util.cos_sim(test_word_embedding, embedding)\n",
    "    \n",
    "    # convert tensor to a scalar and round to 2 decimal places\n",
    "    score = round(score.item(),2)\n",
    "\n",
    "    results.append((score, words[i]))\n",
    "\n",
    "results.sort(reverse=True)\n",
    "\n",
    "print(\"Test word = \", test_word)\n",
    "\n",
    "# Iterate through the resulst\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c8a5b-5e9d-4ace-ab3b-835d0ce4db54",
   "metadata": {},
   "source": [
    "### Compute the cosine similarity score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d2694-34f9-45ba-bc9c-d8e4fef243e2",
   "metadata": {},
   "source": [
    "## 2. Classification\n",
    "\n",
    "1. Multiple sentences are given in 2 categories [Sports, History]\n",
    "2. Given a new sentence:\n",
    "    * Classify it [Sports, History]\n",
    "    * Find a sentence that is closest to it from the 2 categories\n",
    "  \n",
    "**Plan of action:**\n",
    "1. Calculate the embeddings for the given sentences (corpus)\n",
    "2. For the query:\n",
    "    * calculate its embedding\n",
    "    * caclculate the average cosine score between the query emebedding and each of the 2 clusters\n",
    "    * find the corpus string amon the 2 categories, that have the maximum score\n",
    "3. Use average score to classify\n",
    "4. Find the sentence within the category that has the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90de5dd-34de-4413-a938-3a289f6bbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category : Sports\n",
    "sports_facts = [\n",
    "    \"Football, also known as soccer in some countries, is the most popular sport in the world, with billions of fans worldwide.\",\n",
    "    \"Basketball was invented in 1891 by Dr. James Naismith, a Canadian physical education instructor, as an indoor game to keep his students active during the winter months.\",\n",
    "    \"Tennis is a highly competitive sport that originated in the 19th century and is played by millions of people around the world on various surfaces such as grass, clay, and hardcourt.\",\n",
    "    \"Golf is a precision club-and-ball sport in which players use various clubs to hit balls into a series of holes on a course in as few strokes as possible.\"\n",
    "]\n",
    "\n",
    "# Category : History\n",
    "history_facts = [\n",
    "    \"The Renaissance was a period of cultural rebirth that emerged in Europe during the 14th to 17th centuries, marking a transition from the Middle Ages to modernity.\",\n",
    "    \"The Industrial Revolution, which began in Britain in the late 18th century, transformed society by introducing mechanized manufacturing processes and urbanization.\",\n",
    "    \"The Cold War, spanning from the late 1940s to the early 1990s, was a geopolitical conflict between the United States and the Soviet Union, characterized by ideological, economic, and military competition.\",\n",
    "    \"The French Revolution, which erupted in 1789, was a watershed moment in European history, leading to the overthrow of the monarchy and the rise of democratic principles.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f73601c-2a7e-4f4d-ae0b-2f40daa62ad4",
   "metadata": {},
   "source": [
    "### Use model.encode() to generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d2fe01-930f-4427-be76-d43f5ebbb7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_facts_embeddings = model.encode(sports_facts)\n",
    "history_facts_embeddings = model.encode(history_facts)\n",
    "\n",
    "# optional step\n",
    "# print(\"Dimension = \", len(sports_facts_embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4adb3a3-afbe-49c3-b30f-1cca2bee588e",
   "metadata": {},
   "source": [
    "### Calculate Cosine Score\n",
    "\n",
    "For ease of use, create a utility function to calculate the semantic score between query embedding and the list of embeddings for a given category.\n",
    "\n",
    "Function returns a tuple:\n",
    "\n",
    "* Scores for each of the list item\n",
    "* Average score\n",
    "* Index of the item for which the score is maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "549547fc-d37d-4f6b-88a4-8069e4b2660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  calculate_cosine_score(test_embedding, embeddings):\n",
    "    # variable holds the score\n",
    "    scores = []\n",
    "\n",
    "    # calculate the average score, max score\n",
    "    average_score = 0\n",
    "\n",
    "    # holds the info on max score\n",
    "    max_score = 0\n",
    "    max_score_index = 0\n",
    "\n",
    "    # loop through the list to calculate the score, average, max\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        score = util.cos_sim(test_embedding, embedding)\n",
    "        scores.append(score)\n",
    "        average_score += score\n",
    "        if score > max_score:\n",
    "            max_score_index = i\n",
    "            max_score = score\n",
    "\n",
    "    return scores, (average_score)/len(scores), max_score_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1112ccb9-dd62-4987-b93a-84bbcc4673ff",
   "metadata": {},
   "source": [
    "### Test sentence & its embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d01ca541-f2c2-4262-b2ef-2eb79ce4db5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arts, and self expression was the highlight  - Belongs to category :  history\n",
      "Closest sentence :  The Renaissance was a period of cultural rebirth that emerged in Europe during the 14th to 17th centuries, marking a transition from the Middle Ages to modernity.\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"I like putting\",\n",
    "    \"two strong armies came face to face\",\n",
    "    \"hoops on the two ends of the court\",\n",
    "    \"steam engine changed the world\",\n",
    "    \"arts, and self expression was the highlight\"\n",
    "]\n",
    "\n",
    "test_sentence = test_sentences[4]\n",
    "\n",
    "test_sentence_embedding =  model.encode(test_sentence)\n",
    "\n",
    "# Calculate the scores\n",
    "scores_sports, average_score_sports, max_score_index_sports = calculate_cosine_score(test_sentence_embedding, sports_facts_embeddings)\n",
    "scores_history, average_score_history, max_score_index_history = calculate_cosine_score(test_sentence_embedding, history_facts_embeddings)\n",
    "\n",
    "### Check category\n",
    "category = \"sports\"\n",
    "if average_score_history > average_score_sports:\n",
    "    category = \"history\"\n",
    "\n",
    "print(test_sentence,\" - Belongs to category : \", category)\n",
    "\n",
    "# Get the closest sentence\n",
    "if category == \"sports\":\n",
    "    print(\"Closest sentence : \", sports_facts[max_score_index_sports])\n",
    "else:\n",
    "    print(\"Closest sentence : \", history_facts[max_score_index_history])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f31a46-7a71-4956-bd53-4c9ec3993fbb",
   "metadata": {},
   "source": [
    "## 3. Paraphrase mining\n",
    "\n",
    "Given a list of sentences / texts, this function performs paraphrase mining. It compares all sentences against all other sentences and returns a list with the pairs that have the highest cosine similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d9ca7e-b0a7-4d98-841c-920170c8197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Score:  0.76   -------\n",
      "A man is eating food.\n",
      "A man is eating a piece of bread.\n",
      "------ Score:  0.74   -------\n",
      "A man is riding a horse.\n",
      "A man is riding a white horse on an enclosed ground.\n",
      "------ Score:  0.25   -------\n",
      "A man is eating food.\n",
      "A man is riding a horse.\n",
      "------ Score:  0.2   -------\n",
      "A woman is playing violin.\n",
      "A monkey is playing drums.\n",
      "------ Score:  0.17   -------\n",
      "A man is eating food.\n",
      "A man is riding a white horse on an enclosed ground.\n",
      "------ Score:  0.14   -------\n",
      "A man is eating a piece of bread.\n",
      "A man is riding a horse.\n",
      "------ Score:  0.14   -------\n",
      "A man is eating food.\n",
      "A cheetah is running behind its prey.\n",
      "------ Score:  0.12   -------\n",
      "A monkey is playing drums.\n",
      "A cheetah is running behind its prey.\n",
      "------ Score:  0.12   -------\n",
      "A man is eating a piece of bread.\n",
      "A man is riding a white horse on an enclosed ground.\n",
      "------ Score:  0.08   -------\n",
      "A man is riding a horse.\n",
      "A monkey is playing drums.\n",
      "------ Score:  0.08   -------\n",
      "A man is riding a white horse on an enclosed ground.\n",
      "A cheetah is running behind its prey.\n",
      "------ Score:  0.08   -------\n",
      "Two men pushed carts through the woods.\n",
      "A man is riding a white horse on an enclosed ground.\n",
      "------ Score:  0.06   -------\n",
      "A man is eating a piece of bread.\n",
      "A cheetah is running behind its prey.\n",
      "------ Score:  0.05   -------\n",
      "A man is riding a white horse on an enclosed ground.\n",
      "A monkey is playing drums.\n",
      "------ Score:  0.05   -------\n",
      "A man is eating food.\n",
      "A monkey is playing drums.\n",
      "------ Score:  0.04   -------\n",
      "A man is eating a piece of bread.\n",
      "A monkey is playing drums.\n",
      "------ Score:  0.04   -------\n",
      "A man is riding a horse.\n",
      "Two men pushed carts through the woods.\n",
      "------ Score:  0.03   -------\n",
      "A man is riding a horse.\n",
      "A cheetah is running behind its prey.\n",
      "------ Score:  0.02   -------\n",
      "The girl is carrying a baby.\n",
      "A monkey is playing drums.\n",
      "------ Score:  0.02   -------\n",
      "The girl is carrying a baby.\n",
      "A cheetah is running behind its prey.\n",
      "------ Score:  0.02   -------\n",
      "The girl is carrying a baby.\n",
      "A woman is playing violin.\n",
      "------ Score:  -0.02   -------\n",
      "A man is eating a piece of bread.\n",
      "Two men pushed carts through the woods.\n",
      "------ Score:  -0.03   -------\n",
      "A man is eating food.\n",
      "Two men pushed carts through the woods.\n",
      "------ Score:  -0.03   -------\n",
      "A man is riding a horse.\n",
      "A woman is playing violin.\n",
      "------ Score:  -0.04   -------\n",
      "Two men pushed carts through the woods.\n",
      "A cheetah is running behind its prey.\n",
      "------ Score:  -0.04   -------\n",
      "Two men pushed carts through the woods.\n",
      "A monkey is playing drums.\n",
      "------ Score:  -0.04   -------\n",
      "A woman is playing violin.\n",
      "A cheetah is running behind its prey.\n",
      "------ Score:  -0.04   -------\n",
      "The girl is carrying a baby.\n",
      "Two men pushed carts through the woods.\n",
      "------ Score:  -0.06   -------\n",
      "A woman is playing violin.\n",
      "A man is riding a white horse on an enclosed ground.\n",
      "------ Score:  -0.06   -------\n",
      "A man is eating a piece of bread.\n",
      "The girl is carrying a baby.\n",
      "------ Score:  -0.07   -------\n",
      "A man is eating food.\n",
      "A woman is playing violin.\n",
      "------ Score:  -0.08   -------\n",
      "A man is eating a piece of bread.\n",
      "A woman is playing violin.\n",
      "------ Score:  -0.09   -------\n",
      "The girl is carrying a baby.\n",
      "A man is riding a white horse on an enclosed ground.\n",
      "------ Score:  -0.1   -------\n",
      "A man is eating food.\n",
      "The girl is carrying a baby.\n",
      "------ Score:  -0.11   -------\n",
      "The girl is carrying a baby.\n",
      "A man is riding a horse.\n",
      "------ Score:  -0.17   -------\n",
      "A woman is playing violin.\n",
      "Two men pushed carts through the woods.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "corpus = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]\n",
    "\n",
    "mining_result = util.paraphrase_mining(model, corpus)\n",
    "for result in mining_result:\n",
    "    print(\"------ Score: \",round(result[0],2),\"  -------\")\n",
    "    print(corpus[result[1]])\n",
    "    print(corpus[result[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b07163a-b5ed-4535-89bb-6e2a4f20a1de",
   "metadata": {},
   "source": [
    "## 4. Semantic search\n",
    "In the classification example we had to build our own search logic to find the nearest matching sentence. Semantic search enginers offers this capability out of the box, as a result you don't have to build a search algorithm on your own. Sentence transformer library offers a simple utility function to carry out semantic search. \n",
    "\n",
    "https://sbert.net/examples/applications/semantic-search/README.html\n",
    "https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/semantic-search/semantic_search.py\n",
    "\n",
    "#### 2 ways to do it\n",
    "1. Use sentence-transformer **util.semantic_search(...)**\n",
    "2. Use cosine distance and PyTorch.topk function for evaluating the top k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c7eca-a6af-45b7-bf22-b857d62c0330",
   "metadata": {},
   "source": [
    "### Define the corpus\n",
    "\n",
    "In this example we are using an array of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8bdc6-e8c6-467a-b813-bd4e99152141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = [\n",
    "    \"A man is eating food.\",\n",
    "    \"A man is eating a piece of bread.\",\n",
    "    \"The girl is carrying a baby.\",\n",
    "    \"A man is riding a horse.\",\n",
    "    \"A woman is playing violin.\",\n",
    "    \"Two men pushed carts through the woods.\",\n",
    "    \"A man is riding a white horse on an enclosed ground.\",\n",
    "    \"A monkey is playing drums.\",\n",
    "    \"A cheetah is running behind its prey.\",\n",
    "]\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ab495-ce47-4e67-ba84-faf816defa58",
   "metadata": {},
   "source": [
    "### Test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc713fef-8501-4f7a-9d94-648a112d3957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query sentences:\n",
    "queries = [\n",
    "    \"A man is eating pasta.\",\n",
    "    \"Someone in a gorilla costume is playing a set of drums.\",\n",
    "    \"A cheetah chases prey on across a field.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb5cbfb-a170-4ed7-aa59-7a1dc0abd792",
   "metadata": {},
   "source": [
    "### 1. Top-K queries using sentence-transformers util\n",
    "\n",
    "Search corpus for each of the test queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8dbc33-b4d0-4265-b952-f9494518c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = min(5, len(corpus))\n",
    "for query in queries:\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    hits = hits[0]      #Get the hits for the first query\n",
    "    for hit in hits:\n",
    "        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d528b35-5511-4ce0-9358-838b207ff27c",
   "metadata": {},
   "source": [
    "### 2. Top-K queries using PyTorch topk\n",
    "\n",
    "Search corpus for each of the test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1930f11-996d-4029-83aa-1187f585a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = min(5, len(corpus))\n",
    "for query in queries:\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: {:.4f})\".format(score))\n",
    "\n",
    "    \"\"\"\n",
    "    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    hits = hits[0]      #Get the hits for the first query\n",
    "    for hit in hits:\n",
    "        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c4d1c-6441-4885-b4a8-5f6e6be25ba3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112739f-cdd1-4fdc-98bb-c199eda97c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
