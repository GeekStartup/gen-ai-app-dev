{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8b2327f-b87e-4ec7-880c-301f1001f666",
   "metadata": {},
   "source": [
    "# Table Question & Answering task\n",
    "\n",
    "* Use an appropriate model for the task\n",
    "* Response depends of the task & model in use\n",
    "\n",
    "**Note:**\n",
    "An error = 503 indicates that model is in *cold* state but will be loaded. Try again after a few moments.\n",
    "\n",
    "https://huggingface.co/docs/api-inference/detailed_parameters#table-question-answering-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb251864-3f24-4d42-869e-e05d487c9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import getpass\n",
    "\n",
    "# setting path for utils package\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.hf_post_api import hf_rest_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8805f-0d3e-4177-8b41-5e3cd9c75c45",
   "metadata": {},
   "source": [
    "## Get the HUGGINGFACEHUB_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eea1131-2e4d-42c6-8427-594b0ac437b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide the HF API Token:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "print(\"Provide the HF API Token:\")\n",
    "HUGGINGFACEHUB_API_TOKEN=getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba5c56-21eb-45a0-9c37-9488f9287ff1",
   "metadata": {},
   "source": [
    "## 1. Setup the table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ab59cd-7f09-48e8-a1c9-959041f0eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data could be coming from a SQL database, REST API or any other source\n",
    "table_data = {\n",
    "  \"Product\": [\"Laptop\", \"Smartphone\", \"Tablet\", \"Headphones\", \"Laptop\", \"Smartphone\", \"Tablet\"],\n",
    "  \"Region\": [\"North America\", \"Europe\", \"Asia\", \"North America\", \"Europe\", \"Asia\", \"North America\"],\n",
    "  \"Units Sold\": [5000, 8000, 6500, 12000, 4200, 10000, 7000],\n",
    "  \"Revenue (USD)\": [5000000, 4800000, 3250000, 1200000, 4200000, 6000000, 3500000],\n",
    "  \"Profit (USD in thousands)\": [1200, 800, 650, 300, 1000, 1200, 700]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c078f3a9-c3ce-40c3-ba84-56d6a02f06bf",
   "metadata": {},
   "source": [
    "## 2. Create the model client\n",
    "\n",
    "**Note**\n",
    "* Model must be trained on table Q&A task\n",
    "* Accuracy of the model depends on the model's capability !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15c2063e-d33e-4a89-be23-839b44d7bfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model URL:  https://api-inference.huggingface.co/models/microsoft/tapex-large-finetuned-wtq\n"
     ]
    }
   ],
   "source": [
    "# Select the model for the task\n",
    "# google/tapas-base-finetuned-wtq is a good model for table Q&A\n",
    "\n",
    "# model_id='google/tapas-large-finetuned-wtq'\n",
    "model_id='microsoft/tapex-large-finetuned-wtq'\n",
    "\n",
    "# Create the client\n",
    "hf_client = hf_rest_client(model_id, api_token=HUGGINGFACEHUB_API_TOKEN)\n",
    "\n",
    "# Check endpoint URL\n",
    "print(\"Model URL: \", hf_client.get_model_url())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380faa9f-8f1f-45a7-89b9-824036bd5858",
   "metadata": {},
   "source": [
    "## 3. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485c2587-6f01-4946-9999-812b66943626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': ' north america'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample questions for the data\n",
    "questions = [\n",
    "    \"Which region generated the highest total revenue from all products?\",\n",
    "    \"Which product category achieved the highest profit in Europe?\",\n",
    "    \"How many total units of Smartphones were sold across all regions?\",\n",
    "    \"What was the average revenue per unit for Tablets sold in Asia?\"\n",
    "]\n",
    "\n",
    "# Answers for reference ONLY.\n",
    "# Models will be used for generating the answers\n",
    "# answers = [\n",
    "#     \"North America generated the highest total revenue from all products, with a total of $9,700,000 (calculated as $5,000,000 from Laptops, $1,200,000 from Headphones, and $3,500,000 from Tablets).\",\n",
    "#     \"Laptops achieved the highest profit in Europe, with a profit of $1,000,000.\",\n",
    "#     \"A total of 18,000 units of Smartphones were sold across all regions (8,000 in Europe + 10,000 in Asia).\",\n",
    "#     \"The average revenue per unit for Tablets sold in Asia was $500 (calculated as $3,250,000 ÷ 6,500 units).\"\n",
    "# ]\n",
    "\n",
    "# Change index to try other question(s)\n",
    "question_index = 0\n",
    "\n",
    "question = {\n",
    "    \"query\": questions[question_index],\n",
    "    \"table\": table_data\n",
    "}\n",
    "\n",
    "response = hf_client.invoke(question)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96791a39-a42d-4048-956e-f0efabb45ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
