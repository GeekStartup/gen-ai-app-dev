{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1c106b-5a32-452c-a374-d689da710d20",
   "metadata": {},
   "source": [
    "# Tokenizer class\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/tokenizer\n",
    "\n",
    "Try out various methods:\n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.PreTrainedTokenizer\n",
    "\n",
    "* call(\"text\")\n",
    "* tokenize(\"text\")\n",
    "* encode(\"text\") : converts to IDs of the tokens\n",
    "* decode(encoded_text) : converts IDs to token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1addb38c-49a3-419f-91ba-de3fff2bc114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a58a7ef-daeb-434d-8061-1dfe5ad59923",
   "metadata": {},
   "source": [
    "## 1. Create an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99d8a6f-b6f7-4f9c-9f2c-48af0c8539fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffaaf5c-d3e6-45de-884e-2ea89ee7d309",
   "metadata": {},
   "source": [
    "## 2. Tokenize  the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b3986a0-5431-47dc-8cf6-613e145274ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he', 'is', 'a', 'story', '##tell', '##er']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'he is a storyteller'\n",
    "\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf07b3-7d3d-4c12-a53a-89b40b519e82",
   "metadata": {},
   "source": [
    "# 3. Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02c4ebff-7e30-4fb0-b373-28faad33c161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2002, 2003, 1037, 2466, 23567, 2121, 102]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = tokenizer.encode(text)\n",
    "\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acc9445-ad70-435b-af69-aad49e794999",
   "metadata": {},
   "source": [
    "## 4. Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e145d9d8-8fe5-4c43-8bb8-85315255a4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] he is a storyteller [SEP]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text = tokenizer.decode(encoded_text)\n",
    "\n",
    "decoded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87872e12-c8c9-4674-a302-27c343011b5e",
   "metadata": {},
   "source": [
    "## 5. Create tensors for input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13839a10-fedc-4952-bbbc-ffa1974ba3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2002, 2003, 1037, 2466, 23567, 2121, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns Python Lists\n",
    "inputs = tokenizer(text)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eba6e34c-8687-4525-aa26-fc4ce41eb6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2002,  2003,  1037,  2466, 23567,  2121,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns tensors in desired format (PyTorch=pt, TensorFlow=tf, Flax=jax, Numpy=np)\n",
    "return_tensors = 'pt' \n",
    "\n",
    "inputs = tokenizer(text, return_tensors=return_tensors)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a16c9c38-6a67-4564-8bb5-fd467d9feef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c025d0-83f9-4dbd-bef3-8936747a21dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
