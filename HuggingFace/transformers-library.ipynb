{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7780d108-f341-4a7b-b4cd-94d8ef145dc1",
   "metadata": {},
   "source": [
    "# 1. Setup Transformers Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537c609-79f8-44f5-b753-0ef9b973354e",
   "metadata": {},
   "source": [
    "### Transformers library dependency\n",
    "Transformers library is dependent on ML libraries. In order to use it, you MUST install the ML library itself before installing the Transformers library. You will be installing the **Pytorch** ML framework.\n",
    "\n",
    "#### Pytorch installation\n",
    "* Depends on the machine's architecture.\n",
    "* It has separate libraries for CPU & GPU\n",
    "* Follow instructions at [https://pytorch.org/](https://pytorch.org/) to install on your machine\n",
    "* If an incorrect library version is installed, it would lead to an error at runtime (on import statement). You would see an error similar to one below:\n",
    "\n",
    "> **OSError:** [WinError 126] can't find this module. Error loading \"d:\\anaconda3\\envs\\RN\\lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.\n",
    "\n",
    "#### Transformer library installation\n",
    "Once you have the Pytorch installed, use an appropriate command to install the package.\n",
    "\n",
    "* pip install transformers\n",
    "* conda install transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "df382b63-cf33-46db-bf9a-e72f3ae61631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T12:24:11.543240Z",
     "start_time": "2025-08-03T12:24:11.534769Z"
    }
   },
   "source": [
    "## Do not use this on your machine. Follow instructions in course guide to setup on local machine.\n",
    "\n",
    "## Uncomment the following & run it if you are using Google Colab\n",
    "## Restart kernel otherwise, you may get an error\n",
    "\n",
    "# !pip install torch transformers"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "2418364f-e3b6-4647-bc1a-7f2867972061",
   "metadata": {},
   "source": [
    "# 2. Import *pipeline* from transformers \n",
    "\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines"
   ]
  },
  {
   "cell_type": "code",
   "id": "f7613e7a-c290-40b0-9b8f-05b9f0c6edbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:45:49.043846Z",
     "start_time": "2025-08-16T10:45:49.038909Z"
    }
   },
   "source": "from transformers import pipeline",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "f7d38dc2-bb05-42da-b7a1-490db0430607",
   "metadata": {},
   "source": [
    "# 3. Create the pipeline\n",
    "\n",
    "Easiest way to use any Hugging Face model for inference. \n",
    "\n",
    "**Note:**\n",
    "\n",
    "* Without model argument, you will get a warning\n",
    "* Never use pipeline without model specified explicitly as default model may change in future !!"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0cd5ce2-f5b9-4531-b806-8aa3df267523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:45:53.711492Z",
     "start_time": "2025-08-16T10:45:52.809072Z"
    }
   },
   "source": [
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "pipe = pipeline(\"sentiment-analysis\", model = model_name)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "5f016e8c-fe5d-4fef-9ed0-dcce4f628f77",
   "metadata": {},
   "source": [
    "# 4. Inferencing\n",
    "\n",
    "The parameters used for the pipeline depends on the task. Check out the parameters for each task based on the pipeline class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6ff25d73-ea21-4b48-a55d-8d39659a7560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:45:56.720115Z",
     "start_time": "2025-08-16T10:45:56.663272Z"
    }
   },
   "source": [
    "text = \"restaurant had good food\"\n",
    "\n",
    "pipe(text)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998434782028198}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ef671ae4-370a-4269-a8da-67f28ee2b4ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-16T10:45:58.910139Z",
     "start_time": "2025-08-16T10:45:58.878935Z"
    }
   },
   "source": [
    "text = \"I hated it\"\n",
    "\n",
    "pipe(text)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9996846914291382}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6b4be-f505-44b2-a4c5-ef6bd03e23c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
