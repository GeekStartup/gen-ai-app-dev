{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bff477c",
   "metadata": {},
   "source": [
    "# LLM Challenges\n",
    "\n",
    "Demonstrates the common challenges with LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4c5164-83f3-491f-9c42-d79b4a90bf4f",
   "metadata": {},
   "source": [
    "#### Google Colab\n",
    "If you are running the code in Google colab, install the packages by uncommenting/running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3463acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Collab\n",
    "# !pip install load_dotenv transformers huggingface-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a5e71",
   "metadata": {},
   "source": [
    "## Setup the enviornment varaibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b45c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the file that contains the API keys\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')\n",
    "\n",
    "# Sets up keys : HUGGINGFACEHUB_API_TOKEN, OPENAI_API_KEY, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e0247ef-0d2b-4ed0-9549-77ab561be879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694e045",
   "metadata": {},
   "source": [
    "## Create LLM for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7abfdb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "hugging_face_model_ids = [\n",
    "    'google/gemma-2-2b-it',\n",
    "    'tiiuae/falcon-7b-instruct',\n",
    "    'mistralai/Mistral-7B-Instruct-v0.2',\n",
    "    'openlm-research/open_llama_3b_v2'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f3e7f2",
   "metadata": {},
   "source": [
    "## 1. Hallucination\n",
    "\n",
    "Some models are better than others. Try out a couple of models to figure out the ones that hallucinate more than other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5a6b51b",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "429 Client Error: Too Many Requests for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it (Request ID: Re64SGapf8SJ0jNfij-AO)\n\nRate limit reached. Please log in or use a HF access token",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen-ai-app-dev-course\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen-ai-app-dev-course\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Change the index to try out different models\u001b[39;00m\n\u001b[0;32m      4\u001b[0m llm \u001b[38;5;241m=\u001b[39m InferenceClient(model\u001b[38;5;241m=\u001b[39mhugging_face_model_ids[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m llm\u001b[38;5;241m.\u001b[39mtext_generation(text, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen-ai-app-dev-course\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:2060\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[1;34m(self, prompt, details, stream, model, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         _set_unsupported_text_generation_kwargs(model, unused_params)\n\u001b[0;32m   2037\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_generation(  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2038\u001b[0m             prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m   2039\u001b[0m             details\u001b[38;5;241m=\u001b[39mdetails,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2058\u001b[0m             watermark\u001b[38;5;241m=\u001b[39mwatermark,\n\u001b[0;32m   2059\u001b[0m         )\n\u001b[1;32m-> 2060\u001b[0m     raise_text_generation_error(e)\n\u001b[0;32m   2062\u001b[0m \u001b[38;5;66;03m# Parse output\u001b[39;00m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen-ai-app-dev-course\\Lib\\site-packages\\huggingface_hub\\inference\\_common.py:460\u001b[0m, in \u001b[0;36mraise_text_generation_error\u001b[1;34m(http_error)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhttp_error\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;66;03m# Otherwise, fallback to default error\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m http_error\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen-ai-app-dev-course\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:2031\u001b[0m, in \u001b[0;36mInferenceClient.text_generation\u001b[1;34m(self, prompt, details, stream, model, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[0;32m   2029\u001b[0m \u001b[38;5;66;03m# Handle errors separately for more precise error messages\u001b[39;00m\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2031\u001b[0m     bytes_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost(json\u001b[38;5;241m=\u001b[39mpayload, model\u001b[38;5;241m=\u001b[39mmodel, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, stream\u001b[38;5;241m=\u001b[39mstream)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2032\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2033\u001b[0m     match \u001b[38;5;241m=\u001b[39m MODEL_KWARGS_NOT_USED_REGEX\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen-ai-app-dev-course\\Lib\\site-packages\\huggingface_hub\\inference\\_client.py:273\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[1;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m     hf_raise_for_status(response)\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gen-ai-app-dev-course\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:371\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[1;32m--> 371\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mHfHubHTTPError\u001b[0m: 429 Client Error: Too Many Requests for url: https://api-inference.huggingface.co/models/google/gemma-2-2b-it (Request ID: Re64SGapf8SJ0jNfij-AO)\n\nRate limit reached. Please log in or use a HF access token"
     ]
    }
   ],
   "source": [
    "text = \"define LLM in the context of biology\"\n",
    "\n",
    "# Change the index to try out different models\n",
    "llm = InferenceClient(model=hugging_face_model_ids[0])\n",
    "\n",
    "llm.text_generation(text, max_new_tokens=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04015520",
   "metadata": {},
   "source": [
    "## 2. Dated knowledge\n",
    "\n",
    "**Note:**\n",
    "You will also observe hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ce47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the models & your own prompts\n",
    "# text = \"who won the 2022 super bowl?\"  # LA Rams vs Cincinnati Bengals  https://en.wikipedia.org/wiki/Super_Bowl_LVI\n",
    "text = \"as of today, who is the prime minister of UK\"\n",
    "\n",
    "# Change the index to try out different models\n",
    "llm = InferenceClient(model=hugging_face_model_ids[0])\n",
    "\n",
    "llm.text_generation(text, max_new_tokens=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a080bf8b",
   "metadata": {},
   "source": [
    "## 3. Missing context\n",
    "\n",
    "Model is not aware of your enterprise's business domain or model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the models and your own prompts\n",
    "text = \"do you carry the acme brand robo cleaner?\"\n",
    "# text = \"what is your return policy?\"\n",
    "\n",
    "# Change the index to try out different models\n",
    "llm = InferenceClient(model=hugging_face_model_ids[1])  # 1 = mistralai/Mistral-7B-Instruct-v0.2\n",
    "\n",
    "llm.text_generation(text, max_new_tokens=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d7fdd",
   "metadata": {},
   "source": [
    "## 4. Bias\n",
    "\n",
    "Some models are trained to prevent biases. Try out the model **index= 1 'tiiuae/falcon-7b-instruct'** to see its behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d95e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"for the engineering jobs we should only hire men because \"\n",
    "\n",
    "# Change the index to try out different models\n",
    "llm = InferenceClient(model=hugging_face_model_ids[2])  # 2 = openlm-research/open_llama_3b_v2\n",
    "\n",
    "llm.text_generation(text, max_new_tokens=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7915dd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\Users\\raj\\anaconda3\\envs\\gen-ai-app-dev-course:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "aiohttp                   3.9.5           py312h2bbff1b_0  \n",
      "aiosignal                 1.2.0              pyhd3eb1b0_0  \n",
      "annotated-types           0.6.0           py312haa95532_0  \n",
      "anyio                     4.2.0           py312haa95532_0  \n",
      "argon2-cffi               21.3.0             pyhd3eb1b0_0  \n",
      "argon2-cffi-bindings      21.2.0          py312h2bbff1b_0  \n",
      "arrow-cpp                 16.1.0               h7cd61ee_0  \n",
      "asttokens                 2.0.5              pyhd3eb1b0_0  \n",
      "async-lru                 2.0.4           py312haa95532_0  \n",
      "async-timeout             4.0.3           py312haa95532_0  \n",
      "attrs                     23.1.0          py312haa95532_0  \n",
      "aws-c-auth                0.6.19               h2bbff1b_0  \n",
      "aws-c-cal                 0.5.20               h2bbff1b_0  \n",
      "aws-c-common              0.8.5                h2bbff1b_0  \n",
      "aws-c-compression         0.2.16               h2bbff1b_0  \n",
      "aws-c-event-stream        0.2.15               hd77b12b_0  \n",
      "aws-c-http                0.6.25               h2bbff1b_0  \n",
      "aws-c-io                  0.13.10              h2bbff1b_0  \n",
      "aws-c-mqtt                0.7.13               h2bbff1b_0  \n",
      "aws-c-s3                  0.1.51               h2bbff1b_0  \n",
      "aws-c-sdkutils            0.1.6                h2bbff1b_0  \n",
      "aws-checksums             0.1.13               h2bbff1b_0  \n",
      "aws-crt-cpp               0.18.16              hd77b12b_0  \n",
      "aws-sdk-cpp               1.10.55              hd77b12b_0  \n",
      "babel                     2.11.0          py312haa95532_0  \n",
      "beautifulsoup4            4.12.3          py312haa95532_0  \n",
      "blas                      1.0                         mkl  \n",
      "bleach                    4.1.0              pyhd3eb1b0_0  \n",
      "boost-cpp                 1.82.0               h59b6b97_2  \n",
      "bottleneck                1.3.7           py312he558020_0  \n",
      "brotli                    1.0.9                h2bbff1b_8  \n",
      "brotli-bin                1.0.9                h2bbff1b_8  \n",
      "brotli-python             1.0.9           py312hd77b12b_8  \n",
      "bzip2                     1.0.8                h2bbff1b_6  \n",
      "c-ares                    1.19.1               h2bbff1b_0  \n",
      "ca-certificates           2024.7.2             haa95532_0  \n",
      "certifi                   2024.7.4        py312haa95532_0  \n",
      "cffi                      1.16.0          py312h2bbff1b_1  \n",
      "charset-normalizer        3.3.2              pyhd3eb1b0_0  \n",
      "colorama                  0.4.6           py312haa95532_0  \n",
      "comm                      0.2.1           py312haa95532_0  \n",
      "contourpy                 1.2.0           py312h59b6b97_0  \n",
      "cpuonly                   2.0                           0    pytorch\n",
      "cycler                    0.11.0             pyhd3eb1b0_0  \n",
      "datasets                  2.19.1          py312haa95532_0  \n",
      "debugpy                   1.6.7           py312hd77b12b_0  \n",
      "decorator                 5.1.1              pyhd3eb1b0_0  \n",
      "defusedxml                0.7.1              pyhd3eb1b0_0  \n",
      "dill                      0.3.8           py312haa95532_0  \n",
      "executing                 0.8.3              pyhd3eb1b0_0  \n",
      "expat                     2.6.2                hd77b12b_0  \n",
      "filelock                  3.13.1          py312haa95532_0  \n",
      "fonttools                 4.51.0          py312h2bbff1b_0  \n",
      "freetype                  2.12.1               ha860e81_0  \n",
      "frozenlist                1.4.0           py312h2bbff1b_0  \n",
      "fsspec                    2024.3.1        py312haa95532_0  \n",
      "gflags                    2.2.2                hd77b12b_1  \n",
      "glog                      0.5.0                hd77b12b_1  \n",
      "greenlet                  3.0.1           py312hd77b12b_0  \n",
      "huggingface_hub           0.23.1          py312haa95532_0  \n",
      "icu                       73.1                 h6c2663c_0  \n",
      "idna                      3.7             py312haa95532_0  \n",
      "importlib-metadata        7.0.1           py312haa95532_0  \n",
      "importlib_resources       6.4.0           py312haa95532_0  \n",
      "intel-openmp              2023.1.0         h59b6b97_46320  \n",
      "ipykernel                 6.28.0          py312haa95532_0  \n",
      "ipython                   8.25.0          py312haa95532_0  \n",
      "ipywidgets                8.1.2           py312haa95532_0  \n",
      "jedi                      0.19.1          py312haa95532_0  \n",
      "jinja2                    3.1.4           py312haa95532_0  \n",
      "jpeg                      9e                   h827c3e9_3  \n",
      "json5                     0.9.6              pyhd3eb1b0_0  \n",
      "jsonpatch                 1.33            py312haa95532_1  \n",
      "jsonpointer               2.1                pyhd3eb1b0_0  \n",
      "jsonschema                4.23.0             pyhd8ed1ab_0    conda-forge\n",
      "jsonschema-specifications 2023.7.1        py312haa95532_0  \n",
      "jupyter                   1.0.0           py312haa95532_9  \n",
      "jupyter-lsp               2.2.0           py312haa95532_0  \n",
      "jupyter_client            8.6.0           py312haa95532_0  \n",
      "jupyter_console           6.6.3           py312haa95532_1  \n",
      "jupyter_core              5.7.2           py312haa95532_0  \n",
      "jupyter_events            0.10.0          py312haa95532_0  \n",
      "jupyter_server            2.14.1          py312haa95532_0  \n",
      "jupyter_server_terminals  0.4.4           py312haa95532_1  \n",
      "jupyterlab                4.0.11          py312haa95532_0  \n",
      "jupyterlab_pygments       0.1.2                      py_0  \n",
      "jupyterlab_server         2.25.1          py312haa95532_0  \n",
      "jupyterlab_widgets        3.0.10          py312haa95532_0  \n",
      "kiwisolver                1.4.4           py312hd77b12b_0  \n",
      "krb5                      1.20.1               h5b6d351_0  \n",
      "langchain                 0.2.14             pyhd8ed1ab_0    conda-forge\n",
      "langchain-core            0.2.33             pyhd8ed1ab_0    conda-forge\n",
      "langchain-text-splitters  0.2.2              pyhd8ed1ab_0    conda-forge\n",
      "langsmith                 0.1.99             pyhd8ed1ab_0    conda-forge\n",
      "lcms2                     2.12                 h83e58a3_0  \n",
      "lerc                      3.0                  hd77b12b_0  \n",
      "libabseil                 20240116.2      cxx17_h5da7b33_0  \n",
      "libboost                  1.82.0               h3399ecb_2  \n",
      "libbrotlicommon           1.0.9                h2bbff1b_8  \n",
      "libbrotlidec              1.0.9                h2bbff1b_8  \n",
      "libbrotlienc              1.0.9                h2bbff1b_8  \n",
      "libclang                  14.0.6          default_hb5a9fac_1  \n",
      "libclang13                14.0.6          default_h8e68704_1  \n",
      "libcurl                   8.7.1                h86230a5_0  \n",
      "libdeflate                1.17                 h2bbff1b_1  \n",
      "libevent                  2.1.12               h56d1f94_1  \n",
      "libffi                    3.4.4                hd77b12b_1  \n",
      "libgrpc                   1.62.2               hf25190f_0  \n",
      "libjpeg-turbo             2.0.0                h196d8e1_0  \n",
      "libpng                    1.6.39               h8cc25b3_0  \n",
      "libpq                     12.17                h906ac69_0  \n",
      "libprotobuf               4.25.3               hf2fb9eb_0  \n",
      "libsodium                 1.0.18               h62dcd97_0  \n",
      "libssh2                   1.11.0               h291bd65_0  \n",
      "libthrift                 0.15.0               h4364b78_2  \n",
      "libtiff                   4.5.1                hd77b12b_0  \n",
      "libuv                     1.48.0               h827c3e9_0  \n",
      "libwebp-base              1.3.2                h2bbff1b_0  \n",
      "lz4-c                     1.9.4                h2bbff1b_1  \n",
      "markupsafe                2.1.3           py312h2bbff1b_0  \n",
      "matplotlib                3.8.4           py312haa95532_0  \n",
      "matplotlib-base           3.8.4           py312hc7c4135_0  \n",
      "matplotlib-inline         0.1.6           py312haa95532_0  \n",
      "mistune                   2.0.4           py312haa95532_0  \n",
      "mkl                       2023.1.0         h6b88ed4_46358  \n",
      "mkl-service               2.4.0           py312h2bbff1b_1  \n",
      "mkl_fft                   1.3.8           py312h2bbff1b_0  \n",
      "mkl_random                1.2.4           py312h59b6b97_0  \n",
      "mpmath                    1.3.0           py312haa95532_0  \n",
      "multidict                 6.0.4           py312h2bbff1b_0  \n",
      "multiprocess              0.70.15         py312haa95532_0  \n",
      "nbclient                  0.8.0           py312haa95532_0  \n",
      "nbconvert                 7.10.0          py312haa95532_0  \n",
      "nbformat                  5.9.2           py312haa95532_0  \n",
      "nest-asyncio              1.6.0           py312haa95532_0  \n",
      "networkx                  3.3             py312haa95532_0  \n",
      "notebook                  7.0.8           py312haa95532_2  \n",
      "notebook-shim             0.2.3           py312haa95532_0  \n",
      "numexpr                   2.8.7           py312h96b7d27_0  \n",
      "numpy                     1.26.4          py312hfd52020_0  \n",
      "numpy-base                1.26.4          py312h4dde369_0  \n",
      "openjpeg                  2.5.2                hae555c5_0  \n",
      "openssl                   3.0.14               h827c3e9_0  \n",
      "orc                       2.0.1                hd8d391b_0  \n",
      "orjson                    3.9.15          py312h2bbff1b_0  \n",
      "overrides                 7.4.0           py312haa95532_0  \n",
      "packaging                 24.1            py312haa95532_0  \n",
      "pandas                    2.2.2           py312h0158946_0  \n",
      "pandocfilters             1.5.0              pyhd3eb1b0_0  \n",
      "parso                     0.8.3              pyhd3eb1b0_0  \n",
      "pillow                    10.4.0          py312h827c3e9_0  \n",
      "pip                       24.2            py312haa95532_0  \n",
      "pkgutil-resolve-name      1.3.10          py312haa95532_1  \n",
      "platformdirs              3.10.0          py312haa95532_0  \n",
      "ply                       3.11            py312haa95532_1  \n",
      "prometheus_client         0.14.1          py312haa95532_0  \n",
      "prompt-toolkit            3.0.43          py312haa95532_0  \n",
      "prompt_toolkit            3.0.43               hd3eb1b0_0  \n",
      "psutil                    5.9.0           py312h2bbff1b_0  \n",
      "pure_eval                 0.2.2              pyhd3eb1b0_0  \n",
      "pyarrow                   16.1.0          py312h0158946_0  \n",
      "pycparser                 2.21               pyhd3eb1b0_0  \n",
      "pydantic                  2.5.3           py312haa95532_0  \n",
      "pydantic-core             2.14.6          py312h062c2fa_0  \n",
      "pygments                  2.15.1          py312haa95532_1  \n",
      "pyparsing                 3.0.9           py312haa95532_0  \n",
      "pyqt                      5.15.10         py312hd77b12b_0  \n",
      "pyqt5-sip                 12.13.0         py312h2bbff1b_0  \n",
      "pysocks                   1.7.1           py312haa95532_0  \n",
      "python                    3.12.4               h14ffc60_1  \n",
      "python-dateutil           2.9.0post0      py312haa95532_2  \n",
      "python-fastjsonschema     2.16.2          py312haa95532_0  \n",
      "python-json-logger        2.0.7           py312haa95532_0  \n",
      "python-tzdata             2023.3             pyhd3eb1b0_0  \n",
      "python-xxhash             2.0.2           py312h2bbff1b_1  \n",
      "pytorch                   2.4.0              py3.12_cpu_0    pytorch\n",
      "pytorch-mutex             1.0                         cpu    pytorch\n",
      "pytz                      2024.1          py312haa95532_0  \n",
      "pywin32                   305             py312h2bbff1b_0  \n",
      "pywinpty                  2.0.10          py312h5da7b33_0  \n",
      "pyyaml                    6.0.1           py312h2bbff1b_0  \n",
      "pyzmq                     25.1.2          py312hd77b12b_0  \n",
      "qt-main                   5.15.2              h19c9488_10  \n",
      "qtconsole                 5.5.1           py312haa95532_0  \n",
      "qtpy                      2.4.1           py312haa95532_0  \n",
      "re2                       2022.04.01           hd77b12b_0  \n",
      "referencing               0.30.2          py312haa95532_0  \n",
      "regex                     2024.7.24       py312h827c3e9_0  \n",
      "requests                  2.32.3          py312haa95532_0  \n",
      "rfc3339-validator         0.1.4           py312haa95532_0  \n",
      "rfc3986-validator         0.1.1           py312haa95532_0  \n",
      "rpds-py                   0.10.6          py312h062c2fa_0  \n",
      "safetensors               0.4.2           py312h1429478_1  \n",
      "send2trash                1.8.2           py312haa95532_0  \n",
      "setuptools                72.1.0          py312haa95532_0  \n",
      "sip                       6.7.12          py312hd77b12b_0  \n",
      "six                       1.16.0             pyhd3eb1b0_1  \n",
      "snappy                    1.2.1                hcdb6601_0  \n",
      "sniffio                   1.3.0           py312haa95532_0  \n",
      "soupsieve                 2.5             py312haa95532_0  \n",
      "sqlalchemy                2.0.30          py312h827c3e9_0  \n",
      "sqlite                    3.45.3               h2bbff1b_0  \n",
      "stack_data                0.2.0              pyhd3eb1b0_0  \n",
      "sympy                     1.12            py312haa95532_0  \n",
      "tbb                       2021.8.0             h59b6b97_0  \n",
      "tenacity                  8.2.3           py312haa95532_0  \n",
      "terminado                 0.17.1          py312haa95532_0  \n",
      "tinycss2                  1.2.1           py312haa95532_0  \n",
      "tk                        8.6.14               h0416ee5_0  \n",
      "tokenizers                0.19.1          py312hc899e84_0  \n",
      "torchaudio                2.4.0                 py312_cpu    pytorch\n",
      "torchvision               0.19.0                py312_cpu    pytorch\n",
      "tornado                   6.4.1           py312h827c3e9_0  \n",
      "tqdm                      4.66.4          py312hfc267ef_0  \n",
      "traitlets                 5.14.3          py312haa95532_0  \n",
      "transformers              4.41.2          py312haa95532_0  \n",
      "typing-extensions         4.11.0          py312haa95532_0  \n",
      "typing_extensions         4.11.0          py312haa95532_0  \n",
      "tzdata                    2024a                h04d1e81_0  \n",
      "unicodedata2              15.1.0          py312h2bbff1b_0  \n",
      "urllib3                   2.2.2           py312haa95532_0  \n",
      "utf8proc                  2.6.1                h2bbff1b_1  \n",
      "vc                        14.40                h2eaa2aa_0  \n",
      "vs2015_runtime            14.40.33807          h98bb1dd_0  \n",
      "wcwidth                   0.2.5              pyhd3eb1b0_0  \n",
      "webencodings              0.5.1           py312haa95532_2  \n",
      "websocket-client          1.8.0           py312haa95532_0  \n",
      "wheel                     0.43.0          py312haa95532_0  \n",
      "widgetsnbextension        4.0.10          py312haa95532_0  \n",
      "win_inet_pton             1.1.0           py312haa95532_0  \n",
      "winpty                    0.4.3                         4  \n",
      "xxhash                    0.8.0                h2bbff1b_3  \n",
      "xz                        5.4.6                h8cc25b3_1  \n",
      "yaml                      0.2.5                he774522_0  \n",
      "yarl                      1.9.3           py312h2bbff1b_0  \n",
      "zeromq                    4.3.5                hd77b12b_0  \n",
      "zipp                      3.17.0          py312haa95532_0  \n",
      "zlib                      1.2.13               h8cc25b3_1  \n",
      "zstd                      1.5.5                hd43e919_2  \n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31afb9a3-d724-4d4f-95c3-bb71e63dcb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: gen-ai-app-dev-course\n",
      "channels:\n",
      "  - pytorch\n",
      "  - defaults\n",
      "  - conda-forge\n",
      "dependencies:\n",
      "  - aiohttp=3.9.5=py312h2bbff1b_0\n",
      "  - aiosignal=1.2.0=pyhd3eb1b0_0\n",
      "  - annotated-types=0.6.0=py312haa95532_0\n",
      "  - anyio=4.2.0=py312haa95532_0\n",
      "  - argon2-cffi=21.3.0=pyhd3eb1b0_0\n",
      "  - argon2-cffi-bindings=21.2.0=py312h2bbff1b_0\n",
      "  - arrow-cpp=16.1.0=h7cd61ee_0\n",
      "  - asttokens=2.0.5=pyhd3eb1b0_0\n",
      "  - async-lru=2.0.4=py312haa95532_0\n",
      "  - async-timeout=4.0.3=py312haa95532_0\n",
      "  - attrs=23.1.0=py312haa95532_0\n",
      "  - aws-c-auth=0.6.19=h2bbff1b_0\n",
      "  - aws-c-cal=0.5.20=h2bbff1b_0\n",
      "  - aws-c-common=0.8.5=h2bbff1b_0\n",
      "  - aws-c-compression=0.2.16=h2bbff1b_0\n",
      "  - aws-c-event-stream=0.2.15=hd77b12b_0\n",
      "  - aws-c-http=0.6.25=h2bbff1b_0\n",
      "  - aws-c-io=0.13.10=h2bbff1b_0\n",
      "  - aws-c-mqtt=0.7.13=h2bbff1b_0\n",
      "  - aws-c-s3=0.1.51=h2bbff1b_0\n",
      "  - aws-c-sdkutils=0.1.6=h2bbff1b_0\n",
      "  - aws-checksums=0.1.13=h2bbff1b_0\n",
      "  - aws-crt-cpp=0.18.16=hd77b12b_0\n",
      "  - aws-sdk-cpp=1.10.55=hd77b12b_0\n",
      "  - babel=2.11.0=py312haa95532_0\n",
      "  - beautifulsoup4=4.12.3=py312haa95532_0\n",
      "  - blas=1.0=mkl\n",
      "  - bleach=4.1.0=pyhd3eb1b0_0\n",
      "  - boost-cpp=1.82.0=h59b6b97_2\n",
      "  - bottleneck=1.3.7=py312he558020_0\n",
      "  - brotli=1.0.9=h2bbff1b_8\n",
      "  - brotli-bin=1.0.9=h2bbff1b_8\n",
      "  - brotli-python=1.0.9=py312hd77b12b_8\n",
      "  - bzip2=1.0.8=h2bbff1b_6\n",
      "  - c-ares=1.19.1=h2bbff1b_0\n",
      "  - ca-certificates=2024.7.2=haa95532_0\n",
      "  - certifi=2024.7.4=py312haa95532_0\n",
      "  - cffi=1.16.0=py312h2bbff1b_1\n",
      "  - charset-normalizer=3.3.2=pyhd3eb1b0_0\n",
      "  - colorama=0.4.6=py312haa95532_0\n",
      "  - comm=0.2.1=py312haa95532_0\n",
      "  - contourpy=1.2.0=py312h59b6b97_0\n",
      "  - cpuonly=2.0=0\n",
      "  - cycler=0.11.0=pyhd3eb1b0_0\n",
      "  - datasets=2.19.1=py312haa95532_0\n",
      "  - debugpy=1.6.7=py312hd77b12b_0\n",
      "  - decorator=5.1.1=pyhd3eb1b0_0\n",
      "  - defusedxml=0.7.1=pyhd3eb1b0_0\n",
      "  - dill=0.3.8=py312haa95532_0\n",
      "  - executing=0.8.3=pyhd3eb1b0_0\n",
      "  - expat=2.6.2=hd77b12b_0\n",
      "  - filelock=3.13.1=py312haa95532_0\n",
      "  - fonttools=4.51.0=py312h2bbff1b_0\n",
      "  - freetype=2.12.1=ha860e81_0\n",
      "  - frozenlist=1.4.0=py312h2bbff1b_0\n",
      "  - fsspec=2024.3.1=py312haa95532_0\n",
      "  - gflags=2.2.2=hd77b12b_1\n",
      "  - glog=0.5.0=hd77b12b_1\n",
      "  - greenlet=3.0.1=py312hd77b12b_0\n",
      "  - huggingface_hub=0.23.1=py312haa95532_0\n",
      "  - icu=73.1=h6c2663c_0\n",
      "  - idna=3.7=py312haa95532_0\n",
      "  - importlib-metadata=7.0.1=py312haa95532_0\n",
      "  - importlib_resources=6.4.0=py312haa95532_0\n",
      "  - intel-openmp=2023.1.0=h59b6b97_46320\n",
      "  - ipykernel=6.28.0=py312haa95532_0\n",
      "  - ipython=8.25.0=py312haa95532_0\n",
      "  - ipywidgets=8.1.2=py312haa95532_0\n",
      "  - jedi=0.19.1=py312haa95532_0\n",
      "  - jinja2=3.1.4=py312haa95532_0\n",
      "  - jpeg=9e=h827c3e9_3\n",
      "  - json5=0.9.6=pyhd3eb1b0_0\n",
      "  - jsonpatch=1.33=py312haa95532_1\n",
      "  - jsonpointer=2.1=pyhd3eb1b0_0\n",
      "  - jsonschema=4.23.0=pyhd8ed1ab_0\n",
      "  - jsonschema-specifications=2023.7.1=py312haa95532_0\n",
      "  - jupyter=1.0.0=py312haa95532_9\n",
      "  - jupyter-lsp=2.2.0=py312haa95532_0\n",
      "  - jupyter_client=8.6.0=py312haa95532_0\n",
      "  - jupyter_console=6.6.3=py312haa95532_1\n",
      "  - jupyter_core=5.7.2=py312haa95532_0\n",
      "  - jupyter_events=0.10.0=py312haa95532_0\n",
      "  - jupyter_server=2.14.1=py312haa95532_0\n",
      "  - jupyter_server_terminals=0.4.4=py312haa95532_1\n",
      "  - jupyterlab=4.0.11=py312haa95532_0\n",
      "  - jupyterlab_pygments=0.1.2=py_0\n",
      "  - jupyterlab_server=2.25.1=py312haa95532_0\n",
      "  - jupyterlab_widgets=3.0.10=py312haa95532_0\n",
      "  - kiwisolver=1.4.4=py312hd77b12b_0\n",
      "  - krb5=1.20.1=h5b6d351_0\n",
      "  - langchain=0.2.14=pyhd8ed1ab_0\n",
      "  - langchain-core=0.2.33=pyhd8ed1ab_0\n",
      "  - langchain-text-splitters=0.2.2=pyhd8ed1ab_0\n",
      "  - langsmith=0.1.99=pyhd8ed1ab_0\n",
      "  - lcms2=2.12=h83e58a3_0\n",
      "  - lerc=3.0=hd77b12b_0\n",
      "  - libabseil=20240116.2=cxx17_h5da7b33_0\n",
      "  - libboost=1.82.0=h3399ecb_2\n",
      "  - libbrotlicommon=1.0.9=h2bbff1b_8\n",
      "  - libbrotlidec=1.0.9=h2bbff1b_8\n",
      "  - libbrotlienc=1.0.9=h2bbff1b_8\n",
      "  - libclang=14.0.6=default_hb5a9fac_1\n",
      "  - libclang13=14.0.6=default_h8e68704_1\n",
      "  - libcurl=8.7.1=h86230a5_0\n",
      "  - libdeflate=1.17=h2bbff1b_1\n",
      "  - libevent=2.1.12=h56d1f94_1\n",
      "  - libffi=3.4.4=hd77b12b_1\n",
      "  - libgrpc=1.62.2=hf25190f_0\n",
      "  - libjpeg-turbo=2.0.0=h196d8e1_0\n",
      "  - libpng=1.6.39=h8cc25b3_0\n",
      "  - libpq=12.17=h906ac69_0\n",
      "  - libprotobuf=4.25.3=hf2fb9eb_0\n",
      "  - libsodium=1.0.18=h62dcd97_0\n",
      "  - libssh2=1.11.0=h291bd65_0\n",
      "  - libthrift=0.15.0=h4364b78_2\n",
      "  - libtiff=4.5.1=hd77b12b_0\n",
      "  - libuv=1.48.0=h827c3e9_0\n",
      "  - libwebp-base=1.3.2=h2bbff1b_0\n",
      "  - lz4-c=1.9.4=h2bbff1b_1\n",
      "  - markupsafe=2.1.3=py312h2bbff1b_0\n",
      "  - matplotlib=3.8.4=py312haa95532_0\n",
      "  - matplotlib-base=3.8.4=py312hc7c4135_0\n",
      "  - matplotlib-inline=0.1.6=py312haa95532_0\n",
      "  - mistune=2.0.4=py312haa95532_0\n",
      "  - mkl=2023.1.0=h6b88ed4_46358\n",
      "  - mkl-service=2.4.0=py312h2bbff1b_1\n",
      "  - mkl_fft=1.3.8=py312h2bbff1b_0\n",
      "  - mkl_random=1.2.4=py312h59b6b97_0\n",
      "  - mpmath=1.3.0=py312haa95532_0\n",
      "  - multidict=6.0.4=py312h2bbff1b_0\n",
      "  - multiprocess=0.70.15=py312haa95532_0\n",
      "  - nbclient=0.8.0=py312haa95532_0\n",
      "  - nbconvert=7.10.0=py312haa95532_0\n",
      "  - nbformat=5.9.2=py312haa95532_0\n",
      "  - nest-asyncio=1.6.0=py312haa95532_0\n",
      "  - networkx=3.3=py312haa95532_0\n",
      "  - notebook=7.0.8=py312haa95532_2\n",
      "  - notebook-shim=0.2.3=py312haa95532_0\n",
      "  - numexpr=2.8.7=py312h96b7d27_0\n",
      "  - numpy=1.26.4=py312hfd52020_0\n",
      "  - numpy-base=1.26.4=py312h4dde369_0\n",
      "  - openjpeg=2.5.2=hae555c5_0\n",
      "  - openssl=3.0.14=h827c3e9_0\n",
      "  - orc=2.0.1=hd8d391b_0\n",
      "  - orjson=3.9.15=py312h2bbff1b_0\n",
      "  - overrides=7.4.0=py312haa95532_0\n",
      "  - packaging=24.1=py312haa95532_0\n",
      "  - pandas=2.2.2=py312h0158946_0\n",
      "  - pandocfilters=1.5.0=pyhd3eb1b0_0\n",
      "  - parso=0.8.3=pyhd3eb1b0_0\n",
      "  - pillow=10.4.0=py312h827c3e9_0\n",
      "  - pip=24.2=py312haa95532_0\n",
      "  - pkgutil-resolve-name=1.3.10=py312haa95532_1\n",
      "  - platformdirs=3.10.0=py312haa95532_0\n",
      "  - ply=3.11=py312haa95532_1\n",
      "  - prometheus_client=0.14.1=py312haa95532_0\n",
      "  - prompt-toolkit=3.0.43=py312haa95532_0\n",
      "  - prompt_toolkit=3.0.43=hd3eb1b0_0\n",
      "  - psutil=5.9.0=py312h2bbff1b_0\n",
      "  - pure_eval=0.2.2=pyhd3eb1b0_0\n",
      "  - pyarrow=16.1.0=py312h0158946_0\n",
      "  - pycparser=2.21=pyhd3eb1b0_0\n",
      "  - pydantic=2.5.3=py312haa95532_0\n",
      "  - pydantic-core=2.14.6=py312h062c2fa_0\n",
      "  - pygments=2.15.1=py312haa95532_1\n",
      "  - pyparsing=3.0.9=py312haa95532_0\n",
      "  - pyqt=5.15.10=py312hd77b12b_0\n",
      "  - pyqt5-sip=12.13.0=py312h2bbff1b_0\n",
      "  - pysocks=1.7.1=py312haa95532_0\n",
      "  - python=3.12.4=h14ffc60_1\n",
      "  - python-dateutil=2.9.0post0=py312haa95532_2\n",
      "  - python-fastjsonschema=2.16.2=py312haa95532_0\n",
      "  - python-json-logger=2.0.7=py312haa95532_0\n",
      "  - python-tzdata=2023.3=pyhd3eb1b0_0\n",
      "  - python-xxhash=2.0.2=py312h2bbff1b_1\n",
      "  - pytorch=2.4.0=py3.12_cpu_0\n",
      "  - pytorch-mutex=1.0=cpu\n",
      "  - pytz=2024.1=py312haa95532_0\n",
      "  - pywin32=305=py312h2bbff1b_0\n",
      "  - pywinpty=2.0.10=py312h5da7b33_0\n",
      "  - pyyaml=6.0.1=py312h2bbff1b_0\n",
      "  - pyzmq=25.1.2=py312hd77b12b_0\n",
      "  - qt-main=5.15.2=h19c9488_10\n",
      "  - qtconsole=5.5.1=py312haa95532_0\n",
      "  - qtpy=2.4.1=py312haa95532_0\n",
      "  - re2=2022.04.01=hd77b12b_0\n",
      "  - referencing=0.30.2=py312haa95532_0\n",
      "  - regex=2024.7.24=py312h827c3e9_0\n",
      "  - requests=2.32.3=py312haa95532_0\n",
      "  - rfc3339-validator=0.1.4=py312haa95532_0\n",
      "  - rfc3986-validator=0.1.1=py312haa95532_0\n",
      "  - rpds-py=0.10.6=py312h062c2fa_0\n",
      "  - safetensors=0.4.2=py312h1429478_1\n",
      "  - send2trash=1.8.2=py312haa95532_0\n",
      "  - setuptools=72.1.0=py312haa95532_0\n",
      "  - sip=6.7.12=py312hd77b12b_0\n",
      "  - six=1.16.0=pyhd3eb1b0_1\n",
      "  - snappy=1.2.1=hcdb6601_0\n",
      "  - sniffio=1.3.0=py312haa95532_0\n",
      "  - soupsieve=2.5=py312haa95532_0\n",
      "  - sqlalchemy=2.0.30=py312h827c3e9_0\n",
      "  - sqlite=3.45.3=h2bbff1b_0\n",
      "  - stack_data=0.2.0=pyhd3eb1b0_0\n",
      "  - sympy=1.12=py312haa95532_0\n",
      "  - tbb=2021.8.0=h59b6b97_0\n",
      "  - tenacity=8.2.3=py312haa95532_0\n",
      "  - terminado=0.17.1=py312haa95532_0\n",
      "  - tinycss2=1.2.1=py312haa95532_0\n",
      "  - tk=8.6.14=h0416ee5_0\n",
      "  - tokenizers=0.19.1=py312hc899e84_0\n",
      "  - torchaudio=2.4.0=py312_cpu\n",
      "  - torchvision=0.19.0=py312_cpu\n",
      "  - tornado=6.4.1=py312h827c3e9_0\n",
      "  - tqdm=4.66.4=py312hfc267ef_0\n",
      "  - traitlets=5.14.3=py312haa95532_0\n",
      "  - transformers=4.41.2=py312haa95532_0\n",
      "  - typing-extensions=4.11.0=py312haa95532_0\n",
      "  - typing_extensions=4.11.0=py312haa95532_0\n",
      "  - tzdata=2024a=h04d1e81_0\n",
      "  - unicodedata2=15.1.0=py312h2bbff1b_0\n",
      "  - urllib3=2.2.2=py312haa95532_0\n",
      "  - utf8proc=2.6.1=h2bbff1b_1\n",
      "  - vc=14.40=h2eaa2aa_0\n",
      "  - vs2015_runtime=14.40.33807=h98bb1dd_0\n",
      "  - wcwidth=0.2.5=pyhd3eb1b0_0\n",
      "  - webencodings=0.5.1=py312haa95532_2\n",
      "  - websocket-client=1.8.0=py312haa95532_0\n",
      "  - wheel=0.43.0=py312haa95532_0\n",
      "  - widgetsnbextension=4.0.10=py312haa95532_0\n",
      "  - win_inet_pton=1.1.0=py312haa95532_0\n",
      "  - winpty=0.4.3=4\n",
      "  - xxhash=0.8.0=h2bbff1b_3\n",
      "  - xz=5.4.6=h8cc25b3_1\n",
      "  - yaml=0.2.5=he774522_0\n",
      "  - yarl=1.9.3=py312h2bbff1b_0\n",
      "  - zeromq=4.3.5=hd77b12b_0\n",
      "  - zipp=3.17.0=py312haa95532_0\n",
      "  - zlib=1.2.13=h8cc25b3_1\n",
      "  - zstd=1.5.5=hd43e919_2\n",
      "prefix: C:\\Users\\raj\\anaconda3\\envs\\gen-ai-app-dev-course\n"
     ]
    }
   ],
   "source": [
    "!conda env export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf2da7d6-b7a5-4ea2-a595-fe93cd3842dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'utils'...\n",
      "remote: Not Found\n",
      "fatal: repository 'https://github.com/acloudfan/gen-ai-app-dev.git/utils/' not found\n"
     ]
    }
   ],
   "source": [
    "!git clone  --sparse https://github.com/acloudfan/gen-ai-app-dev.git/utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ed0f82c-c607-46ee-9303-16d3750e6e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'gen-ai-app-dev'...\n"
     ]
    }
   ],
   "source": [
    "!git clone \\\n",
    "\t--filter=blob:none \\\n",
    "\t--sparse \\\n",
    "\t--no-checkout \\\n",
    "   https://github.com/acloudfan/gen-ai-app-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dfe2fe-333a-41a3-b948-b716e4491891",
   "metadata": {},
   "outputs": [],
   "source": [
    "git sparse-checkout set --no-cone small small2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
