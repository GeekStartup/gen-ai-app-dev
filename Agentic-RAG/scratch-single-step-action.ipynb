{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ed7585-a502-4bbf-8483-0df5e6dfbed7",
   "metadata": {},
   "source": [
    "# Single step agent\n",
    "\n",
    "1. Setup prompt that asks an LLM to use provided tools or use tool responses to generate answers\n",
    "2. Setup the tools, decriptions\n",
    "3. **Single Step Agent**:\n",
    "   - Ask LLM to pick the tools to run\n",
    "   - Runs the tools\n",
    "   - Send the tools responses to LLM to generate final answer\n",
    "4. Test scenarios\n",
    "\n",
    "Note:\n",
    "* Code uses the OpenAI GPT 3.5 turbo model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2b1d8-251a-4b0a-b113-1d9bfca8b72b",
   "metadata": {},
   "source": [
    "## Setup LLM\n",
    "Same LLM will be used for planning & answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dcee5a3-230e-4d0f-a61b-bb7c3944acc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcreate_llm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_gpt_llm, create_anthropic_llm, create_ai21_llm, create_cohere_llm\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Try with GPT\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m llm \u001b[38;5;241m=\u001b[39m create_gpt_llm()\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\Courses\\Generative-AI\\workspace\\generative-ai-for-architects\\RAG\\..\\utils\\create_llm.py:22\u001b[0m, in \u001b[0;36mcreate_gpt_llm\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_gpt_llm\u001b[39m(args\u001b[38;5;241m=\u001b[39m{}):\n\u001b[1;32m---> 22\u001b[0m     llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs) \n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ChatOpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load the file that contains the API keys - OPENAI_API_KEY\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')\n",
    "\n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.create_llm import create_gpt_llm, create_anthropic_llm, create_ai21_llm, create_cohere_llm\n",
    "\n",
    "# Try with GPT\n",
    "llm = create_gpt_llm()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f932d9-f0a0-4776-b96a-c52188884994",
   "metadata": {},
   "source": [
    "## 1. Setup the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f862de3b-b134-4a0e-a4f9-8a41897fdc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful assistant who can answer questions on a variety of topics. \n",
    "Do not use your own internal knowledge or information to answer the question. \n",
    "Think step by step and use only the following available tools.\n",
    "\n",
    "Tools:\n",
    "{tools}\n",
    "\n",
    "There is no need for preamble, just give the response in ONE of the following valid JSON formats:\n",
    "\n",
    "option 1:\n",
    "use this if you need tools to be run to get the information\n",
    "{{\"actions\": [{{ \"action\" : tool name, \"arguments\" : dictionary of argument values}}}}]\n",
    "\n",
    "option 2:\n",
    "use this if you can use the action responses to answer the question\n",
    "{{\"answer\": \"your response to the question\", \"explanation\": \"provide your explanation here\"}}\n",
    "\n",
    "Here is the question: {question}\n",
    "\n",
    "action_responses: {action_responses}\n",
    "\n",
    "response:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = template,\n",
    "    input_variables = ['tools', 'question', 'action_responses']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f44c12-4358-405a-8099-a1f305a25da9",
   "metadata": {},
   "source": [
    "## 2. Setup tools\n",
    "* Dummy tool functions for stock price & city weather\n",
    "* Tool map = dictionary of functions with function name as the key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f4af73d-9733-48c4-8084-2512b9b8c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tool 1 for stocks\n",
    "def  company_stock_price(stock_symbol: str) -> float:\n",
    "    if stock_symbol.upper()=='APPL':\n",
    "        return  {\"price\": 192.32}\n",
    "    elif stock_symbol.upper()=='MSFT':\n",
    "        return  {\"price\": 415.60}\n",
    "    elif stock_symbol.upper()=='AMZN':\n",
    "        return  {\"price\": 183.60}\n",
    "    else:\n",
    "        return {\"price\": \"unknown\"}\n",
    "    pass\n",
    "\n",
    "stock_tool_description = {\n",
    "    \"name\" : \"company_stock_price\",\n",
    "    \"description\": \"This tool returns the last known stock price for a company\",\n",
    "    \"arguments\": [\n",
    "        {\"stock_symbol\" : \"stock exchange symbol for the company\"}\n",
    "    ],\n",
    "    \"response\": \"last known stock price\"\n",
    "}\n",
    "\n",
    "## Tool 2 for city weather\n",
    "def city_weather(city: str) -> int:\n",
    "    if city.lower() == \"new york\":\n",
    "        return {\"temperature\": 68, \"forecast\": \"rain\"}\n",
    "    elif city.lower() == \"paris\":\n",
    "        return {\"temperature\": 73, \"forecast\": \"sunny\"}\n",
    "    elif city.lower() == \"london\":\n",
    "        return {\"temperature\": 82, \"forecast\": \"cloudy\"}\n",
    "    else:\n",
    "        return {\"temperature\": \"unknown\"}\n",
    "        \n",
    "city_weather_tool_description = {\n",
    "    \"name\" : \"city_weather\",\n",
    "    \"description\": \"This tool returns the current temperature and forecast for the given city\",\n",
    "    \"arguments\": [\n",
    "        {\"city\" : \"name of the city\"}\n",
    "    ],\n",
    "    \"response\": \"current temperature & forecast\"\n",
    "}\n",
    "\n",
    "tools = [stock_tool_description, city_weather_tool_description]\n",
    "tools_map = {\n",
    "    'company_stock_price': company_stock_price,\n",
    "    'city_weather' : city_weather\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b2d07-7fae-4a69-ae69-f0bc8c8a1460",
   "metadata": {},
   "source": [
    "## 3. Agent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fff8a1e9-bdae-4767-a884-63cc4d4d3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to process the actions receieved from the LLM\n",
    "def   process_response_actions(response):\n",
    "    action_responses = []\n",
    "    if len(response[\"actions\"]) == 0:\n",
    "        print('question cannot be answered as there is no tool to use !!!')\n",
    "        exit\n",
    "    else:\n",
    "        for action in response[\"actions\"]:\n",
    "            action_function = tools_map[action[\"action\"]]\n",
    "            action_invoke_result = action_function(**action[\"arguments\"])\n",
    "            action[\"response\"] = action_invoke_result\n",
    "            action_responses.append(action)\n",
    "            \n",
    "    return action_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d9f564-92b5-4729-a58d-5d06b14d6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for answering the question\n",
    "def  process_query(question):\n",
    "    # Setup the prompt. Since no tool has been invoked set action_response as blank\n",
    "    query = prompt.format(tools=tools, question=question,action_responses=\"\")\n",
    "\n",
    "    # Invoke LLM to get the tools to be run\n",
    "    response = llm.invoke(query)\n",
    "\n",
    "    # print the response\n",
    "    print(\"Step-1:\", response)\n",
    "\n",
    "    # Convert response to JSON object\n",
    "    response_json = json.loads(response)\n",
    "\n",
    "    # LLM may respond with an answer \n",
    "    # It may happen if LLM determines that no tool is available for responding to the question\n",
    "    action_responses=[]\n",
    "    if \"answer\" in response_json:\n",
    "        return {\"answer\" : response_json[\"answer\"]}\n",
    "    elif \"actions\" in response_json:\n",
    "        action_responses = process_response_actions(response_json)\n",
    "\n",
    "    print(\"Agent tool invocation responses :\", action_responses)\n",
    "    \n",
    "    # Now send the action responses to LLM for generating the answer\n",
    "    query = prompt.format(tools=tools, question=question,action_responses=action_responses)\n",
    "    response = llm.invoke(query)\n",
    "\n",
    "    # print the response\n",
    "    print(\"Step-2:\", response)\n",
    "\n",
    "    # Convert response to JSON object\n",
    "    response_json = json.loads(response)\n",
    "\n",
    "    # Extract the answer from the response    \n",
    "    if \"answer\" in response_json:\n",
    "        return response_json[\"answer\"]\n",
    "    else:\n",
    "        return (\"Something unexpected has happened !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff2bfe-bf71-459a-a509-29c2236f4346",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb069cbc-093e-4218-abc4-6f9d470455ad",
   "metadata": {},
   "source": [
    "### 1. Simple test that uses 1 tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce2fda5-d301-4dca-b597-bc87ff74c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-1: {\"actions\": [{\"action\": \"city_weather\", \"arguments\": {\"city\": \"paris\"}}]}\n",
      "Agent tool invocation responses : [{'action': 'city_weather', 'arguments': {'city': 'paris'}, 'response': {'temperature': 73, 'forecast': 'sunny'}}]\n",
      "Step-2: {\"answer\": \"No, you should not carry an umbrella.\", \"explanation\": \"The current forecast for Paris is sunny and the temperature is 73 degrees, so an umbrella is not necessary.\"}\n",
      "Final response:: No, you should not carry an umbrella.\n"
     ]
    }
   ],
   "source": [
    "question = \"Which of these cities is hotter, Paris or London\"\n",
    "question = \"I am visting paris, should i carry an umbrella?\"\n",
    "\n",
    "response = process_query(question)\n",
    "\n",
    "print(\"Final response::\",response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e859be7-f0a9-44f7-acdd-158bcb73c46c",
   "metadata": {},
   "source": [
    "### 2. Test for a scenario when no appropriate tool is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c315ae8-22f1-4272-a28c-b48a3e510aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-1: {\"actions\": [\n",
      "    {\"action\": \"city_weather\", \"arguments\": {\"city\": \"Paris\"}},\n",
      "    {\"action\": \"company_stock_price\", \"arguments\": {\"stock_symbol\": \"EUR\"}}\n",
      "]}\n",
      "Agent tool invocation responses : [{'action': 'city_weather', 'arguments': {'city': 'Paris'}, 'response': {'temperature': 73, 'forecast': 'sunny'}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'EUR'}, 'response': {'price': 'unknown'}}]\n",
      "Step-2: {\"answer\": \"No\", \"explanation\": \"The current temperature in Paris is 73 degrees and the forecast is sunny. However, the stock price for EUR (Euro) is unknown, so we cannot determine if you can afford to live in Paris for 3 nights with only $200.\"}\n",
      "Final response: No\n"
     ]
    }
   ],
   "source": [
    "question = \"I have only $200, can I afford to live in Paris for 3 nights?\"\n",
    "\n",
    "response = process_query(question)\n",
    "\n",
    "print(\"Final response:\",response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac578414-77f7-4b9e-8556-23b3776deb20",
   "metadata": {},
   "source": [
    "### 3. A complex scenario requiring use of more than one tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db8c90b-76b2-421c-83a4-fc2fcce651b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-1: {\"actions\": [\n",
      "    {\"action\": \"city_weather\", \"arguments\": {\"city\": \"London\"}},\n",
      "    {\"action\": \"company_stock_price\", \"arguments\": {\"stock_symbol\": \"AAPL\"}},\n",
      "    {\"action\": \"company_stock_price\", \"arguments\": {\"stock_symbol\": \"MSFT\"}},\n",
      "    {\"action\": \"company_stock_price\", \"arguments\": {\"stock_symbol\": \"AMZN\"}}\n",
      "]}\n",
      "Agent tool invocation responses : [{'action': 'city_weather', 'arguments': {'city': 'London'}, 'response': {'temperature': 82, 'forecast': 'cloudy'}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'AAPL'}, 'response': {'price': 'unknown'}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'MSFT'}, 'response': {'price': 415.6}}, {'action': 'company_stock_price', 'arguments': {'stock_symbol': 'AMZN'}, 'response': {'price': 183.6}}]\n",
      "Step-2: {\"answer\": \"I would not recommend buying any of the stocks (AAPL, MSFT, AMZN) based on the current weather forecast in London, which is cloudy. It would be best to wait for a different weather condition to make a decision.\", \"explanation\": \"The weather in London is currently cloudy, which according to the given criteria, means you should not buy any stocks. However, if you were to choose a stock, I would recommend MSFT as it has the highest price among the three stocks.\"}\n",
      "Final response: I would not recommend buying any of the stocks (AAPL, MSFT, AMZN) based on the current weather forecast in London, which is cloudy. It would be best to wait for a different weather condition to make a decision.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\" \n",
    "I am interested in buying one of the stocks (AAPL, MSFT, AMZN). \n",
    "I will make my decision based on the weather forecast in the city I am in and the price of the stock.\n",
    "If the weather is sunny then I will chose a stock that has a lower price.\n",
    "If the weather is raining then I will chose a stock that has a higher price.\n",
    "If the wwather is cloudy then I will not buy any stock.\n",
    "\n",
    "Today I am in London, which stock should I buy?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = process_query(question)\n",
    "\n",
    "print(\"Final response:\",response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25aa896-f8f3-458c-95da-eeb987e1156b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
