{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04274fc3-ee48-4083-8499-8fbeb6f030ec",
   "metadata": {},
   "source": [
    "# Agent creation functions\n",
    "https://python.langchain.com/v0.1/docs/modules/agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be479ab1-b706-4ead-8277-833f9dada5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, create_structured_chat_agent, create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8344b5d-64f9-4335-9113-34a54afe055b",
   "metadata": {},
   "source": [
    "## Setup LLM\n",
    "\n",
    "Use an LLM for which \"Stop sequence\" key name is supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7590e9d2-237c-445b-b11f-8eae5a66454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load the file that contains the API keys - OPENAI_API_KEY\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')\n",
    "\n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.create_chat_llm import create_gpt_chat_llm, create_cohere_chat_llm, create_anthropic_chat_llm, create_hugging_face_chat_llm\n",
    "from utils.create_llm import create_cohere_llm, create_gpt_llm\n",
    "\n",
    "# Try with GPT\n",
    "llm = create_gpt_chat_llm({\"temperature\":0.1}) \n",
    "\n",
    "\n",
    "### Try out ONLY if you have tested Amazon Bedrock connectivity\n",
    "### Model must support \"Stop Sequence\" e.g., [model_id='meta.llama3-8b-instruct-v1:0'] does not support \"Stop sequence\"\n",
    "\n",
    "### Uncomment following lines of code to try out Anthropic Claude Haiku on Bedrock\n",
    "# from utils.amazon_bedrock import create_bedrock_chat_model\n",
    "# model_id='anthropic.claude-3-haiku-20240307-v1:0'\n",
    "# llm = create_bedrock_chat_model(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f9eeb7-16dc-43a3-bfca-ee0e3e9a834f",
   "metadata": {},
   "source": [
    "## 1. Tool calling agent\n",
    "\n",
    "Tool calling allows a model to detect when one or more tools should be called and respond with the inputs that should be passed to those tools. In an API call, you can describe tools and have the model intelligently choose to output a structured object like JSON containing arguments to call these tools. \n",
    "\n",
    "https://api.python.langchain.com/en/latest/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc198ca-5907-44f0-bf5d-19798aac7492",
   "metadata": {},
   "source": [
    "#### Create prompt, setup tools - create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac676fe-b747-47c8-8078-59f2512d8cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt MUST have a {agent_scratchpad} input\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Make sure to use the tools for information.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Load the wikipedia tool\n",
    "tools = load_tools([\"wikipedia\", \"arxiv\"])\n",
    "\n",
    "# Construct the Tools agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3724a-aebc-40db-b2f8-8401ee868185",
   "metadata": {},
   "source": [
    "#### Setup agent executor\n",
    "\n",
    "https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d5683-2faa-46c1-9f88-812dd8be3732",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469385e-0fc7-4e86-9efb-bcccaac93299",
   "metadata": {},
   "source": [
    "#### Invoke agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655cd75-c594-4403-9242-5945209aa366",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"share paper on React in the context of large language models?\"\n",
    "# input = \"name the president of France\"\n",
    "\n",
    "# Invoke the agent\n",
    "agent_executor.invoke({\"input\": input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8e24a-8aac-45db-a17b-5a381d24b94a",
   "metadata": {},
   "source": [
    "## 2. Structured chat agent\n",
    "The structured chat agent is capable of using multi-input tools.\n",
    "\n",
    "#### Solution for exercise#4\n",
    "\n",
    "#### RE-Write of \"Scratch single step agent\" \n",
    "It is using the utility function create_structured_chat_agent\n",
    "\n",
    "https://api.python.langchain.com/en/latest/agents/langchain.agents.structured_chat.base.create_structured_chat_agent.html\n",
    "\n",
    "#### The prompt must have input keys:\r",
    "* **{tools}** contains descriptions and arguments for each tool.\r\n",
    "\r\n",
    "* **{tool_names}** contains all tool names.\r\n",
    "\r\n",
    "* **{agent_scratchpad}** contains previous agent actions and tool outputs as a string.ring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade28e4-2328-497b-998d-a88e3224e16c",
   "metadata": {},
   "source": [
    "#### dummy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d22ec3-3598-484e-9580-8d545ca29dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def  company_stock_price(stock_symbol: str) -> float:\n",
    "    \"\"\"\n",
    "    Retrieve the current stock price for a given company stock symbol.\n",
    "\n",
    "    This function accepts a stock symbol and returns the current stock price for the specified company.\n",
    "    It supports stock symbols for the following companies:\n",
    "    - Apple Inc. (\"AAPL\")\n",
    "    - Microsoft Corporation (\"MSFT\")\n",
    "    - Amazon.com, Inc. (\"AMZN\")\n",
    "\n",
    "    If the stock symbol does not match any of the supported companies, the function returns \"unknown\" as the price.\n",
    "\n",
    "    Args:\n",
    "        stock_symbol (str): The stock symbol of the company whose stock price is requested.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the stock price with the key \"price\".\n",
    "              If the stock symbol is not recognized, the value is \"unknown\".\n",
    "    \"\"\"\n",
    "    if stock_symbol.upper()=='AAPL':\n",
    "        return  {\"price\": 192.32}\n",
    "    elif stock_symbol.upper()=='MSFT':\n",
    "        return  {\"price\": 415.60}\n",
    "    elif stock_symbol.upper()=='AMZN':\n",
    "        return  {\"price\": 183.60}\n",
    "    else:\n",
    "        return {\"price\": \"unknown\"}\n",
    "\n",
    "\n",
    "@tool\n",
    "def city_weather(city: str) -> int:\n",
    "    \"\"\"\n",
    "    Retrieve the current weather information for a given city.\n",
    "\n",
    "    This function accepts a city name and returns a dictionary containing the current temperature and weather forecast for that city. \n",
    "    It supports the following cities:\n",
    "    - New York\n",
    "    - Paris\n",
    "    - London\n",
    "\n",
    "    If the city is not recognized, the function returns \"unknown\" for the temperature.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city for which the weather information is requested.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the following keys:\n",
    "            - \"temperature\": The current temperature in Fahrenheit.\n",
    "            - \"forecast\": A brief description of the current weather forecast.\n",
    "            \n",
    "        If the city is not recognized, the \"temperature\" key will have a value of \"unknown\".\n",
    "    \"\"\"\n",
    "    if city.lower() == \"new york\":\n",
    "        return {\"temperature\": 68, \"forecast\": \"rain\"}\n",
    "    elif city.lower() == \"paris\":\n",
    "        return {\"temperature\": 73, \"forecast\": \"sunny\"}\n",
    "    elif city.lower() == \"london\":\n",
    "        return {\"temperature\": 82, \"forecast\": \"cloudy\"}\n",
    "    else:\n",
    "        return {\"temperature\": \"unknown\"}\n",
    "\n",
    "# create the tools array\n",
    "tools = [company_stock_price, city_weather]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b6888-e63a-4935-ab20-026b9993072c",
   "metadata": {},
   "source": [
    "#### Setup the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2324e-f848-4f45-8c45-843021d1eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = '''Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "\n",
    "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
    "\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\n",
    "\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "\n",
    "Follow this format:\n",
    "\n",
    "Question: input question to answer\n",
    "Thought: consider previous and subsequent steps\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: action result\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human\"\n",
    "}}\n",
    "\n",
    "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'''\n",
    "\n",
    "human = '''{input}\n",
    "\n",
    "{agent_scratchpad}\n",
    "\n",
    "(reminder to respond in a JSON blob no matter what)'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", human),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8de35f-75c0-4b10-a577-4bcfb8251877",
   "metadata": {},
   "source": [
    "#### Create agent executor\n",
    "\n",
    "* Checkout the documentation for [create_structured_chat_agent](https://api.python.langchain.com/en/latest/agents/langchain.agents.structured_chat.base.create_structured_chat_agent.html#langchain-agents-structured-chat-base-create-structured-chat-agent)\r\n",
    "* Checkout the documentation for [AgentExecutor](https://api.python.langchain.com/en/latest/agents/langchain.agents.agent.AgentExecutor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4e2cf-2e7c-4156-9df0-e94449aaf0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_structured_chat_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, maximum_iterations=2, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aefc7e-a0b2-43f4-8d17-6553bdddf3f7",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a7bdc-560b-4091-9c6e-e71b540efebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# question = \"Which of these cities is hotter, Paris or London\"\n",
    "# question = \"I am visting paris city, should i carry an umbrella?\"\n",
    "question = question = \"\"\"\n",
    "I am interested in investing in one of these stocks: AAPL, MSFT, or AMZN.\n",
    "\n",
    "Decision Criteria:\n",
    "\n",
    "Sunny Weather: Choose the stock with the lowest price.\n",
    "Raining Weather: Choose the stock with the highest price.\n",
    "Cloudy Weather: Do not buy any stock.\n",
    "Location:\n",
    "\n",
    "I am currently in New York.\n",
    "Question:\n",
    "\n",
    "Based on the current weather in New York and the stock prices, which stock should I invest in?\n",
    "\"\"\"\n",
    "\n",
    "# Invoke the agent executor\n",
    "agent_executor.invoke({\n",
    "    \"input\": question\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22aa20e-4b0e-426d-95c9-8c1342bde06b",
   "metadata": {},
   "source": [
    "## 3. React agent\n",
    "\n",
    "#### Solution for exercise#4\n",
    "\n",
    "https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html\n",
    "\n",
    "**llm** (BaseLanguageModel) – LLM to use as the agent.\r",
    "\r\n",
    "**tools** (Sequence[BaseTool]) – Tools this agent has access to\r\n",
    "\r\n",
    "**prompt** (BasePromptTemplate) – The prompt to use. See Prompt section below for moe.\r\n",
    "\r\n",
    "**output_parser** (Optional[AgentOutputParser]) – AgentOutputParser for parse the LLM ouput.\r\n",
    "\r\n",
    "**tools_renderer** (Callable[[List[BaseTool]], str]) – This controls how the tools are converted into a string and then passed into the LLM. Default is render_text_descrption.\r\n",
    "\r\n",
    "**stop_sequence** (Union[bool, Lis str]]) –\r\n",
    "\r\n",
    "bool or list of str. If True, adds a stop token of “Observation:” to avoid hallucinates. If False, does not add a stop token. If a list of str, uses the provided list as the  top tokens.\r\n",
    "\r\n",
    "Default is True. You may to set this to False if the LLM you are using does not support stop sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5e84c-6dee-41f4-96a3-820f41df9e78",
   "metadata": {},
   "source": [
    "#### Setup tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4472c7f9-6a75-42b3-9bf1-bd87e6993ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the wikipedia tool\n",
    "tools = load_tools([\"wikipedia\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d056a57-1ebb-4848-bb20-27a41f11d400",
   "metadata": {},
   "source": [
    "#### Setup prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010e688d-dcd9-451d-a8bc-80e072ce234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://smith.langchain.com/hub/hwchase17/react\n",
    "template=\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Create the template\n",
    "prompt = PromptTemplate.from_template(template) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51da6e-04fb-4f1c-b33e-123f4c7ff1fb",
   "metadata": {},
   "source": [
    "#### Create the agent and the executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aef1b31-ffc5-49e4-8ab4-13d04c22bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate steps\n",
    "# https://python.langchain.com/v0.1/docs/modules/agents/how_to/intermediate_steps/\n",
    "agent_react = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "# verbose, trim_itermediate_steps : Optional\n",
    "agent_executor_react = AgentExecutor(agent=agent_react, \n",
    "                               tools=tools, \n",
    "                               maximum_iterations=3, \n",
    "                               verbose=False, \n",
    "                               handle_parsing_errors=True, \n",
    "                               return_intermediate_steps=True,\n",
    "                               trim_itermediate_steps=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b2ca917-8747-42b9-b458-5131e6dbfef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: The Jungle Book\n",
    "question = \"Which film stars more animals, The Jungle Book or The Lone Ranger?\"\n",
    "\n",
    "# Q: Risingson is the first single from what album by Massive Attack, that was the first to be produced by Neil Davidge, along with the group?\n",
    "# A: Mezzanine\n",
    "# question = \"Risingson is the first single from what album by Massive Attack, that was the first to be produced by Neil Davidge, along with the group?\"\n",
    "\n",
    "# Q: Where is the basketball team that Mike DiNunno plays for based ?\n",
    "# A: Ellesmere Port\n",
    "# question = \"Where is the basketball team that Mike DiNunno plays for based ?\"\n",
    "\n",
    "# Q: Which one of Ricardo Rodríguez Saá's relatives would become governor from 1983 to 2001?\n",
    "# A: Adolfo Rodríguez Saá\n",
    "# question=\"Which one of Ricardo Rodríguez Saá's relatives would become governor from 1983 to 2001?\"\n",
    "\n",
    "response = agent_executor_react({\"input\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6320234-a86a-412f-9210-6c93062991df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentAction Step:  0\n",
      "=================\n",
      "Thought:  You can use Wikipedia to find information about the number of animals in each film.\n",
      "Action: wikipedia\n",
      "Action Input: The Jungle Book (2016 film)\n",
      "AgentAction Step:  1\n",
      "=================\n",
      "Thought:  Action: wikipedia\n",
      "Action Input: The Lone Ranger (2013 film)\n",
      "AgentAction Step:  2\n",
      "=================\n",
      "Thought:  Action: wikipedia\n",
      "Action Input: The Jungle Book (2016 film) cast\n",
      "AgentAction Step:  3\n",
      "=================\n",
      "Thought:  Action: wikipedia\n",
      "Action Input: The Lone Ranger (2013 film) cast\n",
      "AgentAction Step:  4\n",
      "=================\n",
      "Thought:  Action: wikipedia\n",
      "Action Input: The Jungle Book (2016 film) animals\n",
      "AgentFinish:\n",
      "============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Jungle Book (2016 film) stars more animals than The Lone Ranger (2013 film).'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # print(response[\"intermediate_steps\"])\n",
    "if \"intermediate_steps\" in response:\n",
    "    for i, action_or_finish in enumerate(response[\"intermediate_steps\"]):\n",
    "        print(\"AgentAction Step: \", i)\n",
    "        print(\"=================\")\n",
    "        # print(\"Tool: \", action_or_finish[0].tool)\n",
    "        # print(\"Tool input: \", action_or_finish[0].tool_input)\n",
    "        print(\"Thought: \", action_or_finish[0].log)\n",
    "else:\n",
    "    print(\"No 'intermediate_steps'\")\n",
    "print(\"AgentFinish:\")\n",
    "print(\"============\")\n",
    "response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc8582-4d07-4959-98c0-2f546169319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cfa9e-c7be-46d0-bf7d-b4a0945e5dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
