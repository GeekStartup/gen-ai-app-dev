{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f555e2-a87a-4824-9325-c2caf40ea31d",
   "metadata": {},
   "source": [
    "# Text Splitters\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/character_text_splitter\n",
    "\n",
    "API\n",
    "\n",
    "https://api.python.langchain.com/en/latest/text_splitters_api_reference.html\n",
    "\n",
    "https://api.python.langchain.com/en/stable/text_splitter/langchain.text_splitter.TextSplitter.html#langchain.text_splitter.TextSplitter.split_documents\n",
    "\n",
    "umenty document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8a3e58-f0da-4048-8a3a-ab442ab93ca2",
   "metadata": {},
   "source": [
    "## 1.Recursive Character Text Splitter\n",
    "\n",
    "https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html\n",
    "\n",
    "#### Sample PDF\n",
    "Download it to local file system:  https://constitutioncenter.org/media/files/constitution.pdf\n",
    "\n",
    "#### Note\n",
    "The sample code below can be replaced with *pdf_loader.load_and_split(pdf_text_splitter)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87da2abc-7141-4146-9fbc-395dae2310ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document list size :  52\n",
      "Metadata :  {'source': 'C:/temp/us-constitution.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load from local file system or from a URL\n",
    "# You may also us the PDF web loader\n",
    "pdf_source = 'C:/temp/us-constitution.pdf'\n",
    "pdf_loader = PyPDFLoader(pdf_source) \n",
    "documents = pdf_loader.load()\n",
    "\n",
    "# print(documents) #[0].page_content)\n",
    "\n",
    "print(\"Document list size : \", len(documents))\n",
    "print(\"Metadata : \", documents[0].metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266c7c71-6f8d-4b63-806d-1385706158ec",
   "metadata": {},
   "source": [
    "* chunk_size – Maximum size of chunks to return.\n",
    "* chunk_overlap : Overlap in characters between chunks\n",
    "* length_function – Function that measures the length of given chunks\n",
    "* keep_separator – Whether to keep the separator in the chunks\n",
    "* add_start_index – If True, includes chunk’s start index in metadata\n",
    "* strip_whitespace – If True, strips whitespace from the start and end of every document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e10a414-f749-40a3-a748-777f329b8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = 784\n",
    "chunk_overlap = 100\n",
    "\n",
    "# Create an instance of the splitter\n",
    "pdf_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee7fe7d9-2e98-4d84-a090-f440292d4362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks :  0\n"
     ]
    }
   ],
   "source": [
    "chunked_documents = pdf_text_splitter.split_documents(documents)\n",
    "\n",
    "print(\"Number of chunks : \", len(chunked_documents))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d0e884-e9a0-4246-8f75-312ff00e99aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mChunk length = \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(chunked_documents[\u001b[38;5;241m20\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(chunked_documents[\u001b[38;5;241m20\u001b[39m]\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print('Chunk length = ', len(chunked_documents[20].page_content))\n",
    "print(chunked_documents[20].metadata)\n",
    "print('------------')\n",
    "print(chunked_documents[20].page_content)\n",
    "print('------------')\n",
    "print(chunked_documents[21].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef242e3-0f94-4926-ae4a-594b92b804ed",
   "metadata": {},
   "source": [
    "## 2.JSON \n",
    "\n",
    "This json splitter traverses json data depth first and builds smaller json chunks. It attempts to keep nested json objects whole but will split them if needed to keep chunks between a min_chunk_size and the max_chunk_size. If the value is not a nested json, but rather a very large string the string will not be split. If you need a hard cap on the chunk size considder following this with a Recursive Text splitter on those chunks. There is an optional pre-processing step to split lists, by first converting them to json (dict) and then splitting them as such.\n",
    "\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_json_splitter\n",
    "\n",
    "#### API\n",
    "\n",
    "https://api.python.langchain.com/en/latest/json/langchain_text_splitters.json.RecursiveJsonSplitter.html#langchain_text_splitters.json.RecursiveJsonSplitter\n",
    "\n",
    "- max_chunk_size(int)\n",
    "- min_chunk_size (Optional[int]) –"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd439a-8e96-4253-b31b-c268092fa5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_json = {\n",
    "  \"name\": \"John\",\n",
    "  \"age\": 30,\n",
    "  \"city\": \"New York\",\n",
    "  \"pets\": [\n",
    "    {\n",
    "      \"type\": \"dog\",\n",
    "      \"name\": \"Buddy\",\n",
    "      \"age\": 5,\n",
    "      \"traits\": [\"friendly\", \"energetic\"]\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"cat\",\n",
    "      \"name\": \"Whiskers\",\n",
    "      \"age\": 3,\n",
    "      \"traits\": [\"independent\", \"playful\"]\n",
    "    }\n",
    "  ],\n",
    "  \"work\": {\n",
    "    \"company\": \"XYZ Corp\",\n",
    "    \"position\": \"Software Engineer\",\n",
    "    \"years_of_experience\": 8,\n",
    "    \"projects\": [\n",
    "      {\n",
    "        \"name\": \"Project A\",\n",
    "        \"status\": \"completed\",\n",
    "        \"team_members\": [\"Alice\", \"Bob\", \"Charlie\"]\n",
    "      },\n",
    "      {\n",
    "        \"name\": \"Project B\",\n",
    "        \"status\": \"in_progress\",\n",
    "        \"team_members\": [\"Dave\", \"Eve\"]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f592d933-0cc5-498c-8fb0-a22655184873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=50)\n",
    "\n",
    "json_chunks = splitter.split_json(json_data=sample_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856359a9-74e4-4a0f-bd0b-a00b8331c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of chunks : ', len(json_chunks))\n",
    "\n",
    "for chunk in json_chunks:\n",
    "    print('---------', type(chunk),'----------')\n",
    "    print(chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6fcf24-37f6-4689-8281-b40514357105",
   "metadata": {},
   "source": [
    "## 3.HTML Splitter\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/HTML_header_metadata\n",
    "\n",
    "#### API\n",
    "https://api.python.langchain.com/en/latest/html/langchain_text_splitters.html.HTMLHeaderTextSplitter.html#langchain_text_splitters.html.HTMLHeaderTextSplitter\n",
    "\n",
    "* headers_to_split_on (List[Tuple[str, str]]) – list of tuples of headers we want to track mapped to (arbitrary) keys for metadata. Allowed header values: h1, h2, h3, h4, h5, h6 e.g. [(“h1”, “Header 1”), (“h2”, “Header 2)].\r\n",
    "* \r\n",
    "return_each_element (bool) – Return each element w/ associated headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ec256-0a95-4af3-955e-034c645daf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <div>\n",
    "        <h1>Foo</h1>\n",
    "        <p>Some intro text about Foo.</p>\n",
    "        <div>\n",
    "            <h2>Bar main section</h2>\n",
    "            <p>Some intro text about Bar.</p>\n",
    "            <h3>Bar subsection 1</h3>\n",
    "            <p>Some text about the first subtopic of Bar.</p>\n",
    "            <h3>Bar subsection 2</h3>\n",
    "            <p>Some text about the second subtopic of Bar.</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <h2>Baz</h2>\n",
    "            <p>Some text about Baz</p>\n",
    "        </div>\n",
    "        <br>\n",
    "        <p>Some concluding text about Foo</p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba2a42-7c84-488e-b21a-e2a9927b6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "url = \"https://plato.stanford.edu/entries/goedel/\"\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "    (\"h4\", \"Header 4\"),\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "# for local file use html_splitter.split_text_from_file(<path_to_file>)\n",
    "html_header_splits = html_splitter.split_text_from_url(url)\n",
    "\n",
    "chunk_size = 500\n",
    "chunk_overlap = 30\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "# Split\n",
    "splits = text_splitter.split_documents(html_header_splits)\n",
    "splits[80:85]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15c46e-2931-41d1-bf74-830ea9adf876",
   "metadata": {},
   "source": [
    "## 4.Semantic splitter\n",
    "\n",
    "EXPERIMENTAL\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d28271-946e-4b2d-a3b4-bdd991045fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
