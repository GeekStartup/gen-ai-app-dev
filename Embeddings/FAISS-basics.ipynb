{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93abe491-0132-4488-afc4-1fb4efa9ffb5",
   "metadata": {},
   "source": [
    "# FAISS Intro + Similarity search algorithm\n",
    "\n",
    "## Objective\n",
    "Learn about the configuration parameters for the various algorithms:\n",
    "\n",
    "* Flat\n",
    "* LSH\n",
    "* IVF\n",
    "* PQ\n",
    "* IVF PQ\n",
    "* HNSW PQ\n",
    "* HNSW Scalar\n",
    "\n",
    "### Installation\n",
    "https://github.com/facebookresearch/faiss/wiki/Installing-Faiss\n",
    "\n",
    "https://github.com/matsui528/faiss_tips\n",
    "\n",
    "#### Note\n",
    "* Small dataset is in use to make it easy to understand/follow the working of algos\n",
    "* The time measurement is NOT applicable as the datasets is too small for achieving high efficiency via many of the algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0408804c-f921-45f0-8762-b70392d46a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu\n",
    "# !pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa584b9-37f0-405a-8645-7cd9aa5f407d",
   "metadata": {},
   "source": [
    "## 1. Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbe8900c-0cb1-49ec-b27a-b701dd1e84db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the file that contains the API keys\n",
    "# CHANGE THIS TO YOUR ENV FILE LOCATION\n",
    "load_dotenv('C:\\\\Users\\\\raj\\\\.jupyter\\\\.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4c7b4-7c76-4d86-afcd-a5c9819ede68",
   "metadata": {},
   "source": [
    "## 2. Generate the embeddings\n",
    "\n",
    "#### Note\n",
    "Cohere in use but may be switched with any embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37118d78-fbd2-4f5f-ae41-749ba6948596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.embeddings import CohereEmbeddings\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "# Create the embeddings model - Dimension = 384\n",
    "# Cohere model in use\n",
    "# model_name = \"embed-english-light-v3.0\"\n",
    "\n",
    "# Create the embeddings model - Dimension = 1024\n",
    "model_name = \"embed-english-v3.0\"\n",
    "\n",
    "embeddings_model = CohereEmbeddings(model=model_name)\n",
    "\n",
    "corpus = [\n",
    "  \"A man is eating food.\", \"A man is eating a piece of bread.\",\n",
    "  \"The chef is preparing a delicious meal in the kitchen.\", \"A chef is tossing vegetables in a sizzling pan.\",\n",
    "  \"A man is riding a horse.\", \"A man is riding a white horse on an enclosed ground.\",\n",
    "  \"A woman is playing violin.\", \"A musician is tuning his guitar before the concert.\",\n",
    "  \"The girl is carrying a baby.\", \"The baby is giggling while playing with her toys.\",\n",
    "  \"The family is having a picnic under the shady oak tree.\", \"A group of friends is hiking up the mountain trail.\",\n",
    "  \"The mechanic is repairing a broken-down car in the garage.\", \"The old man is feeding breadcrumbs to the ducks at the pond.\",\n",
    "  \"The artist is sketching a beautiful landscape at sunset.\", \"A man is painting a colorful mural on the city wall.\",\n",
    "  \"A team of scientists is conducting experiments in the laboratory.\", \"A group of students is studying together in the library.\",\n",
    "  \"The birds are chirping happily in the morning sun.\", \"The dog is chasing its tail around the backyard.\",\n",
    "  \"A group of children are playing soccer in the park.\", \"A monkey is playing drums.\",\n",
    "  \"A boy is flying a kite in the open field.\", \"Two men pushed carts through the woods.\",\n",
    "  \"A woman is walking her dog along the beach.\", \"A young girl is reading a book under a shady tree.\",\n",
    "  \"The dancer is gracefully performing on stage.\", \"The farmer is harvesting ripe tomatoes from the vine.\"\n",
    "]\n",
    "\n",
    "\n",
    "# A list of embeddings\n",
    "corpus_embeddings = embeddings_model.embed_documents(corpus)\n",
    "\n",
    "# convert list of embeddings to numpy\n",
    "corpus_embeddings_numpy = np.array(corpus_embeddings).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6ee88-2208-40f2-887f-6e8b1c6fc8b2",
   "metadata": {},
   "source": [
    "### Generate embeddings\n",
    "\n",
    "#### Note\n",
    "The quality of embedding & results will depend on the dimension !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "750b6f5a-03d2-4eb9-884f-66bac7343d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension =  1024\n"
     ]
    }
   ],
   "source": [
    "embedding_dimension = len(corpus_embeddings[0])\n",
    "\n",
    "print(\"Embedding dimension = \", embedding_dimension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed925e-a4fc-4a56-96dc-3982466350f7",
   "metadata": {},
   "source": [
    "##  3. IndexFlatL2\n",
    "\n",
    "* Some indexes require training. FlatL2 doesn't require any training as it is brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84e4f4a9-ce25-4297-89b2-d427ebca13f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is trained :  True\n",
      "Size of index :  28\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "\n",
    "# Create index \n",
    "index_flatl2 = faiss.IndexFlatL2(embedding_dimension)\n",
    "\n",
    "# Is trained\n",
    "print(\"Is trained : \",index_flatl2.is_trained)\n",
    "\n",
    "\n",
    "\n",
    "# Add embeddings\n",
    "index_flatl2.add(corpus_embeddings_numpy)\n",
    "\n",
    "print(\"Size of index : \",index_flatl2.ntotal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b70544-d168-4694-a006-a9846943ad12",
   "metadata": {},
   "source": [
    "#### Query\n",
    "\n",
    "#### index.search\n",
    "\n",
    "Takes as parameter an ndarray with embedding\n",
    "\n",
    "Returns the Distance:ndarray, Indexes:ndarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9966e5df-0a96-47c0-9e75-c09427b1f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = [\n",
    "    'I am a foodie',\n",
    "    'My siter loves to play string instruments',\n",
    "    'Musical instruments'\n",
    "]\n",
    "\n",
    "embed_query = embeddings_model.embed_documents([test_docs[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc404098-c81f-4c4f-bcff-3dfd02d472e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances :  [[0.8526868 1.0069261 1.16745  ]]\n",
      "Indexes :  [[0 2 1]]\n",
      "------\n",
      "A man is eating food.   ( 0.8526868 )\n",
      "The chef is preparing a delicious meal in the kitchen.   ( 1.0069261 )\n",
      "A man is eating a piece of bread.   ( 1.16745 )\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 11.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=3\n",
    "\n",
    "distances, indexes = index_flatl2.search(np.array(embed_query), k)\n",
    "\n",
    "print(\"Distances : \", distances)\n",
    "print(\"Indexes : \", indexes)\n",
    "\n",
    "print(\"------\")\n",
    "for i, corpus_index in enumerate(indexes[0]):\n",
    "    print(corpus[corpus_index],\"  (\",  distances[0][i],\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dbd945-51bb-4c70-8c53-5b020199644f",
   "metadata": {},
   "source": [
    "## 4. Index LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "119eaf67-d24e-4708-a8d5-f72640a2ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Index LSH. Higher bits is better but results in lowering of QPS, potential increase in latency\n",
    "## nbits is generally expressed as multiple of d (embedding dimension)\n",
    "\n",
    "## For testing use low numbers such as 8, 16, 32, 64 and check out the impact on results\n",
    "## Low values translates into BAD recall\n",
    "nbits = 16\n",
    "\n",
    "# initialize the index using our vectors dimensionality and nbits\n",
    "index_lsh = faiss.IndexLSH(embedding_dimension, nbits)\n",
    "\n",
    "# then add the data\n",
    "index_lsh.add(corpus_embeddings_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b33bc4f4-b51b-45d4-8e47-e2461d640b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances :  [[2. 3. 3.]]\n",
      "Indexes :  [[0 1 2]]\n",
      "------\n",
      "A man is eating food.   ( 2.0 )\n",
      "A man is eating a piece of bread.   ( 3.0 )\n",
      "The chef is preparing a delicious meal in the kitchen.   ( 3.0 )\n",
      "CPU times: total: 2.11 s\n",
      "Wall time: 604 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Test docs\n",
    "test_docs = [\n",
    "    'I am a foodie',\n",
    "    'My siter loves to play string instruments',\n",
    "    'Musical instruments'\n",
    "]\n",
    "\n",
    "# Create query vector\n",
    "embed_query = embeddings_model.embed_documents([test_docs[0]])\n",
    "\n",
    "k=3\n",
    "\n",
    "distances, indexes = index_lsh.search(np.array(embed_query), k)\n",
    "\n",
    "print(\"Distances : \", distances)\n",
    "print(\"Indexes : \", indexes)\n",
    "\n",
    "print(\"------\")\n",
    "for i, corpus_index in enumerate(indexes[0]):\n",
    "    print(corpus[corpus_index],\"  (\",  distances[0][i],\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea0729c-f9c2-4134-b733-06b3567b7329",
   "metadata": {},
   "source": [
    "## 5. IVF + PQ\n",
    "\n",
    "https://faiss.ai/cpp_api/struct/structfaiss_1_1IndexIVFPQ.html\n",
    "\n",
    "##### Note:\n",
    "Dataset is too small to demonstrate the true value of PQ with IVF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "245e4c75-13fd-4a03-9a7d-f5a6aa6e7620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is trained:  False\n"
     ]
    }
   ],
   "source": [
    "# Change to this number will change the performance & recall\n",
    "nlist_ivfpq = 4\n",
    "\n",
    "# Number of centroids in the compressed vectors\n",
    "number_centroids = 8\n",
    "\n",
    "# Number of bits in each centroid\n",
    "number_bits_per_centroid = 2 \n",
    "\n",
    "quantizer = faiss.IndexFlatL2(embedding_dimension)  # we keep the same L2 distance flat index\n",
    "index_ivfpq = faiss.IndexIVFPQ(quantizer, embedding_dimension, nlist_ivfpq, number_centroids, number_bits_per_centroid) \n",
    "\n",
    "print(\"Is trained: \", index_ivfpq.is_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f589250b-4a8d-46aa-b5a7-ca7626a0675d",
   "metadata": {},
   "source": [
    "### Train index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5be6c274-18fb-4c36-add3-6ee944db7669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is trained:  True\n",
      "ntotal :  28\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 34.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Now add the embeddings to the index\n",
    "index_ivfpq.train(corpus_embeddings_numpy)\n",
    "index_ivfpq.add(corpus_embeddings_numpy)\n",
    "\n",
    "print(\"Is trained: \", index_ivfpq.is_trained)\n",
    "print(\"ntotal : \", index_ivfpq.ntotal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5448b79-262a-480a-bf7b-332bdd93133f",
   "metadata": {},
   "source": [
    "### Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c20d5e6-aded-46db-907d-49c3e831ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances :  [[0.79832053 0.8417079  0.8417079 ]]\n",
      "Indexes :  [[ 6  9 16]]\n",
      "------\n",
      "A woman is playing violin.   ( 0.79832053 )\n",
      "The baby is giggling while playing with her toys.   ( 0.8417079 )\n",
      "A team of scientists is conducting experiments in the laboratory.   ( 0.8417079 )\n",
      "CPU times: total: 2.69 s\n",
      "Wall time: 546 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Test docs\n",
    "test_docs = [\n",
    "    'I am a foodie',\n",
    "    'My siter loves to play string instruments',\n",
    "    'Musical instruments'\n",
    "]\n",
    "\n",
    "# Create query vector\n",
    "embed_query = embeddings_model.embed_documents([test_docs[0]])\n",
    "\n",
    "k=3\n",
    "\n",
    "distances, indexes = index_ivfpq.search(np.array(embed_query), k)\n",
    "\n",
    "print(\"Distances : \", distances)\n",
    "print(\"Indexes : \", indexes)\n",
    "print(\"------\")\n",
    "for i, corpus_index in enumerate(indexes[0]):\n",
    "    print(corpus[corpus_index],\"  (\",  distances[0][i],\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb51c4cb-02f0-43d6-9f53-dfe4a0f42d6c",
   "metadata": {},
   "source": [
    "## 6. Product Quantization (PQ)\n",
    "\n",
    "https://faiss.ai/cpp_api/struct/structfaiss_1_1IndexPQ.html#\n",
    "\n",
    "IndexPQ(int d, size_t M, size_t nbits, MetricType metric = METRIC_L2)\n",
    "\n",
    "- d – dimensionality of the input vectors\n",
    "- M – number of subquantizers\n",
    "- nbits – number of bit per subvector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd25c06e-c9b9-43a5-83dd-2402c3cb360a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of sub spaces\n",
    "m = 8\n",
    "\n",
    "# Number of bits per subquantizer. Total number of centroids = 2**nbits\n",
    "# If you set this number very high, you will get an error : \"Number of training points (28) should be at least as large as number of clusters (...)\"\n",
    "# For the example set with 28 vectors (max nbits = 4)\n",
    "nbits = 4\n",
    "\n",
    "# embedding dimension must be divisble by number of vector spaces\n",
    "assert embedding_dimension % m == 0\n",
    "\n",
    "# Create the index\n",
    "index_pq = faiss.IndexPQ(embedding_dimension, m, nbits)\n",
    "\n",
    "index_pq.is_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa9fb5c-8f0c-4995-bfe2-71f981654445",
   "metadata": {},
   "source": [
    "### Train index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "348de854-e38b-4f12-9dc5-db21c93e160f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_trained:  True\n",
      "ntotal :  28\n",
      "CPU times: total: 172 ms\n",
      "Wall time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train and add embeddings\n",
    "index_pq.train(corpus_embeddings_numpy)\n",
    "index_pq.add(corpus_embeddings_numpy)\n",
    "\n",
    "print(\"is_trained: \", index_pq.is_trained)\n",
    "print(\"ntotal : \", index_pq.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b3d4d6-b6d0-48d3-ad6c-e69bf3a69b6a",
   "metadata": {},
   "source": [
    "### Test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0c7feb0-1dbf-4131-83e5-cc1a51445b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances :  [[0.86941785 0.92359406 0.92359406]]\n",
      "Indexes :  [[0 2 3]]\n",
      "------\n",
      "A man is eating food.   ( 0.86941785 )\n",
      "The chef is preparing a delicious meal in the kitchen.   ( 0.92359406 )\n",
      "A chef is tossing vegetables in a sizzling pan.   ( 0.92359406 )\n",
      "CPU times: total: 2.3 s\n",
      "Wall time: 545 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Test docs\n",
    "test_docs = [\n",
    "    'I am a foodie',\n",
    "    'My siter loves to play string instruments',\n",
    "    'Musical instruments'\n",
    "]\n",
    "\n",
    "# Create query vector\n",
    "embed_query = embeddings_model.embed_documents([test_docs[0]])\n",
    "\n",
    "k=3\n",
    "\n",
    "distances, indexes = index_pq.search(np.array(embed_query), k)\n",
    "\n",
    "print(\"Distances : \", distances)\n",
    "print(\"Indexes : \", indexes)\n",
    "\n",
    "print(\"------\")\n",
    "for i, corpus_index in enumerate(indexes[0]):\n",
    "    print(corpus[corpus_index],\"  (\",  distances[0][i],\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce58840-f7cc-4feb-8e9e-0f095420478d",
   "metadata": {},
   "source": [
    "## 7.IndexIVFFlat \n",
    "\n",
    "https://faiss.ai/cpp_api/struct/structfaiss_1_1IndexIVFFlat.html\n",
    "\n",
    "#### Note\n",
    "\n",
    "Negative index in the result set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9820b7bb-5725-429f-815c-1fda1ddf4ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is training :  False\n",
      "Is training :  True\n",
      "ntotal :  28\n"
     ]
    }
   ],
   "source": [
    "# how many cells\n",
    "nlist = 4\n",
    "\n",
    "# Quantizer\n",
    "quantizer = faiss.IndexFlatL2(embedding_dimension)\n",
    "\n",
    "# Index creation\n",
    "ivfflat_index = faiss.IndexIVFFlat(quantizer, embedding_dimension, nlist)\n",
    "\n",
    "# index\n",
    "print(\"Is training : \", ivfflat_index.is_trained)\n",
    "\n",
    "ivfflat_index.train(corpus_embeddings_numpy)\n",
    "ivfflat_index.add(corpus_embeddings_numpy)\n",
    "\n",
    "print(\"Is training : \", ivfflat_index.is_trained)\n",
    "print(\"ntotal : \", ivfflat_index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c26d2a64-1ad1-4a95-bb81-e839817e8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances :  [[0.8513175 1.0079684 1.1668954]]\n",
      "Indexes :  [[0 2 1]]\n",
      "------\n",
      "A man is eating food.   ( 0.8513175 )\n",
      "The chef is preparing a delicious meal in the kitchen.   ( 1.0079684 )\n",
      "A man is eating a piece of bread.   ( 1.1668954 )\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 1.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=3\n",
    "\n",
    "nprobes = 3\n",
    "ivfflat_index.nprobe = nprobes \n",
    "\n",
    "distances, indexes = ivfflat_index.search(np.array(embed_query), k)\n",
    "\n",
    "print(\"Distances : \", distances)\n",
    "print(\"Indexes : \", indexes)\n",
    "\n",
    "print(\"------\")\n",
    "for i, corpus_index in enumerate(indexes[0]):\n",
    "    print(corpus[corpus_index],\"  (\",  distances[0][i],\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da2f981-8881-42c9-a851-562c480a2107",
   "metadata": {},
   "source": [
    "## 8. HNSW with Flat Quantizer\n",
    "\n",
    "https://faiss.ai/cpp_api/struct/structfaiss_1_1IndexHNSWFlat.html\n",
    "\n",
    "#### IndexHNSWFlat.hnsw\n",
    "\n",
    "https://faiss.ai/cpp_api/file/HNSW_8h.html#_CPPv4N5faiss4HNSWE\n",
    "\n",
    "https://github.com/facebookresearch/faiss/blob/main/benchs/bench_hnsw.py\n",
    "\n",
    "#### Note:\n",
    "* Sample is provided to aid familiarization with HNSW\n",
    "* With the small dataset you would not see much gain by way of adjusting the efConstruction/efSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "746aee11-e57d-420e-949e-81b195da4c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is trained:  True\n"
     ]
    }
   ],
   "source": [
    "# Bidirectional links from each node in graph\n",
    "m = 3\n",
    "\n",
    "index_hnsw_flat = faiss.IndexHNSWFlat(embedding_dimension, m)\n",
    "\n",
    "# layer_depth_construction\n",
    "efConstruction = 1\n",
    "\n",
    "# layer_depth_in_search \n",
    "efSearch = 1\n",
    "\n",
    "index_hnsw_flat.hnsw.efConstruction = efConstruction \n",
    "index_hnsw_flat.hnsw.efSearch = efSearch # \n",
    "\n",
    "\n",
    "print(\"Is trained: \", index_hnsw_flat.is_trained)\n",
    "\n",
    "index_hnsw_flat.train(corpus_embeddings_numpy)\n",
    "index_hnsw_flat.add(corpus_embeddings_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be276327-b83a-457f-adab-870e8a49168f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances :  [[0.8513175 1.0079685 1.1668953]]\n",
      "Indexes :  [[0 2 1]]\n",
      "------\n",
      "A man is eating food.   ( 0.8513175 )\n",
      "The chef is preparing a delicious meal in the kitchen.   ( 1.0079685 )\n",
      "A man is eating a piece of bread.   ( 1.1668953 )\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 6.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k=3\n",
    "\n",
    "distances, indexes = index_hnsw_flat.search(np.array(embed_query), k)\n",
    "\n",
    "print(\"Distances : \", distances)\n",
    "print(\"Indexes : \", indexes)\n",
    "\n",
    "print(\"------\")\n",
    "for i, corpus_index in enumerate(indexes[0]):\n",
    "    print(corpus[corpus_index],\"  (\",  distances[0][i],\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef09da-38da-441d-bf5c-07afdea00a35",
   "metadata": {},
   "source": [
    "## 9. Write & Read index\n",
    "\n",
    "#### Note\n",
    "Change the location of temp folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde745ee-0ec6-4fe6-a626-00102744bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index_cache = \"c:\\\\temp\\\\faiss\"\n",
    "\n",
    "faiss.write_index(index_flatl2, faiss_index_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f93292-d294-42a3-8ac1-26b858bd29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_flatl2 = faiss.read_index(faiss_index_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811eb4f-816a-4327-a12b-4cf2a033762e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
